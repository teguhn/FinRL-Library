{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_ensemble_stock_trading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPT0ipYE28wL"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-01-02'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AALI.JK', 'ADHI.JK', 'ASII.JK', 'BBCA.JK', 'BBNI.JK', 'BBRI.JK', 'BBTN.JK', 'BMRI.JK', 'BSDE.JK', 'INDF.JK', 'JPFA.JK', 'JSMR.JK', 'KLBF.JK', 'PGAS.JK', 'PJAA.JK', 'PPRO.JK', 'SIDO.JK', 'SMGR.JK', 'TINS.JK', 'TLKM.JK', 'UNTR.JK', 'UNVR.JK', 'WIKA.JK', 'WSKT.JK', 'WTON.JK']\n"
     ]
    }
   ],
   "source": [
    "print(config.SRI_KEHATI_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (77537, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = config.START_DATE,\n",
    "                     end_date = '2021-01-19',\n",
    "                     ticker_list = config.JII_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GiRuFOTOtj1Y",
    "outputId": "bf7071db-d71a-4e1b-a28f-8e0145e0d204"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>1063.347290</td>\n",
       "      <td>26001500.0</td>\n",
       "      <td>ADRO.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1170.000000</td>\n",
       "      <td>767.357300</td>\n",
       "      <td>31557000.0</td>\n",
       "      <td>AKRA.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>1847.949097</td>\n",
       "      <td>1601.085693</td>\n",
       "      <td>39619544.0</td>\n",
       "      <td>ANTM.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>127.704979</td>\n",
       "      <td>35430000.0</td>\n",
       "      <td>BRPT.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>357.485199</td>\n",
       "      <td>6182500.0</td>\n",
       "      <td>CPIN.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         open         high          low        close      volume  \\\n",
       "0  2010-01-04  1750.000000  1750.000000  1730.000000  1063.347290  26001500.0   \n",
       "1  2010-01-04  1220.000000  1250.000000  1170.000000   767.357300  31557000.0   \n",
       "2  2010-01-04  1931.946777  1931.946777  1847.949097  1601.085693  39619544.0   \n",
       "3  2010-01-04   130.000000   133.000000   129.000000   127.704979  35430000.0   \n",
       "4  2010-01-04   440.000000   450.000000   435.000000   357.485199   6182500.0   \n",
       "\n",
       "       tic  day  \n",
       "0  ADRO.JK    0  \n",
       "1  AKRA.JK    0  \n",
       "2  ANTM.JK    0  \n",
       "3  BRPT.JK    0  \n",
       "4  CPIN.JK    0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DSw4ZEzVtj1Z",
    "outputId": "1a04171b-04c8-4974-9c63-3195261d8fd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77532</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>3430.0</td>\n",
       "      <td>3450.000000</td>\n",
       "      <td>138913100.0</td>\n",
       "      <td>TLKM.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77533</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>10125.0</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>10075.0</td>\n",
       "      <td>10268.323242</td>\n",
       "      <td>1743100.0</td>\n",
       "      <td>TPIA.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77534</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>26300.0</td>\n",
       "      <td>26850.0</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>26131.123047</td>\n",
       "      <td>4282500.0</td>\n",
       "      <td>UNTR.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77535</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>7525.0</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>44943900.0</td>\n",
       "      <td>UNVR.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77536</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>2250.000000</td>\n",
       "      <td>234257600.0</td>\n",
       "      <td>WIKA.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date     open     high      low         close       volume  \\\n",
       "77532  2021-01-18   3480.0   3520.0   3430.0   3450.000000  138913100.0   \n",
       "77533  2021-01-18  10125.0  10300.0  10075.0  10268.323242    1743100.0   \n",
       "77534  2021-01-18  26300.0  26850.0  25950.0  26131.123047    4282500.0   \n",
       "77535  2021-01-18   6950.0   7525.0   6900.0   7500.000000   44943900.0   \n",
       "77536  2021-01-18   2410.0   2450.0   2220.0   2250.000000  234257600.0   \n",
       "\n",
       "           tic  day  \n",
       "77532  TLKM.JK    0  \n",
       "77533  TPIA.JK    0  \n",
       "77534  UNTR.JK    0  \n",
       "77535  UNVR.JK    0  \n",
       "77536  WIKA.JK    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77537, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "4hYkeaPiICHS",
    "outputId": "ce9d7463-a74c-4917-c96d-848a1e8ad493"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>1063.347290</td>\n",
       "      <td>26001500.0</td>\n",
       "      <td>ADRO.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1170.000000</td>\n",
       "      <td>767.357300</td>\n",
       "      <td>31557000.0</td>\n",
       "      <td>AKRA.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>1847.949097</td>\n",
       "      <td>1601.085693</td>\n",
       "      <td>39619544.0</td>\n",
       "      <td>ANTM.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>127.704979</td>\n",
       "      <td>35430000.0</td>\n",
       "      <td>BRPT.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>357.485199</td>\n",
       "      <td>6182500.0</td>\n",
       "      <td>CPIN.JK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         open         high          low        close      volume  \\\n",
       "0  2010-01-04  1750.000000  1750.000000  1730.000000  1063.347290  26001500.0   \n",
       "1  2010-01-04  1220.000000  1250.000000  1170.000000   767.357300  31557000.0   \n",
       "2  2010-01-04  1931.946777  1931.946777  1847.949097  1601.085693  39619544.0   \n",
       "3  2010-01-04   130.000000   133.000000   129.000000   127.704979  35430000.0   \n",
       "4  2010-01-04   440.000000   450.000000   435.000000   357.485199   6182500.0   \n",
       "\n",
       "       tic  day  \n",
       "0  ADRO.JK    0  \n",
       "1  AKRA.JK    0  \n",
       "2  ANTM.JK    0  \n",
       "3  BRPT.JK    0  \n",
       "4  CPIN.JK    0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jgXfBcjxtj1a",
    "outputId": "abf8d5bb-2cd2-4c12-d4cb-ed1c429e60ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "R_3v-ycktj1b"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [],
   "source": [
    "processed_full = pd.read_csv('ensemble_processed_full_20210517.csv', index=False)\n",
    "processed_full.sample(5)\n",
    "# processed_full.to_csv('ensemble_processed_full_20210517.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 150_000_000/100, #Since in Indonesia the minimum number of shares per trx is 100, then we scaled the initial amount by dividing it with 100 \n",
    "    \"buy_cost_pct\": 0.0019, #IPOT has 0.19% buy cost\n",
    "    \"sell_cost_pct\": 0.0029, #IPOT has 0.29% sell cost\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = '2000-01-01'\n",
    "train_end = '2019-01-01'\n",
    "val_test_start = '2019-01-01'\n",
    "val_test_end = '2021-01-18'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed_full,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KsfEHa_Etj1d"
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      \"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 50_000,\n",
    "                      \"learning_rate\": 0.000005,\n",
    "                      \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 100_000, \n",
    "                 'ppo' : 100_000, \n",
    "                 'ddpg' : 50_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_1lyCECstj1e",
    "outputId": "72ac1ecc-909e-4d4c-d724-d906d7881ed9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  397.3376832837864\n",
      "======Model training from:  2000-01-01 to  2019-01-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_126_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 81.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -92.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 36.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 412      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 132      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -392     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 136      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.43e+06 |\n",
      "|    total_cost         | 4.12e+05 |\n",
      "|    total_reward       | 2.93e+06 |\n",
      "|    total_reward_pct   | 195      |\n",
      "|    total_trades       | 33046    |\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 153      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 52.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | -0.018   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 218      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 120      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -477     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 139      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.65e+06  |\n",
      "|    total_cost         | 1.09e+05  |\n",
      "|    total_reward       | 1.15e+06  |\n",
      "|    total_reward_pct   | 76.5      |\n",
      "|    total_trades       | 33676     |\n",
      "| time/                 |           |\n",
      "|    fps                | 46        |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 58.3      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.33      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0478   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -24.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -76.4    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -93.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0138  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 107      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 82       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.91e+06 |\n",
      "|    total_cost         | 1.21e+05 |\n",
      "|    total_reward       | 3.41e+06 |\n",
      "|    total_reward_pct   | 227      |\n",
      "|    total_trades       | 33174    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -46.8    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 195      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 28.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -309     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 56.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 453       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 222       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.92e+06 |\n",
      "|    total_cost         | 6.46e+04 |\n",
      "|    total_reward       | 2.42e+06 |\n",
      "|    total_reward_pct   | 162      |\n",
      "|    total_trades       | 32259    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 22.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.618    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 82.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 68.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0146  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 43.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 43.4     |\n",
      "------------------------------------\n",
      "day: 2232, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1452561.07\n",
      "total_reward: -47438.93\n",
      "total_cost: 30245.39\n",
      "total_trades: 30554\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.45e+06  |\n",
      "|    total_cost         | 3.02e+04  |\n",
      "|    total_reward       | -4.74e+04 |\n",
      "|    total_reward_pct   | -3.16     |\n",
      "|    total_trades       | 30554     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 242       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 69.3      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.61      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 252       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -166      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -54      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 8.2      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.3      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.42e+05  |\n",
      "|    total_cost         | 1.96e+04  |\n",
      "|    total_reward       | -5.58e+05 |\n",
      "|    total_reward_pct   | -37.2     |\n",
      "|    total_trades       | 28683     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 283       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -140      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 11.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -260     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 34       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -161     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 25.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 182      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -515      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 189       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.4e+06   |\n",
      "|    total_cost         | 1.75e+04  |\n",
      "|    total_reward       | -9.57e+04 |\n",
      "|    total_reward_pct   | -6.38     |\n",
      "|    total_trades       | 28075     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 336       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 48.7      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 346      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -191     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 24       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -252     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 37.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 367       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -145      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.32e+06  |\n",
      "|    total_cost         | 1.08e+04  |\n",
      "|    total_reward       | -1.81e+05 |\n",
      "|    total_reward_pct   | -12       |\n",
      "|    total_trades       | 26937     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 377       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -18.3     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.232     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 387      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -10.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.198    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 398      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 31.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.617    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 408      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 75.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 419      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -209     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 23.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.31e+05  |\n",
      "|    total_cost         | 7.67e+03  |\n",
      "|    total_reward       | -9.69e+05 |\n",
      "|    total_reward_pct   | -64.6     |\n",
      "|    total_trades       | 30857     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 429       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 47.3      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.38      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 440      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 27.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 45.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 450      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -8.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 460      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 382      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 123      |\n",
      "------------------------------------\n",
      "day: 2232, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2615047.52\n",
      "total_reward: 1115047.52\n",
      "total_cost: 19789.27\n",
      "total_trades: 32714\n",
      "Sharpe: 0.396\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.62e+06 |\n",
      "|    total_cost         | 1.98e+04 |\n",
      "|    total_reward       | 1.12e+06 |\n",
      "|    total_reward_pct   | 74.3     |\n",
      "|    total_trades       | 32714    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 470      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -42.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 481      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 54       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 491      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -45.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 502      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -2.36    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.049    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 512      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.194    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.95e+05 |\n",
      "|    total_cost         | 5.1e+03  |\n",
      "|    total_reward       | -1.2e+06 |\n",
      "|    total_reward_pct   | -80.3    |\n",
      "|    total_trades       | 32209    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 523      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 54.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 533      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 65.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 544      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 40.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 555      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -41.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.63     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.12e+06  |\n",
      "|    total_cost         | 1.32e+04  |\n",
      "|    total_reward       | -3.78e+05 |\n",
      "|    total_reward_pct   | -25.2     |\n",
      "|    total_trades       | 30394     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 565       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 121       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 10.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 576      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -58      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 586      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 139      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 9.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 596      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 607      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -30.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.42     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.22e+06  |\n",
      "|    total_cost         | 2.01e+04  |\n",
      "|    total_reward       | -2.81e+05 |\n",
      "|    total_reward_pct   | -18.7     |\n",
      "|    total_trades       | 29019     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 617       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -21.7     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.448     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 627      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 24       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.377    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 637       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 7.97      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.141     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 648      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 8.69     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0881   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.74e+05  |\n",
      "|    total_cost         | 1.16e+04  |\n",
      "|    total_reward       | -1.13e+06 |\n",
      "|    total_reward_pct   | -75       |\n",
      "|    total_trades       | 31386     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 658       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -37.9     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.81      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 669      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -41.1    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 679      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -133     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 690       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -613      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 201       |\n",
      "-------------------------------------\n",
      "day: 2232, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2301934.17\n",
      "total_reward: 801934.17\n",
      "total_cost: 25081.46\n",
      "total_trades: 32343\n",
      "Sharpe: 0.340\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.3e+06  |\n",
      "|    total_cost         | 2.51e+04 |\n",
      "|    total_reward       | 8.02e+05 |\n",
      "|    total_reward_pct   | 53.5     |\n",
      "|    total_trades       | 32343    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 700      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -13.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 710      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 12.5     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 721      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -31.4    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 731      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 2.29     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.254    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 741      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -144     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 13.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6e+05    |\n",
      "|    total_cost         | 1.21e+04 |\n",
      "|    total_reward       | -9e+05   |\n",
      "|    total_reward_pct   | -60      |\n",
      "|    total_trades       | 30777    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 752      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -58.8    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 4.22     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 762       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 129       |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 773      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -57.9    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 22.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 783      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -394     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 99.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.03e+06 |\n",
      "|    total_cost         | 2.28e+04 |\n",
      "|    total_reward       | 4.53e+06 |\n",
      "|    total_reward_pct   | 302      |\n",
      "|    total_trades       | 30022    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 793      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 16.4     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.999    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 804      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -36.9    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.45     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 814       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 134       |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 12        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 825      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 28.6     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 835      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -158     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 20.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.56e+06 |\n",
      "|    total_cost         | 1e+04    |\n",
      "|    total_reward       | 1.06e+06 |\n",
      "|    total_reward_pct   | 70.5     |\n",
      "|    total_trades       | 32103    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 846      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 33.3     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 856      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 9.96     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.555    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 866       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -17.9     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.323     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 877       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 305       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 54.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.96e+06 |\n",
      "|    total_cost         | 1.74e+04 |\n",
      "|    total_reward       | 1.46e+06 |\n",
      "|    total_reward_pct   | 97.5     |\n",
      "|    total_trades       | 34474    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 887      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 94.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 4.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 898      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 25.7     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.693    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 908      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 89.3     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 4.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 919      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -51.4    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 3.09     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 929       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 273       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 56.4      |\n",
      "-------------------------------------\n",
      "day: 2232, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2457490.94\n",
      "total_reward: 957490.94\n",
      "total_cost: 13750.53\n",
      "total_trades: 34729\n",
      "Sharpe: 0.399\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.46e+06 |\n",
      "|    total_cost         | 1.38e+04 |\n",
      "|    total_reward       | 9.57e+05 |\n",
      "|    total_reward_pct   | 63.8     |\n",
      "|    total_trades       | 34729    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 940      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0795   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 950      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -122     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 10       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 960      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -17.8    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 5.1      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 971       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -15       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.877     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.98e+06 |\n",
      "|    total_cost         | 1.44e+04 |\n",
      "|    total_reward       | 1.48e+06 |\n",
      "|    total_reward_pct   | 98.4     |\n",
      "|    total_trades       | 33141    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 981      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 59       |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 9.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 992      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 101      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 14.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 1002     |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 14.3     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.399    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 1013     |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 274      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 34.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 1023     |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -839     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 337      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.02e+06 |\n",
      "|    total_cost         | 1.35e+04 |\n",
      "|    total_reward       | 2.52e+06 |\n",
      "|    total_reward_pct   | 168      |\n",
      "|    total_trades       | 31637    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 1034     |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -4.43    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.0151   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 1044     |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 30.6     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.682    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 1055      |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -2.3      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.0289    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 1065     |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 112      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 6.18     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.14e+06  |\n",
      "|    total_cost         | 6.34e+03  |\n",
      "|    total_reward       | -3.56e+05 |\n",
      "|    total_reward_pct   | -23.7     |\n",
      "|    total_trades       | 31246     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 1076      |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -0.166    |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.272     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 1086     |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 23       |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 6.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 1096     |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -14.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 1107      |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | -709      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 282       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 1117     |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 290      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 125      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.96e+06 |\n",
      "|    total_cost         | 2.85e+04 |\n",
      "|    total_reward       | 3.46e+06 |\n",
      "|    total_reward_pct   | 230      |\n",
      "|    total_trades       | 32282    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 1128     |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -12.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.811    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 1138     |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 1148     |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -80.4    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 7.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 1158     |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -604     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 212      |\n",
      "------------------------------------\n",
      "day: 2232, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 4668485.77\n",
      "total_reward: 3168485.77\n",
      "total_cost: 29740.90\n",
      "total_trades: 33105\n",
      "Sharpe: 0.568\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.67e+06 |\n",
      "|    total_cost         | 2.97e+04 |\n",
      "|    total_reward       | 3.17e+06 |\n",
      "|    total_reward_pct   | 211      |\n",
      "|    total_trades       | 33105    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 1169     |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 48.9     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 1179     |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -15.4    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.435    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 1189     |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -20      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.338    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 1200     |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 1.23     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.287    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 1210     |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -441     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 140      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 8.56e+03 |\n",
      "|    total_reward       | 2.42e+04 |\n",
      "|    total_reward_pct   | 1.61     |\n",
      "|    total_trades       | 33076    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 1221     |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 120      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 14.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 1231     |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -61.5    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 1242     |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 71.5     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 1252      |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -120      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 7.75      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.74e+06 |\n",
      "|    total_cost         | 9.34e+03 |\n",
      "|    total_reward       | 2.4e+05  |\n",
      "|    total_reward_pct   | 16       |\n",
      "|    total_trades       | 33816    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 1263     |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -15.2    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 1274     |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 10.3     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0872   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 1285     |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 3.73     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 1296      |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -71.1     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 4.08      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 1307     |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 6.9      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.61e+05  |\n",
      "|    total_cost         | 5.62e+03  |\n",
      "|    total_reward       | -9.39e+05 |\n",
      "|    total_reward_pct   | -62.6     |\n",
      "|    total_trades       | 33424     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 1318      |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | 34.1      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.753     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 1329     |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -16.6    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.247    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 1340      |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -19.6     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.537     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 1351     |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 54.6     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.76e+06 |\n",
      "|    total_cost         | 7.36e+03 |\n",
      "|    total_reward       | 2.6e+05  |\n",
      "|    total_reward_pct   | 17.3     |\n",
      "|    total_trades       | 33964    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 1362     |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 40.8     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 1373     |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 85.4     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 4.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 1383     |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 143      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 1395     |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -168     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 15.5     |\n",
      "------------------------------------\n",
      "day: 2232, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1694838.71\n",
      "total_reward: 194838.71\n",
      "total_cost: 4198.16\n",
      "total_trades: 34168\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.69e+06 |\n",
      "|    total_cost         | 4.2e+03  |\n",
      "|    total_reward       | 1.95e+05 |\n",
      "|    total_reward_pct   | 13       |\n",
      "|    total_trades       | 34168    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 1406     |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0.147    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -855     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.89e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 1417     |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 5.84     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.0802   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 1427     |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 32.7     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 1437     |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -21.1    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 1441     |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 60       |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.84     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+06     |\n",
      "|    total_cost         | 4.18e+03  |\n",
      "|    total_reward       | -4.96e+05 |\n",
      "|    total_reward_pct   | -33       |\n",
      "|    total_trades       | 33557     |\n",
      "| time/                 |           |\n",
      "|    fps                | 48        |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 1445      |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | -98.8     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 6.27      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 48        |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 1456      |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -131      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 1467     |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -94.5    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 5.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 1478     |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 197      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 22.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.97e+06 |\n",
      "|    total_cost         | 7.19e+03 |\n",
      "|    total_reward       | 4.67e+05 |\n",
      "|    total_reward_pct   | 31.1     |\n",
      "|    total_trades       | 33178    |\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 1488     |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 77.4     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 3.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 1499     |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -58.1    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 1509     |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 8.46     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 1521     |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 30.9     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 1532     |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -51.3    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 6.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.17e+06 |\n",
      "|    total_cost         | 7.02e+03 |\n",
      "|    total_reward       | 6.72e+05 |\n",
      "|    total_reward_pct   | 44.8     |\n",
      "|    total_trades       | 34421    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 1542     |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 18.2     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.238    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 1553      |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | -38.6     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.88      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 1564     |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -131     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 1575     |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -206     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 23.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 1.08e+04 |\n",
      "|    total_reward       | 3.88e+05 |\n",
      "|    total_reward_pct   | 25.9     |\n",
      "|    total_trades       | 34624    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 1586     |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -14.4    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.206    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 1596     |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 47.6     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 1607     |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 39       |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 1618     |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 64.3     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 1629     |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -29.5    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "day: 2232, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1192583.51\n",
      "total_reward: -307416.49\n",
      "total_cost: 5883.50\n",
      "total_trades: 35827\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.19e+06  |\n",
      "|    total_cost         | 5.88e+03  |\n",
      "|    total_reward       | -3.07e+05 |\n",
      "|    total_reward_pct   | -20.5     |\n",
      "|    total_trades       | 35827     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 1639      |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | 25.7      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1         |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 1650     |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -22.7    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.609    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 1661     |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -9.1     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 1671     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -7.71    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0351   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.43e+06  |\n",
      "|    total_cost         | 4.79e+03  |\n",
      "|    total_reward       | -7.26e+04 |\n",
      "|    total_reward_pct   | -4.84     |\n",
      "|    total_trades       | 35627     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 1682      |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -97.4     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 5.91      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 1693     |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 54.4     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 2.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 1704     |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 30.2     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.877    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 1715      |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 9.12      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.261     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 1725      |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | 258       |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 40.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.16e+06  |\n",
      "|    total_cost         | 7.16e+03  |\n",
      "|    total_reward       | -3.41e+05 |\n",
      "|    total_reward_pct   | -22.7     |\n",
      "|    total_trades       | 36389     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 1736      |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | 56.5      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 2.44      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 1747     |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 61.5     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 1757     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -221     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 22.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 1768     |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -76.1    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 4.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.53e+06 |\n",
      "|    total_cost         | 2.86e+03 |\n",
      "|    total_reward       | 2.69e+04 |\n",
      "|    total_reward_pct   | 1.8      |\n",
      "|    total_trades       | 36083    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 1778     |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.196    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 1789     |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -25.1    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.403    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 1799     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -30.2    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.542    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 1810     |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -214     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 26.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 1820     |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 43.8     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.34e+06  |\n",
      "|    total_cost         | 3.83e+03  |\n",
      "|    total_reward       | -1.57e+05 |\n",
      "|    total_reward_pct   | -10.5     |\n",
      "|    total_trades       | 36470     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 1831      |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 18.7      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.658     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 1841     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 7.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 1852     |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -28.4    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.61     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 1863      |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 143       |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 15.2      |\n",
      "-------------------------------------\n",
      "day: 2232, episode: 40\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2876251.84\n",
      "total_reward: 1376251.84\n",
      "total_cost: 9877.43\n",
      "total_trades: 36889\n",
      "Sharpe: 0.434\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.88e+06 |\n",
      "|    total_cost         | 9.88e+03 |\n",
      "|    total_reward       | 1.38e+06 |\n",
      "|    total_reward_pct   | 91.8     |\n",
      "|    total_trades       | 36889    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 1874     |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -19.1    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.478    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 1885     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -19.5    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.44     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 1895      |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -9.51     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.248     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 1906     |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 25.5     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 2.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 1917     |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -54      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.39e+05  |\n",
      "|    total_cost         | 3.77e+03  |\n",
      "|    total_reward       | -6.61e+05 |\n",
      "|    total_reward_pct   | -44.1     |\n",
      "|    total_trades       | 36315     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 1927      |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -59.6     |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 3.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 1938     |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 17.3     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.695    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 1949     |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 91.9     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 7.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 1959     |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -60.6    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.5e+06  |\n",
      "|    total_cost         | 2.85e+03 |\n",
      "|    total_reward       | 3.59e+03 |\n",
      "|    total_reward_pct   | 0.24     |\n",
      "|    total_trades       | 35382    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 1970     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 138      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 1981     |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 10.3     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.699    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 1991      |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | 11.5      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.32      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 2003      |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 22.9      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.409     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 2014     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -50.8    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 3.13     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.91e+05  |\n",
      "|    total_cost         | 5.19e+03  |\n",
      "|    total_reward       | -6.09e+05 |\n",
      "|    total_reward_pct   | -40.6     |\n",
      "|    total_trades       | 34536     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 2025      |\n",
      "|    total_timesteps    | 96500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | 13.5      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.404     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 2035     |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 1.87     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.423    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 2046     |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -122     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 7.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 2057     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 126      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.77e+05  |\n",
      "|    total_cost         | 3.05e+03  |\n",
      "|    total_reward       | -6.23e+05 |\n",
      "|    total_reward_pct   | -41.5     |\n",
      "|    total_trades       | 34635     |\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 2068      |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 27.1      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.592     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 2079     |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.122    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 2089     |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -5.24    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.267    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 2100     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 33.2     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.61     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-01-02 to  2019-04-01\n",
      "A2C Sharpe Ratio:  0.2352575778643864\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_126_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 48   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 41   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.75e+04    |\n",
      "|    total_cost           | 6.97e+05    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.5       |\n",
      "|    total_trades         | 35769       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016700828 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00361     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.6         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.89        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.01e+04    |\n",
      "|    total_cost           | 8.7e+05     |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98         |\n",
      "|    total_trades         | 36446       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014563087 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0426      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.936       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 6.99        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 1.44e+06    |\n",
      "|    total_reward         | -1.4e+06    |\n",
      "|    total_reward_pct     | -93.3       |\n",
      "|    total_trades         | 37502       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019909754 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.5         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.91e+03    |\n",
      "|    total_cost           | 2.79e+05    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.5       |\n",
      "|    total_trades         | 34244       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018715011 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0356      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.3        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.16        |\n",
      "-----------------------------------------\n",
      "day: 2232, episode: 50\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 24950.12\n",
      "total_reward: -1475049.88\n",
      "total_cost: 784828.26\n",
      "total_trades: 35729\n",
      "Sharpe: 0.221\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.5e+04      |\n",
      "|    total_cost           | 7.85e+05     |\n",
      "|    total_reward         | -1.48e+06    |\n",
      "|    total_reward_pct     | -98.3        |\n",
      "|    total_trades         | 35729        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0144722825 |\n",
      "|    clip_fraction        | 0.21         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.9        |\n",
      "|    explained_variance   | 0.0961       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.179        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.27         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.57e+04    |\n",
      "|    total_cost           | 1.19e+06    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.6       |\n",
      "|    total_trades         | 36533       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022568265 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.81e+04    |\n",
      "|    total_cost           | 1.07e+06    |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.5       |\n",
      "|    total_trades         | 36253       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021610351 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.959       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.43e+04    |\n",
      "|    total_cost           | 9.84e+05    |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -94.4       |\n",
      "|    total_trades         | 36228       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019441059 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0708      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.514       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.64e+04    |\n",
      "|    total_cost           | 4.94e+05    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.9       |\n",
      "|    total_trades         | 35028       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015592787 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0887      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.08        |\n",
      "-----------------------------------------\n",
      "day: 2232, episode: 55\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 123763.57\n",
      "total_reward: -1376236.43\n",
      "total_cost: 490561.96\n",
      "total_trades: 34886\n",
      "Sharpe: -0.094\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.24e+05    |\n",
      "|    total_cost           | 4.91e+05    |\n",
      "|    total_reward         | -1.38e+06   |\n",
      "|    total_reward_pct     | -91.7       |\n",
      "|    total_trades         | 34886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024530733 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0907      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0613     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.31e+05    |\n",
      "|    total_cost           | 7.2e+05     |\n",
      "|    total_reward         | -1.37e+06   |\n",
      "|    total_reward_pct     | -91.3       |\n",
      "|    total_trades         | 35604       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037734658 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.526       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 543         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029813865 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0862      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.733       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.41e+04    |\n",
      "|    total_cost           | 1.61e+06    |\n",
      "|    total_reward         | -1.41e+06   |\n",
      "|    total_reward_pct     | -93.7       |\n",
      "|    total_trades         | 37113       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017757941 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.33        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.12e+05    |\n",
      "|    total_cost           | 1.93e+06    |\n",
      "|    total_reward         | -1.29e+06   |\n",
      "|    total_reward_pct     | -85.9       |\n",
      "|    total_trades         | 37951       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 627         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029403945 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.061       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.57        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.00486     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.39e+05    |\n",
      "|    total_cost           | 1.51e+06    |\n",
      "|    total_reward         | -1.36e+06   |\n",
      "|    total_reward_pct     | -90.8       |\n",
      "|    total_trades         | 36956       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 671         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034480907 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0715      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.95        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "day: 2232, episode: 60\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 12045.69\n",
      "total_reward: -1487954.31\n",
      "total_cost: 668316.52\n",
      "total_trades: 35201\n",
      "Sharpe: -0.779\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+04     |\n",
      "|    total_cost           | 6.68e+05    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.2       |\n",
      "|    total_trades         | 35201       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015061133 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.429       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.12        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.28e+04     |\n",
      "|    total_cost           | 1.46e+06     |\n",
      "|    total_reward         | -1.41e+06    |\n",
      "|    total_reward_pct     | -93.8        |\n",
      "|    total_trades         | 36680        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 757          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051321797 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.8        |\n",
      "|    explained_variance   | 0.0759       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.48         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00896     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 8.98         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.42e+04    |\n",
      "|    total_cost           | 3.56e+05    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.1       |\n",
      "|    total_trades         | 34164       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 799         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016384251 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.14e+05    |\n",
      "|    total_cost           | 1.33e+06    |\n",
      "|    total_reward         | -1.29e+06   |\n",
      "|    total_reward_pct     | -85.7       |\n",
      "|    total_trades         | 36264       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 841         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016048145 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.31e+05    |\n",
      "|    total_cost           | 1.44e+06    |\n",
      "|    total_reward         | -1.37e+06   |\n",
      "|    total_reward_pct     | -91.3       |\n",
      "|    total_trades         | 36618       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 884         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012721106 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.17        |\n",
      "-----------------------------------------\n",
      "day: 2232, episode: 65\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 181554.13\n",
      "total_reward: -1318445.87\n",
      "total_cost: 1822749.54\n",
      "total_trades: 37395\n",
      "Sharpe: -0.461\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.82e+05    |\n",
      "|    total_cost           | 1.82e+06    |\n",
      "|    total_reward         | -1.32e+06   |\n",
      "|    total_reward_pct     | -87.9       |\n",
      "|    total_trades         | 37395       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 926         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013511604 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.74        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.97e+03    |\n",
      "|    total_cost           | 3.67e+05    |\n",
      "|    total_reward         | -1.5e+06    |\n",
      "|    total_reward_pct     | -99.8       |\n",
      "|    total_trades         | 34473       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 968         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009189526 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.95        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.39e+04    |\n",
      "|    total_cost           | 3.72e+05    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.1       |\n",
      "|    total_trades         | 34327       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1010        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015871732 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0042     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 7.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 1052        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004473353 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.298      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.07e+04    |\n",
      "|    total_cost           | 1.05e+06    |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -94.6       |\n",
      "|    total_trades         | 35693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1094        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010632718 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0475      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.785       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 3.73        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.34e+05     |\n",
      "|    total_cost           | 1.59e+06     |\n",
      "|    total_reward         | -1.37e+06    |\n",
      "|    total_reward_pct     | -91          |\n",
      "|    total_trades         | 37231        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 1138         |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077179223 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.6        |\n",
      "|    explained_variance   | 0.0898       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.88         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 9.26         |\n",
      "------------------------------------------\n",
      "day: 2232, episode: 70\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 243330.59\n",
      "total_reward: -1256669.41\n",
      "total_cost: 1399309.03\n",
      "total_trades: 36485\n",
      "Sharpe: 0.043\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.43e+05    |\n",
      "|    total_cost           | 1.4e+06     |\n",
      "|    total_reward         | -1.26e+06   |\n",
      "|    total_reward_pct     | -83.8       |\n",
      "|    total_trades         | 36485       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1180        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015051229 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.87        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.19e+04   |\n",
      "|    total_cost           | 1.29e+06   |\n",
      "|    total_reward         | -1.45e+06  |\n",
      "|    total_reward_pct     | -96.5      |\n",
      "|    total_trades         | 36339      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 1222       |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01086098 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.13       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 12         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.82e+05    |\n",
      "|    total_cost           | 1.55e+06    |\n",
      "|    total_reward         | -1.32e+06   |\n",
      "|    total_reward_pct     | -87.8       |\n",
      "|    total_trades         | 36729       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1265        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010012345 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.15        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.08e+05     |\n",
      "|    total_cost           | 2.49e+06     |\n",
      "|    total_reward         | -7.92e+05    |\n",
      "|    total_reward_pct     | -52.8        |\n",
      "|    total_trades         | 38559        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 1308         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110006295 |\n",
      "|    clip_fraction        | 0.0999       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.9        |\n",
      "|    explained_variance   | 0.103        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00923     |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.15e+04    |\n",
      "|    total_cost           | 8.25e+05    |\n",
      "|    total_reward         | -1.41e+06   |\n",
      "|    total_reward_pct     | -93.9       |\n",
      "|    total_trades         | 35569       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1352        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012285782 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.04        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "day: 2232, episode: 75\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 72280.13\n",
      "total_reward: -1427719.87\n",
      "total_cost: 668443.50\n",
      "total_trades: 35363\n",
      "Sharpe: -0.317\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.23e+04    |\n",
      "|    total_cost           | 6.68e+05    |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.2       |\n",
      "|    total_trades         | 35363       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1396        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015571455 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.65        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 8.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.67e+05    |\n",
      "|    total_cost           | 2.03e+06    |\n",
      "|    total_reward         | -5.33e+05   |\n",
      "|    total_reward_pct     | -35.6       |\n",
      "|    total_trades         | 37776       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1439        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016944852 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.81        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.85e+05    |\n",
      "|    total_cost           | 1.77e+06    |\n",
      "|    total_reward         | -5.15e+05   |\n",
      "|    total_reward_pct     | -34.4       |\n",
      "|    total_trades         | 37539       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1483        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020755472 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 85.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.22e+05    |\n",
      "|    total_cost           | 1.84e+06    |\n",
      "|    total_reward         | -8.78e+05   |\n",
      "|    total_reward_pct     | -58.5       |\n",
      "|    total_trades         | 37731       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1526        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012739841 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1569        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012962231 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.29e+04    |\n",
      "|    total_cost           | 7.94e+05    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.1       |\n",
      "|    total_trades         | 35930       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1612        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008100893 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 4.87        |\n",
      "-----------------------------------------\n",
      "day: 2232, episode: 80\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1912472.26\n",
      "total_reward: 412472.26\n",
      "total_cost: 1471110.73\n",
      "total_trades: 37404\n",
      "Sharpe: 0.325\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.91e+06   |\n",
      "|    total_cost           | 1.47e+06   |\n",
      "|    total_reward         | 4.12e+05   |\n",
      "|    total_reward_pct     | 27.5       |\n",
      "|    total_trades         | 37404      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 1654       |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01087584 |\n",
      "|    clip_fraction        | 0.0708     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.2      |\n",
      "|    explained_variance   | 0.208      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 102        |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00887   |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 191        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.59e+06     |\n",
      "|    total_cost           | 1.68e+06     |\n",
      "|    total_reward         | 8.91e+04     |\n",
      "|    total_reward_pct     | 5.94         |\n",
      "|    total_trades         | 37365        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 1697         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100960005 |\n",
      "|    clip_fraction        | 0.0898       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.3        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 192          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.53e+05    |\n",
      "|    total_cost           | 8.09e+05    |\n",
      "|    total_reward         | -1.35e+06   |\n",
      "|    total_reward_pct     | -89.8       |\n",
      "|    total_trades         | 36090       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1739        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013106398 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.05e+05    |\n",
      "|    total_cost           | 1.75e+06    |\n",
      "|    total_reward         | -5.95e+05   |\n",
      "|    total_reward_pct     | -39.6       |\n",
      "|    total_trades         | 37171       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1782        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015844237 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.84e+05    |\n",
      "|    total_cost           | 8.39e+05    |\n",
      "|    total_reward         | -1.22e+06   |\n",
      "|    total_reward_pct     | -81         |\n",
      "|    total_trades         | 36236       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1825        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015571021 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "day: 2232, episode: 85\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 166510.71\n",
      "total_reward: -1333489.29\n",
      "total_cost: 842193.26\n",
      "total_trades: 35992\n",
      "Sharpe: -0.226\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.67e+05     |\n",
      "|    total_cost           | 8.42e+05     |\n",
      "|    total_reward         | -1.33e+06    |\n",
      "|    total_reward_pct     | -88.9        |\n",
      "|    total_trades         | 35992        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 1869         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090803765 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.5        |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.81         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+06    |\n",
      "|    total_cost           | 9.63e+05    |\n",
      "|    total_reward         | -1.64e+05   |\n",
      "|    total_reward_pct     | -10.9       |\n",
      "|    total_trades         | 35897       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1911        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019443877 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.52e+06    |\n",
      "|    total_cost           | 1.03e+06    |\n",
      "|    total_reward         | 1.52e+04    |\n",
      "|    total_reward_pct     | 1.01        |\n",
      "|    total_trades         | 36342       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1953        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009674601 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.58e+06    |\n",
      "|    total_cost           | 1.19e+06    |\n",
      "|    total_reward         | 3.08e+06    |\n",
      "|    total_reward_pct     | 205         |\n",
      "|    total_trades         | 36362       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1995        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008857004 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.81e+05   |\n",
      "|    total_cost           | 7.8e+05    |\n",
      "|    total_reward         | -1.32e+06  |\n",
      "|    total_reward_pct     | -87.9      |\n",
      "|    total_trades         | 35697      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 2037       |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00696156 |\n",
      "|    clip_fraction        | 0.0578     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.6      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 567        |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00685   |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 1.2e+03    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 2079        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008397084 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.15        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-01-02 to  2019-04-01\n",
      "PPO Sharpe Ratio:  0.021855746972372733\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_126_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.52e+06 |\n",
      "|    total_cost       | 3.94e+03 |\n",
      "|    total_reward     | 1.56e+04 |\n",
      "|    total_reward_pct | 1.04     |\n",
      "|    total_trades     | 32368    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 20       |\n",
      "|    time_elapsed     | 436      |\n",
      "|    total timesteps  | 8932     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 421      |\n",
      "|    critic_loss      | 85.8     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6699     |\n",
      "----------------------------------\n",
      "day: 2232, episode: 95\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1886620.76\n",
      "total_reward: 386620.76\n",
      "total_cost: 3661.28\n",
      "total_trades: 32365\n",
      "Sharpe: 0.425\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.61e+06 |\n",
      "|    total_cost       | 4.33e+03 |\n",
      "|    total_reward     | 1.11e+06 |\n",
      "|    total_reward_pct | 74       |\n",
      "|    total_trades     | 32365    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 1032     |\n",
      "|    total timesteps  | 17864    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 263      |\n",
      "|    critic_loss      | 47.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 15631    |\n",
      "----------------------------------\n",
      "day: 2232, episode: 100\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1325538.45\n",
      "total_reward: -174461.55\n",
      "total_cost: 3013.84\n",
      "total_trades: 32365\n",
      "Sharpe: 0.274\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.46e+06  |\n",
      "|    total_cost       | 3.05e+03  |\n",
      "|    total_reward     | -3.81e+04 |\n",
      "|    total_reward_pct | -2.54     |\n",
      "|    total_trades     | 32364     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 19        |\n",
      "|    time_elapsed     | 1357      |\n",
      "|    total timesteps  | 26796     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 165       |\n",
      "|    critic_loss      | 68.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 24563     |\n",
      "-----------------------------------\n",
      "day: 2232, episode: 105\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1499625.69\n",
      "total_reward: -374.31\n",
      "total_cost: 2844.59\n",
      "total_trades: 32363\n",
      "Sharpe: 0.203\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 9.86e+05  |\n",
      "|    total_cost       | 3.23e+03  |\n",
      "|    total_reward     | -5.14e+05 |\n",
      "|    total_reward_pct | -34.3     |\n",
      "|    total_trades     | 32366     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 20        |\n",
      "|    time_elapsed     | 1729      |\n",
      "|    total timesteps  | 35728     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 102       |\n",
      "|    critic_loss      | 46.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 33495     |\n",
      "-----------------------------------\n",
      "day: 2232, episode: 110\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1115393.02\n",
      "total_reward: -384606.98\n",
      "total_cost: 3686.47\n",
      "total_trades: 32365\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.12e+06  |\n",
      "|    total_cost       | 3.69e+03  |\n",
      "|    total_reward     | -3.85e+05 |\n",
      "|    total_reward_pct | -25.6     |\n",
      "|    total_trades     | 32365     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 21        |\n",
      "|    time_elapsed     | 2039      |\n",
      "|    total timesteps  | 44660     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 62.5      |\n",
      "|    critic_loss      | 44.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 42427     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-01-02 to  2019-04-01\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-04-01\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ensemble_126_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.71e+06 |\n",
      "|    total_cost       | 3.74e+03 |\n",
      "|    total_reward     | 2.09e+05 |\n",
      "|    total_reward_pct | 13.9     |\n",
      "|    total_trades     | 22073    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total timesteps  | 9184     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 169      |\n",
      "|    critic_loss      | 150      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 6888     |\n",
      "----------------------------------\n",
      "day: 2295, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1536248.03\n",
      "total_reward: 36248.03\n",
      "total_cost: 2892.81\n",
      "total_trades: 22249\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.33e+06 |\n",
      "|    total_cost       | 7.05e+03 |\n",
      "|    total_reward     | 1.83e+06 |\n",
      "|    total_reward_pct | 122      |\n",
      "|    total_trades     | 22246    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 557      |\n",
      "|    total timesteps  | 18368    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 104      |\n",
      "|    critic_loss      | 103      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16072    |\n",
      "----------------------------------\n",
      "day: 2295, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2388863.96\n",
      "total_reward: 888863.96\n",
      "total_cost: 5369.18\n",
      "total_trades: 22208\n",
      "Sharpe: 0.364\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.85e+06 |\n",
      "|    total_cost       | 6.47e+03 |\n",
      "|    total_reward     | 1.35e+06 |\n",
      "|    total_reward_pct | 89.7     |\n",
      "|    total_trades     | 22192    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 986      |\n",
      "|    total timesteps  | 27552    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 63.1     |\n",
      "|    critic_loss      | 63.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25256    |\n",
      "----------------------------------\n",
      "day: 2295, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1518522.34\n",
      "total_reward: 18522.34\n",
      "total_cost: 2878.45\n",
      "total_trades: 21885\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.26e+06 |\n",
      "|    total_cost       | 4.72e+03 |\n",
      "|    total_reward     | 7.63e+05 |\n",
      "|    total_reward_pct | 50.9     |\n",
      "|    total_trades     | 20937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 25       |\n",
      "|    time_elapsed     | 1421     |\n",
      "|    total timesteps  | 36736    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 37.2     |\n",
      "|    critic_loss      | 60.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 34440    |\n",
      "----------------------------------\n",
      "day: 2295, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2275315.73\n",
      "total_reward: 775315.73\n",
      "total_cost: 6276.45\n",
      "total_trades: 21052\n",
      "Sharpe: 0.330\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.28e+06 |\n",
      "|    total_cost       | 6.28e+03 |\n",
      "|    total_reward     | 7.75e+05 |\n",
      "|    total_reward_pct | 51.7     |\n",
      "|    total_trades     | 21052    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 24       |\n",
      "|    time_elapsed     | 1862     |\n",
      "|    total timesteps  | 45920    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 21.3     |\n",
      "|    critic_loss      | 85.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43624    |\n",
      "----------------------------------\n",
      "======Trading from:  2019-04-01 to  2019-06-27\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  397.3376832837864\n",
      "======Model training from:  2000-01-01 to  2019-04-01\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_189_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -51.6    |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 3.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 93.5     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 46.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 147      |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 219      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 2.59e+03  |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 4.23e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.33e+07  |\n",
      "|    total_cost         | 1.04e+06  |\n",
      "|    total_reward       | 1.18e+07  |\n",
      "|    total_reward_pct   | 787       |\n",
      "|    total_trades       | 35898     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -23.7     |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 0.816     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -27.8    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 0.682    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 348      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 75.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -603     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 417      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 72.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.53e+06 |\n",
      "|    total_cost         | 1.39e+05 |\n",
      "|    total_reward       | 8.03e+06 |\n",
      "|    total_reward_pct   | 536      |\n",
      "|    total_trades       | 30786    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -48      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -281     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 51.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -89.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -821     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 411      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.89e+06  |\n",
      "|    total_cost         | 1.67e+05  |\n",
      "|    total_reward       | 5.39e+06  |\n",
      "|    total_reward_pct   | 359       |\n",
      "|    total_trades       | 31809     |\n",
      "| time/                 |           |\n",
      "|    fps                | 58        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -37.5     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.93      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 2.21     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 24       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 606      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 218      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 192      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 30.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 1.21e+03 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 937      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.56e+06  |\n",
      "|    total_cost         | 2.52e+06  |\n",
      "|    total_reward       | 4.06e+06  |\n",
      "|    total_reward_pct   | 271       |\n",
      "|    total_trades       | 37081     |\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 88.4      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 5.62      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 72.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 49.9     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 3.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 105      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 54.2     |\n",
      "------------------------------------\n",
      "day: 2295, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 14646361.83\n",
      "total_reward: 13146361.83\n",
      "total_cost: 1405303.16\n",
      "total_trades: 38122\n",
      "Sharpe: 0.812\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.46e+07 |\n",
      "|    total_cost         | 1.41e+06 |\n",
      "|    total_reward       | 1.31e+07 |\n",
      "|    total_reward_pct   | 876      |\n",
      "|    total_trades       | 38122    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -41      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 29.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.508    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -3.54    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0125   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 154      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 49        |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 274       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -178      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 22.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.89e+06 |\n",
      "|    total_cost         | 2.65e+05 |\n",
      "|    total_reward       | 3.89e+05 |\n",
      "|    total_reward_pct   | 25.9     |\n",
      "|    total_trades       | 35653    |\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -25.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -166     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 20.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 48        |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 307       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 53.9      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.32      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -14.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.474    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 303      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 54.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.2e+05  |\n",
      "|    total_cost         | 3.95e+04 |\n",
      "|    total_reward       | -6.8e+05 |\n",
      "|    total_reward_pct   | -45.3    |\n",
      "|    total_trades       | 35320    |\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -240     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 32.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 46        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 368       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -76.5     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.64      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 381      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 30       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 390      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -19.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.824    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.17e+06 |\n",
      "|    total_cost         | 3.1e+04  |\n",
      "|    total_reward       | -3.3e+05 |\n",
      "|    total_reward_pct   | -22      |\n",
      "|    total_trades       | 36054    |\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 399      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 16.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.584    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 46        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 409       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -33.4     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 46        |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 417       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -58.4     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.26      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 429      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -46.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 446      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 276      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 41.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.06e+06  |\n",
      "|    total_cost         | 2.54e+04  |\n",
      "|    total_reward       | -4.41e+05 |\n",
      "|    total_reward_pct   | -29.4     |\n",
      "|    total_trades       | 36009     |\n",
      "| time/                 |           |\n",
      "|    fps                | 45        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 460       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -9.16     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.71      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 471      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 74       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 487      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 175      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 21.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 505      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -79.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "day: 2295, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2686794.36\n",
      "total_reward: 1186794.36\n",
      "total_cost: 9881.70\n",
      "total_trades: 34316\n",
      "Sharpe: 0.376\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.69e+06 |\n",
      "|    total_cost         | 9.88e+03 |\n",
      "|    total_reward       | 1.19e+06 |\n",
      "|    total_reward_pct   | 79.1     |\n",
      "|    total_trades       | 34316    |\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 520      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -27.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.482    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 529      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 15.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 538      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -50.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 549      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 46.1     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 558      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 17.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.404    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.47e+06  |\n",
      "|    total_cost         | 1.44e+04  |\n",
      "|    total_reward       | -3.06e+04 |\n",
      "|    total_reward_pct   | -2.04     |\n",
      "|    total_trades       | 34742     |\n",
      "| time/                 |           |\n",
      "|    fps                | 45        |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 566       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 63.1      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.97      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 574      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 177      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 583      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -34.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 16.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 592      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 47.6     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 45        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 603       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -45.7     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 5.67      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.03e+06 |\n",
      "|    total_cost         | 1.39e+04 |\n",
      "|    total_reward       | 1.53e+06 |\n",
      "|    total_reward_pct   | 102      |\n",
      "|    total_trades       | 36153    |\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 612      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 621      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -117     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 9.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 631      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -67.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.24     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 45        |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 642       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -25.9     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 8.11      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 3.87e+03 |\n",
      "|    total_reward       | 1.53e+04 |\n",
      "|    total_reward_pct   | 1.02     |\n",
      "|    total_trades       | 39008    |\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 651      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -20.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.226    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 660      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -7.46    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0538   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 668      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -8.27    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0654   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 46        |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 676       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 1.95      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0301    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 684      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -35.7    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.867    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.84e+05  |\n",
      "|    total_cost         | 5.28e+03  |\n",
      "|    total_reward       | -1.22e+06 |\n",
      "|    total_reward_pct   | -81.1     |\n",
      "|    total_trades       | 36794     |\n",
      "| time/                 |           |\n",
      "|    fps                | 46        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 691       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 51.3      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.78      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 699      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 96.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 708      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 211      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 21.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 717      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 124      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 18.6     |\n",
      "------------------------------------\n",
      "day: 2295, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2857069.98\n",
      "total_reward: 1357069.98\n",
      "total_cost: 29706.56\n",
      "total_trades: 38435\n",
      "Sharpe: 0.403\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.86e+06 |\n",
      "|    total_cost         | 2.97e+04 |\n",
      "|    total_reward       | 1.36e+06 |\n",
      "|    total_reward_pct   | 90.5     |\n",
      "|    total_trades       | 38435    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 728      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 42.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 737      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -5.88    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0731   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 747      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 32.4     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.859    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 756      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 7.05     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 47        |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 763       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -6.65     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.0266    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.97e+05  |\n",
      "|    total_cost         | 8.52e+03  |\n",
      "|    total_reward       | -7.03e+05 |\n",
      "|    total_reward_pct   | -46.9     |\n",
      "|    total_trades       | 39359     |\n",
      "| time/                 |           |\n",
      "|    fps                | 48        |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 770       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -191      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 17.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 777      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -8.24    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0647   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 785      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 2.19     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0583   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 793      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -18.3    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.368    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 801      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -22.9    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.759    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.79e+05  |\n",
      "|    total_cost         | 1.12e+04  |\n",
      "|    total_reward       | -6.21e+05 |\n",
      "|    total_reward_pct   | -41.4     |\n",
      "|    total_trades       | 39270     |\n",
      "| time/                 |           |\n",
      "|    fps                | 48        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 809       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -55       |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.61      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 816      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 54.4     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 823      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 98.6     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 5.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 831      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 67.7     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.79     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.42e+05  |\n",
      "|    total_cost         | 5.39e+03  |\n",
      "|    total_reward       | -8.58e+05 |\n",
      "|    total_reward_pct   | -57.2     |\n",
      "|    total_trades       | 37821     |\n",
      "| time/                 |           |\n",
      "|    fps                | 49        |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 837       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -26.1     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.553     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 49        |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 844       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 21        |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.259     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 850      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -37.8    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 50       |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 856      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -48      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 50       |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 862      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 64.1     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.23e+05  |\n",
      "|    total_cost         | 3.06e+03  |\n",
      "|    total_reward       | -5.77e+05 |\n",
      "|    total_reward_pct   | -38.4     |\n",
      "|    total_trades       | 35641     |\n",
      "| time/                 |           |\n",
      "|    fps                | 50        |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 868       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 20.5      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.391     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 50        |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 874       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -9.09     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 879       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -15.5     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.273     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 885      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -48.2    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "day: 2295, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 856501.13\n",
      "total_reward: -643498.87\n",
      "total_cost: 4415.87\n",
      "total_trades: 35847\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.57e+05  |\n",
      "|    total_cost         | 4.42e+03  |\n",
      "|    total_reward       | -6.43e+05 |\n",
      "|    total_reward_pct   | -42.9     |\n",
      "|    total_trades       | 35847     |\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 891       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 31.1      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.922     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 897      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 137      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 9.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 903      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 54.3     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 909      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 50.2     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 915      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 194      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 25       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.4e+06   |\n",
      "|    total_cost         | 7.6e+03   |\n",
      "|    total_reward       | -1.01e+05 |\n",
      "|    total_reward_pct   | -6.76     |\n",
      "|    total_trades       | 35432     |\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 922       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -33.4     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.815     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 928      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 115      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 7.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 935      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 98.1     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 6.55     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 53        |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 941       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 56.4      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 3.96      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 947      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -61.3    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 6.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.54e+06 |\n",
      "|    total_cost         | 3.71e+03 |\n",
      "|    total_reward       | 3.65e+04 |\n",
      "|    total_reward_pct   | 2.43     |\n",
      "|    total_trades       | 35378    |\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 952      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 9.78     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.167    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 957      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 27.9     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.487    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 963      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -44.8    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 969      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 58.6     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.7      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.06e+05  |\n",
      "|    total_cost         | 4.98e+03  |\n",
      "|    total_reward       | -1.09e+06 |\n",
      "|    total_reward_pct   | -72.9     |\n",
      "|    total_trades       | 36731     |\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 974       |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | -26.2     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.459     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 980       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | 17.6      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.224     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 986      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 37.3     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 992       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -41.1     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 999      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | -0.00365 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -152     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 17.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.21e+06  |\n",
      "|    total_cost         | 1.87e+04  |\n",
      "|    total_reward       | -2.87e+05 |\n",
      "|    total_reward_pct   | -19.1     |\n",
      "|    total_trades       | 38018     |\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 1005      |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -90.5     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 3.68      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 1011      |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | -94.7     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 5.01      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 1017     |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -63.1    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 1023     |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -32.7    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "day: 2295, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1627851.96\n",
      "total_reward: 127851.96\n",
      "total_cost: 10621.50\n",
      "total_trades: 38110\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.63e+06 |\n",
      "|    total_cost         | 1.06e+04 |\n",
      "|    total_reward       | 1.28e+05 |\n",
      "|    total_reward_pct   | 8.52     |\n",
      "|    total_trades       | 38110    |\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 1028     |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -207     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 25.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 1034     |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -213     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 25       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 1039     |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -15.4    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 1045     |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 17.2     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.589    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 1051     |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -96.1    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 4.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.73e+06 |\n",
      "|    total_cost         | 1.95e+04 |\n",
      "|    total_reward       | 2.25e+05 |\n",
      "|    total_reward_pct   | 15       |\n",
      "|    total_trades       | 37511    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 1057     |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 35.1     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.673    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 1064     |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 121      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 9.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 1074     |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -5.72    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.161    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 1083     |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -192     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 26.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.34e+06  |\n",
      "|    total_cost         | 3.51e+03  |\n",
      "|    total_reward       | -1.61e+05 |\n",
      "|    total_reward_pct   | -10.8     |\n",
      "|    total_trades       | 36960     |\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 1090      |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | 0.167     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -912      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.73e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 1098     |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 78.7     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 4.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 1105     |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 7.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 1112     |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 169      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 1118     |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 150      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.18e+06 |\n",
      "|    total_cost         | 8.4e+03  |\n",
      "|    total_reward       | -3.2e+05 |\n",
      "|    total_reward_pct   | -21.3    |\n",
      "|    total_trades       | 36967    |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 1124     |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 99.6     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 5.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 1130     |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -125     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 9.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 1135     |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -41.7    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 1141     |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -121     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 7.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 1148     |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -456     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 153      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.5e+06   |\n",
      "|    total_cost         | 2.85e+03  |\n",
      "|    total_reward       | -1.13e+03 |\n",
      "|    total_reward_pct   | -0.0756   |\n",
      "|    total_trades       | 36099     |\n",
      "| time/                 |           |\n",
      "|    fps                | 58        |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 1153      |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | 40.9      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.16      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 1159     |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 119      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 8.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 1165     |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 49       |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 1170     |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 8.73     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.114    |\n",
      "------------------------------------\n",
      "day: 2295, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 548338.74\n",
      "total_reward: -951661.26\n",
      "total_cost: 4521.73\n",
      "total_trades: 36692\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.48e+05  |\n",
      "|    total_cost         | 4.52e+03  |\n",
      "|    total_reward       | -9.52e+05 |\n",
      "|    total_reward_pct   | -63.4     |\n",
      "|    total_trades       | 36692     |\n",
      "| time/                 |           |\n",
      "|    fps                | 58        |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 1177      |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 26.1      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.5       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 1183     |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 62.7     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 5.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 1189     |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 62.3     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 4.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 1196     |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -18.3    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.553    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 1203     |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 7.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.2e+06   |\n",
      "|    total_cost         | 7.66e+03  |\n",
      "|    total_reward       | -3.03e+05 |\n",
      "|    total_reward_pct   | -20.2     |\n",
      "|    total_trades       | 37245     |\n",
      "| time/                 |           |\n",
      "|    fps                | 59        |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 1210      |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | -9.62     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.0494    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 1216     |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 9.73     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.124    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 59        |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 1222      |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -1.18     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.0554    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 1229     |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 11.8     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0829   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.85e+05  |\n",
      "|    total_cost         | 6.9e+03   |\n",
      "|    total_reward       | -1.02e+06 |\n",
      "|    total_reward_pct   | -67.7     |\n",
      "|    total_trades       | 37523     |\n",
      "| time/                 |           |\n",
      "|    fps                | 59        |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 1235      |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | 76.2      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 4.49      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 1242     |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 25.5     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.481    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 1248     |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 94.4     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 6.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 1255     |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 69.8     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 6.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 1260     |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -152     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.01e+06 |\n",
      "|    total_cost         | 1.27e+04 |\n",
      "|    total_reward       | 5.14e+05 |\n",
      "|    total_reward_pct   | 34.3     |\n",
      "|    total_trades       | 38036    |\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 1267     |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 57.9     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 1273     |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 50.4     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 1280     |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -25      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.341    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 1287     |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -2.86    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.0687   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 1294      |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | 49.2      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 2.25      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.13e+05  |\n",
      "|    total_cost         | 8.29e+03  |\n",
      "|    total_reward       | -6.87e+05 |\n",
      "|    total_reward_pct   | -45.8     |\n",
      "|    total_trades       | 38453     |\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 1300      |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -25       |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 3.47      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 1307     |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 23.5     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.567    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 1313     |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -5.94    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 1321      |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | 45.7      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.15      |\n",
      "-------------------------------------\n",
      "day: 2295, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1148268.43\n",
      "total_reward: -351731.57\n",
      "total_cost: 18131.43\n",
      "total_trades: 38270\n",
      "Sharpe: 0.214\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.15e+06  |\n",
      "|    total_cost         | 1.81e+04  |\n",
      "|    total_reward       | -3.52e+05 |\n",
      "|    total_reward_pct   | -23.4     |\n",
      "|    total_trades       | 38270     |\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 1330      |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 48.4      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.86      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 1343     |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -105     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 8.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 1350     |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -43.3    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 1357     |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 47.9     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 4.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 1363     |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -23.1    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 30.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.81e+06 |\n",
      "|    total_cost         | 1.02e+04 |\n",
      "|    total_reward       | 3.1e+05  |\n",
      "|    total_reward_pct   | 20.7     |\n",
      "|    total_trades       | 37312    |\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 1371     |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -14.9    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.476    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 1378     |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 7.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 1385     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 3.34     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 1392     |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -7.9     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0347   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.21e+05  |\n",
      "|    total_cost         | 1.81e+04  |\n",
      "|    total_reward       | -8.79e+05 |\n",
      "|    total_reward_pct   | -58.6     |\n",
      "|    total_trades       | 37280     |\n",
      "| time/                 |           |\n",
      "|    fps                | 60        |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 1398      |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | 0.808     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.0352    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 1404     |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 4.35     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 1410     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 5.15     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0205   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 1415     |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 0.119    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0027   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 1421     |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 5.32     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.17e+06  |\n",
      "|    total_cost         | 3.32e+03  |\n",
      "|    total_reward       | -3.34e+05 |\n",
      "|    total_reward_pct   | -22.3     |\n",
      "|    total_trades       | 36384     |\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 1426      |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 32.4      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 1.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 1431     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 26.3     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.459    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 1436     |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -73.8    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 2.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 1442     |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 5.58     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 1447      |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | 61.2      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 2.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.81e+05  |\n",
      "|    total_cost         | 1.18e+04  |\n",
      "|    total_reward       | -6.19e+05 |\n",
      "|    total_reward_pct   | -41.2     |\n",
      "|    total_trades       | 35234     |\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 1453      |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | -194      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 21.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 1459      |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -33.3     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 1.46      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 1464     |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -121     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 8.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 1470     |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 7.84     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "day: 2295, episode: 40\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1633302.02\n",
      "total_reward: 133302.02\n",
      "total_cost: 6970.70\n",
      "total_trades: 34093\n",
      "Sharpe: 0.274\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.63e+06  |\n",
      "|    total_cost         | 6.97e+03  |\n",
      "|    total_reward       | 1.33e+05  |\n",
      "|    total_reward_pct   | 8.89      |\n",
      "|    total_trades       | 34093     |\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 1476      |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | 35.8      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 1.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 1482     |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -271     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 32.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 1488     |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 47.7     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 4.44     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 1494      |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 131       |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 8.91      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 1499     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 98.3     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 5.31     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.44e+06  |\n",
      "|    total_cost         | 3.22e+03  |\n",
      "|    total_reward       | -5.78e+04 |\n",
      "|    total_reward_pct   | -3.85     |\n",
      "|    total_trades       | 33430     |\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 1505      |\n",
      "|    total_timesteps    | 94500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | 10.4      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 1510     |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 18.3     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 3.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 1515     |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 55.2     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 1521     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 28.9     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.17e+06  |\n",
      "|    total_cost         | 2.95e+03  |\n",
      "|    total_reward       | -3.26e+05 |\n",
      "|    total_reward_pct   | -21.7     |\n",
      "|    total_trades       | 33032     |\n",
      "| time/                 |           |\n",
      "|    fps                | 63        |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 1527      |\n",
      "|    total_timesteps    | 96500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | 34.4      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.875     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 63        |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 1532      |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | -118      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 9.63      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 1538     |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -4.07    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0916   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 1544     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -1.98    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.116    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 1550     |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 93.6     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 6.23     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.78e+05  |\n",
      "|    total_cost         | 6.08e+03  |\n",
      "|    total_reward       | -5.22e+05 |\n",
      "|    total_reward_pct   | -34.8     |\n",
      "|    total_trades       | 33333     |\n",
      "| time/                 |           |\n",
      "|    fps                | 63        |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 1556      |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | -1.24     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 4.71      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 1562     |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 118      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 1567     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -63.5    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 3.3      |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-04-01 to  2019-06-27\n",
      "A2C Sharpe Ratio:  0.23108131579406002\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_189_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 100  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 20   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "day: 2295, episode: 45\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 49012.38\n",
      "total_reward: -1450987.62\n",
      "total_cost: 1217647.53\n",
      "total_trades: 37704\n",
      "Sharpe: -0.720\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.9e+04      |\n",
      "|    total_cost           | 1.22e+06     |\n",
      "|    total_reward         | -1.45e+06    |\n",
      "|    total_reward_pct     | -96.7        |\n",
      "|    total_trades         | 37704        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094916895 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.00935     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.625        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6.7          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.99e+03   |\n",
      "|    total_cost           | 2.65e+05   |\n",
      "|    total_reward         | -1.5e+06   |\n",
      "|    total_reward_pct     | -99.9      |\n",
      "|    total_trades         | 35660      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 92         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01702241 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | 0.0298     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 61.6       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 8.09       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.16e+04     |\n",
      "|    total_cost           | 7.84e+05     |\n",
      "|    total_reward         | -1.47e+06    |\n",
      "|    total_reward_pct     | -97.9        |\n",
      "|    total_trades         | 37118        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112579465 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | 0.0534       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.445        |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6.65         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.3e+04     |\n",
      "|    total_cost           | 8.99e+05    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -97.8       |\n",
      "|    total_trades         | 37385       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017573457 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0772      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.78        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.64e+05    |\n",
      "|    total_cost           | 1.42e+06    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.1       |\n",
      "|    total_trades         | 38311       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016064528 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.896       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 6.99        |\n",
      "-----------------------------------------\n",
      "day: 2295, episode: 50\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 25226.61\n",
      "total_reward: -1474773.39\n",
      "total_cost: 824686.75\n",
      "total_trades: 37241\n",
      "Sharpe: -0.732\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+04    |\n",
      "|    total_cost           | 8.25e+05    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98.3       |\n",
      "|    total_trades         | 37241       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019557737 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.085       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -8.39e+03   |\n",
      "|    total_cost           | 6.26e+05    |\n",
      "|    total_reward         | -1.51e+06   |\n",
      "|    total_reward_pct     | -101        |\n",
      "|    total_trades         | 36678       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012740867 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.071       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.417       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.4e+04     |\n",
      "|    total_cost           | 6.57e+05    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.1       |\n",
      "|    total_trades         | 36748       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013211014 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0196      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024025472 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.148      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.000716    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 4.52        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 8.19e+04     |\n",
      "|    total_cost           | 1.33e+06     |\n",
      "|    total_reward         | -1.42e+06    |\n",
      "|    total_reward_pct     | -94.5        |\n",
      "|    total_trades         | 38370        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110797975 |\n",
      "|    clip_fraction        | 0.169        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.1        |\n",
      "|    explained_variance   | -0.00668     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.991        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.94e+05    |\n",
      "|    total_cost           | 2.1e+06     |\n",
      "|    total_reward         | -1.31e+06   |\n",
      "|    total_reward_pct     | -87.1       |\n",
      "|    total_trades         | 39992       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012308158 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.35        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n",
      "day: 2295, episode: 55\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 143379.86\n",
      "total_reward: -1356620.14\n",
      "total_cost: 1210138.19\n",
      "total_trades: 37946\n",
      "Sharpe: -0.028\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.43e+05    |\n",
      "|    total_cost           | 1.21e+06    |\n",
      "|    total_reward         | -1.36e+06   |\n",
      "|    total_reward_pct     | -90.4       |\n",
      "|    total_trades         | 37946       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025216116 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0895      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.971       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.14e+04    |\n",
      "|    total_cost           | 1.25e+06    |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.2       |\n",
      "|    total_trades         | 38087       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012293605 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.2e+05     |\n",
      "|    total_cost           | 1.21e+06    |\n",
      "|    total_reward         | -1.38e+06   |\n",
      "|    total_reward_pct     | -92         |\n",
      "|    total_trades         | 38088       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015954815 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.37        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.32e+05   |\n",
      "|    total_cost           | 1.8e+06    |\n",
      "|    total_reward         | -1.27e+06  |\n",
      "|    total_reward_pct     | -84.5      |\n",
      "|    total_trades         | 39257      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 85         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 384        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03983918 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.143      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.89       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.00361   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 10         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.57e+04    |\n",
      "|    total_cost           | 8.18e+05    |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.6       |\n",
      "|    total_trades         | 37288       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024047265 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.5         |\n",
      "-----------------------------------------\n",
      "day: 2295, episode: 60\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 88129.61\n",
      "total_reward: -1411870.39\n",
      "total_cost: 1084749.93\n",
      "total_trades: 38215\n",
      "Sharpe: -0.039\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 8.81e+04   |\n",
      "|    total_cost           | 1.08e+06   |\n",
      "|    total_reward         | -1.41e+06  |\n",
      "|    total_reward_pct     | -94.1      |\n",
      "|    total_trades         | 38215      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 85         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 430        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01972754 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.08       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.00873   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 7.16       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 85         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 454        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03522911 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.605      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 8.77       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 333         |\n",
      "|    total_cost           | 6.91e+05    |\n",
      "|    total_reward         | -1.5e+06    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 37201       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020381218 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.22e+05     |\n",
      "|    total_cost           | 1.31e+06     |\n",
      "|    total_reward         | -1.38e+06    |\n",
      "|    total_reward_pct     | -91.9        |\n",
      "|    total_trades         | 38881        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 500          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078182705 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.6        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.81         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 8.46         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.31e+05    |\n",
      "|    total_cost           | 2.71e+05    |\n",
      "|    total_reward         | -1.37e+06   |\n",
      "|    total_reward_pct     | -91.3       |\n",
      "|    total_trades         | 36056       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020346815 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.33e+04    |\n",
      "|    total_cost           | 1.06e+06    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -97.8       |\n",
      "|    total_trades         | 38583       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029911324 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.93        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.96        |\n",
      "-----------------------------------------\n",
      "day: 2295, episode: 65\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 82336.80\n",
      "total_reward: -1417663.20\n",
      "total_cost: 1643031.36\n",
      "total_trades: 39294\n",
      "Sharpe: -0.529\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.23e+04    |\n",
      "|    total_cost           | 1.64e+06    |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -94.5       |\n",
      "|    total_trades         | 39294       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016686697 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0877      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.81        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.49e+05    |\n",
      "|    total_cost           | 7.22e+05    |\n",
      "|    total_reward         | -1.35e+06   |\n",
      "|    total_reward_pct     | -90.1       |\n",
      "|    total_trades         | 37474       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021443363 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.56e+05    |\n",
      "|    total_cost           | 1.59e+06    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.6       |\n",
      "|    total_trades         | 39235       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023781441 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.94        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.61e+05    |\n",
      "|    total_cost           | 7.48e+05    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.3       |\n",
      "|    total_trades         | 37466       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 633         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016119208 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 656         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023790265 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.51        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 7.07e+04   |\n",
      "|    total_cost           | 8.98e+05   |\n",
      "|    total_reward         | -1.43e+06  |\n",
      "|    total_reward_pct     | -95.3      |\n",
      "|    total_trades         | 38042      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 87         |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 678        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04078694 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.196      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.308      |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 1.35       |\n",
      "----------------------------------------\n",
      "day: 2295, episode: 70\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 122732.94\n",
      "total_reward: -1377267.06\n",
      "total_cost: 868920.53\n",
      "total_trades: 38339\n",
      "Sharpe: -0.387\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.23e+05   |\n",
      "|    total_cost           | 8.69e+05   |\n",
      "|    total_reward         | -1.38e+06  |\n",
      "|    total_reward_pct     | -91.8      |\n",
      "|    total_trades         | 38339      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 87         |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 700        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07727164 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.657      |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | 0.00598    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 7.21       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+05    |\n",
      "|    total_cost           | 9.3e+05     |\n",
      "|    total_reward         | -1.39e+06   |\n",
      "|    total_reward_pct     | -92.5       |\n",
      "|    total_trades         | 38424       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 722         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017212974 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.687       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 9.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.52e+04    |\n",
      "|    total_cost           | 1.07e+06    |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.7       |\n",
      "|    total_trades         | 39110       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 743         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016242903 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 6.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.97e+04    |\n",
      "|    total_cost           | 4.25e+05    |\n",
      "|    total_reward         | -1.44e+06   |\n",
      "|    total_reward_pct     | -96         |\n",
      "|    total_trades         | 37229       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 764         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015508831 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.284      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 6.62        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 6.68e+04     |\n",
      "|    total_cost           | 1.33e+06     |\n",
      "|    total_reward         | -1.43e+06    |\n",
      "|    total_reward_pct     | -95.5        |\n",
      "|    total_trades         | 39295        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 786          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016197376 |\n",
      "|    clip_fraction        | 0.0814       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.5        |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.63         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00837     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 7.34         |\n",
      "------------------------------------------\n",
      "day: 2295, episode: 75\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 73637.72\n",
      "total_reward: -1426362.28\n",
      "total_cost: 867239.46\n",
      "total_trades: 38463\n",
      "Sharpe: -0.455\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.36e+04    |\n",
      "|    total_cost           | 8.67e+05    |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.1       |\n",
      "|    total_trades         | 38463       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015366331 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.924       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 7.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.61e+05    |\n",
      "|    total_cost           | 8.02e+05    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.3       |\n",
      "|    total_trades         | 38499       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 831         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005671559 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 6.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.31e+05    |\n",
      "|    total_cost           | 8.65e+05    |\n",
      "|    total_reward         | -1.37e+06   |\n",
      "|    total_reward_pct     | -91.3       |\n",
      "|    total_trades         | 38465       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 852         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022040494 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.405       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 7.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 873         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013003413 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 6.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.29e+05    |\n",
      "|    total_cost           | 1.16e+06    |\n",
      "|    total_reward         | -1.37e+06   |\n",
      "|    total_reward_pct     | -91.4       |\n",
      "|    total_trades         | 39027       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 894         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010431511 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.00258     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 4.37        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 113         |\n",
      "|    total_cost           | 3.16e+05    |\n",
      "|    total_reward         | -1.5e+06    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 36914       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021077648 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0973     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 7.63        |\n",
      "-----------------------------------------\n",
      "day: 2295, episode: 80\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 401914.67\n",
      "total_reward: -1098085.33\n",
      "total_cost: 1273065.33\n",
      "total_trades: 39613\n",
      "Sharpe: -0.014\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.02e+05    |\n",
      "|    total_cost           | 1.27e+06    |\n",
      "|    total_reward         | -1.1e+06    |\n",
      "|    total_reward_pct     | -73.2       |\n",
      "|    total_trades         | 39613       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 937         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011970496 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.353       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 7.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.56e+05    |\n",
      "|    total_cost           | 2.14e+06    |\n",
      "|    total_reward         | -1.04e+06   |\n",
      "|    total_reward_pct     | -69.6       |\n",
      "|    total_trades         | 40665       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 959         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018974459 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0552      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.02e+05    |\n",
      "|    total_cost           | 2.21e+06    |\n",
      "|    total_reward         | -9.98e+05   |\n",
      "|    total_reward_pct     | -66.6       |\n",
      "|    total_trades         | 41032       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 981         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010827182 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.78e+05    |\n",
      "|    total_cost           | 2.35e+06    |\n",
      "|    total_reward         | -1.22e+06   |\n",
      "|    total_reward_pct     | -81.5       |\n",
      "|    total_trades         | 41410       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1002        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011536345 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0154      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.02e+05    |\n",
      "|    total_cost           | 1.28e+06    |\n",
      "|    total_reward         | -1.1e+06    |\n",
      "|    total_reward_pct     | -73.2       |\n",
      "|    total_trades         | 39543       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1022        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013298655 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0636      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "day: 2295, episode: 85\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 229809.16\n",
      "total_reward: -1270190.84\n",
      "total_cost: 1711376.38\n",
      "total_trades: 40178\n",
      "Sharpe: -0.345\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.3e+05     |\n",
      "|    total_cost           | 1.71e+06    |\n",
      "|    total_reward         | -1.27e+06   |\n",
      "|    total_reward_pct     | -84.7       |\n",
      "|    total_trades         | 40178       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1042        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011506258 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.55        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1064        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008567786 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.3e+05     |\n",
      "|    total_cost           | 1.26e+06    |\n",
      "|    total_reward         | -1.37e+06   |\n",
      "|    total_reward_pct     | -91.3       |\n",
      "|    total_trades         | 38927       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1086        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016209153 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.00983     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.13        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 7.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 5.49e+05    |\n",
      "|    total_reward         | -1.4e+06    |\n",
      "|    total_reward_pct     | -93.2       |\n",
      "|    total_trades         | 37497       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1106        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013545396 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.519       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 7.72        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-04-01 to  2019-06-27\n",
      "PPO Sharpe Ratio:  0.23832819597492666\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_189_1\n",
      "day: 2295, episode: 90\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1878239.02\n",
      "total_reward: 378239.02\n",
      "total_cost: 5739.90\n",
      "total_trades: 25199\n",
      "Sharpe: 0.281\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.37e+06  |\n",
      "|    total_cost       | 2.96e+03  |\n",
      "|    total_reward     | -1.27e+05 |\n",
      "|    total_reward_pct | -8.47     |\n",
      "|    total_trades     | 22193     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 32        |\n",
      "|    time_elapsed     | 280       |\n",
      "|    total timesteps  | 9184      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 75.1      |\n",
      "|    critic_loss      | 81.4      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 6888      |\n",
      "-----------------------------------\n",
      "day: 2295, episode: 95\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 900724.55\n",
      "total_reward: -599275.45\n",
      "total_cost: 4980.85\n",
      "total_trades: 24726\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.49e+06  |\n",
      "|    total_cost       | 2.86e+03  |\n",
      "|    total_reward     | -5.31e+03 |\n",
      "|    total_reward_pct | -0.354    |\n",
      "|    total_trades     | 24769     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 29        |\n",
      "|    time_elapsed     | 616       |\n",
      "|    total timesteps  | 18368     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 45.4      |\n",
      "|    critic_loss      | 48        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16072     |\n",
      "-----------------------------------\n",
      "day: 2295, episode: 100\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1273512.91\n",
      "total_reward: -226487.09\n",
      "total_cost: 5670.15\n",
      "total_trades: 24554\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.27e+06  |\n",
      "|    total_cost       | 5.67e+03  |\n",
      "|    total_reward     | -2.26e+05 |\n",
      "|    total_reward_pct | -15.1     |\n",
      "|    total_trades     | 24554     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 27        |\n",
      "|    time_elapsed     | 990       |\n",
      "|    total timesteps  | 27552     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 27.1      |\n",
      "|    critic_loss      | 91.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 25256     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.38e+06  |\n",
      "|    total_cost       | 2.96e+03  |\n",
      "|    total_reward     | -1.18e+05 |\n",
      "|    total_reward_pct | -7.84     |\n",
      "|    total_trades     | 25383     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 28        |\n",
      "|    time_elapsed     | 1307      |\n",
      "|    total timesteps  | 36736     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 15.7      |\n",
      "|    critic_loss      | 56.4      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 34440     |\n",
      "-----------------------------------\n",
      "day: 2295, episode: 105\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1496840.31\n",
      "total_reward: -3159.69\n",
      "total_cost: 2857.67\n",
      "total_trades: 25534\n",
      "Sharpe: 0.276\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.51e+06 |\n",
      "|    total_cost       | 2.85e+03 |\n",
      "|    total_reward     | 6.22e+03 |\n",
      "|    total_reward_pct | 0.415    |\n",
      "|    total_trades     | 25285    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 1588     |\n",
      "|    total timesteps  | 45920    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 8.55     |\n",
      "|    critic_loss      | 79.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 43624    |\n",
      "----------------------------------\n",
      "day: 2295, episode: 110\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 669295.94\n",
      "total_reward: -830704.06\n",
      "total_cost: 3640.31\n",
      "total_trades: 25558\n",
      "Sharpe: 0.215\n",
      "=================================\n",
      "======DDPG Validation from:  2019-04-01 to  2019-06-27\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-06-27\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ensemble_189_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.53e+06 |\n",
      "|    total_cost       | 3.31e+03 |\n",
      "|    total_reward     | 3.39e+04 |\n",
      "|    total_reward_pct | 2.26     |\n",
      "|    total_trades     | 34384    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total timesteps  | 9436     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -509     |\n",
      "|    critic_loss      | 148      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7077     |\n",
      "----------------------------------\n",
      "day: 2358, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1468042.00\n",
      "total_reward: -31958.00\n",
      "total_cost: 8411.98\n",
      "total_trades: 34333\n",
      "Sharpe: 0.233\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.97e+06 |\n",
      "|    total_cost       | 9.21e+03 |\n",
      "|    total_reward     | 4.65e+05 |\n",
      "|    total_reward_pct | 31       |\n",
      "|    total_trades     | 34413    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 522      |\n",
      "|    total timesteps  | 18872    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -315     |\n",
      "|    critic_loss      | 73.3     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 16513    |\n",
      "----------------------------------\n",
      "day: 2358, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1495880.44\n",
      "total_reward: -4119.56\n",
      "total_cost: 10776.91\n",
      "total_trades: 34589\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.07e+06  |\n",
      "|    total_cost       | 3.92e+03  |\n",
      "|    total_reward     | -4.25e+05 |\n",
      "|    total_reward_pct | -28.3     |\n",
      "|    total_trades     | 34265     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 35        |\n",
      "|    time_elapsed     | 805       |\n",
      "|    total timesteps  | 28308     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -195      |\n",
      "|    critic_loss      | 95.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 25949     |\n",
      "-----------------------------------\n",
      "day: 2358, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2821664.14\n",
      "total_reward: 1321664.14\n",
      "total_cost: 10119.30\n",
      "total_trades: 31967\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.56e+06 |\n",
      "|    total_cost       | 3.21e+03 |\n",
      "|    total_reward     | 5.83e+04 |\n",
      "|    total_reward_pct | 3.88     |\n",
      "|    total_trades     | 31950    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 1086     |\n",
      "|    total timesteps  | 37744    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -122     |\n",
      "|    critic_loss      | 64.2     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35385    |\n",
      "----------------------------------\n",
      "day: 2358, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1968660.22\n",
      "total_reward: 468660.22\n",
      "total_cost: 10202.96\n",
      "total_trades: 31157\n",
      "Sharpe: 0.329\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.97e+06 |\n",
      "|    total_cost       | 1.02e+04 |\n",
      "|    total_reward     | 4.69e+05 |\n",
      "|    total_reward_pct | 31.2     |\n",
      "|    total_trades     | 31157    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 1366     |\n",
      "|    total timesteps  | 47180    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -77.1    |\n",
      "|    critic_loss      | 83.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44821    |\n",
      "----------------------------------\n",
      "======Trading from:  2019-06-27 to  2019-09-24\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  397.3376832837864\n",
      "======Model training from:  2000-01-01 to  2019-06-27\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_252_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 508      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 181      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.88e+03 |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 1.7e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 2.73e+03 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.95e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.00269  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -216     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 200      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 7.78e+06 |\n",
      "|    total_cost         | 2.14e+06 |\n",
      "|    total_reward       | 6.28e+06 |\n",
      "|    total_reward_pct   | 419      |\n",
      "|    total_trades       | 40857    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -9.62    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.17     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 4.69      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.501     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 3.28     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0745   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -25.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.397    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | -0.0618  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 133      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 18       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.71e+06 |\n",
      "|    total_cost         | 3.88e+05 |\n",
      "|    total_reward       | 2.09e+05 |\n",
      "|    total_reward_pct   | 13.9     |\n",
      "|    total_trades       | 37657    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 178      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 20.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 140      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 118       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 284      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 50.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -237      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 29.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.7e+06  |\n",
      "|    total_cost         | 2.68e+05 |\n",
      "|    total_reward       | 2.2e+06  |\n",
      "|    total_reward_pct   | 147      |\n",
      "|    total_trades       | 34676    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -80.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -260     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 53.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 219      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 28.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -103     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.4      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.51e+05  |\n",
      "|    total_cost         | 7.27e+04  |\n",
      "|    total_reward       | -8.49e+05 |\n",
      "|    total_reward_pct   | -56.6     |\n",
      "|    total_trades       | 30360     |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -20       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.872     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -16.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.929    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 60.2     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.58     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -23.2     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.45      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -269     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 53.8     |\n",
      "------------------------------------\n",
      "day: 2358, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 689675.97\n",
      "total_reward: -810324.03\n",
      "total_cost: 92708.79\n",
      "total_trades: 30373\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.9e+05  |\n",
      "|    total_cost         | 9.27e+04 |\n",
      "|    total_reward       | -8.1e+05 |\n",
      "|    total_reward_pct   | -54      |\n",
      "|    total_trades       | 30373    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -45.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -22.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 12.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.348    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 80.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 452      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 189      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.35e+06 |\n",
      "|    total_cost         | 3.07e+04 |\n",
      "|    total_reward       | 8.48e+05 |\n",
      "|    total_reward_pct   | 56.5     |\n",
      "|    total_trades       | 28788    |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -64.9    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.38     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -238      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 31.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 16.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.143    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 189      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 19.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 234       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 39.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.26e+06 |\n",
      "|    total_cost         | 8.63e+04 |\n",
      "|    total_reward       | 2.76e+06 |\n",
      "|    total_reward_pct   | 184      |\n",
      "|    total_trades       | 29753    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 30.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.805    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -9.49    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.924    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.786    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.000449 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 5.69     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 19.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.54e+06 |\n",
      "|    total_cost         | 7.31e+04 |\n",
      "|    total_reward       | 3.04e+06 |\n",
      "|    total_reward_pct   | 203      |\n",
      "|    total_trades       | 30476    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 16.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.198    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | -0.738   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 50.2     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -80      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 5.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 40.1     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 14.4     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.62     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.24e+05  |\n",
      "|    total_cost         | 3.09e+04  |\n",
      "|    total_reward       | -5.76e+05 |\n",
      "|    total_reward_pct   | -38.4     |\n",
      "|    total_trades       | 28867     |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 105       |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 8.96      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -63.5    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 164      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 14.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -76.2    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 7.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 218      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -1.4e+03 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.31e+03 |\n",
      "------------------------------------\n",
      "day: 2358, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 6097939.60\n",
      "total_reward: 4597939.60\n",
      "total_cost: 68940.26\n",
      "total_trades: 29799\n",
      "Sharpe: -0.327\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.1e+06  |\n",
      "|    total_cost         | 6.89e+04 |\n",
      "|    total_reward       | 4.6e+06  |\n",
      "|    total_reward_pct   | 307      |\n",
      "|    total_trades       | 29799    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -71.4    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -4.88    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.33     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 232       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -49.8     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.46      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 569      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 206      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.12e+06 |\n",
      "|    total_cost         | 2.52e+04 |\n",
      "|    total_reward       | 6.62e+06 |\n",
      "|    total_reward_pct   | 441      |\n",
      "|    total_trades       | 30015    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 55.2     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -49.1    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 250       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 35.8      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | -0.0101  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 158      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 17.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 43.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 16.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.64e+06 |\n",
      "|    total_cost         | 2.06e+04 |\n",
      "|    total_reward       | 3.14e+06 |\n",
      "|    total_reward_pct   | 209      |\n",
      "|    total_trades       | 30588    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -36      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.699    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -13.3     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.283     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 17       |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.147    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.732    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -122     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 79.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.44e+06 |\n",
      "|    total_cost         | 1.2e+04  |\n",
      "|    total_reward       | 9.44e+05 |\n",
      "|    total_reward_pct   | 63       |\n",
      "|    total_trades       | 31387    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 19.3     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 16.9     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.193    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -29.9    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.513    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 301       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 46.2      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.55      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 305       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -1.01e+03 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 670       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.24e+06 |\n",
      "|    total_cost         | 2.12e+04 |\n",
      "|    total_reward       | 7.39e+05 |\n",
      "|    total_reward_pct   | 49.3     |\n",
      "|    total_trades       | 33918    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -31      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -158     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 20       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 319      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 32.6     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.47     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 324       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -82.1     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 4.02      |\n",
      "-------------------------------------\n",
      "day: 2358, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 3118842.45\n",
      "total_reward: 1618842.45\n",
      "total_cost: 14799.21\n",
      "total_trades: 35879\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.12e+06  |\n",
      "|    total_cost         | 1.48e+04  |\n",
      "|    total_reward       | 1.62e+06  |\n",
      "|    total_reward_pct   | 108       |\n",
      "|    total_trades       | 35879     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 328       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 56.9      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.67      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 72       |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -17.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 4.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 342      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 173      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 23.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 151      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 107      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.71e+06 |\n",
      "|    total_cost         | 1.42e+04 |\n",
      "|    total_reward       | 1.21e+06 |\n",
      "|    total_reward_pct   | 80.5     |\n",
      "|    total_trades       | 38419    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -56.4    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -13.8    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.157    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -31.9    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 365      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -2       |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0264   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 370      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 314      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 53.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.55e+06 |\n",
      "|    total_cost         | 3.96e+03 |\n",
      "|    total_reward       | 4.81e+04 |\n",
      "|    total_reward_pct   | 3.21     |\n",
      "|    total_trades       | 39453    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 375      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -47.2    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 379       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -502      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 134       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 384      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -276     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 46.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 388       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 93.5      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.58e+06  |\n",
      "|    total_cost         | 4.25e+04  |\n",
      "|    total_reward       | 1.08e+06  |\n",
      "|    total_reward_pct   | 71.7      |\n",
      "|    total_trades       | 39226     |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 393       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -13.9     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.0969    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 397       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -11.1     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.142     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -18.4    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.207    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 407      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 8.84     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.245    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 412      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 258      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 35.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.76e+06 |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | 2.56e+05 |\n",
      "|    total_reward_pct   | 17.1     |\n",
      "|    total_trades       | 39651    |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 416      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 53.7     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.57     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 421       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 151       |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 16.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 426      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 406      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 101      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 430      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -233     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 22.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 434      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -168     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 16.5     |\n",
      "------------------------------------\n",
      "day: 2358, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1748092.60\n",
      "total_reward: 248092.60\n",
      "total_cost: 7716.74\n",
      "total_trades: 38927\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.75e+06 |\n",
      "|    total_cost         | 7.72e+03 |\n",
      "|    total_reward       | 2.48e+05 |\n",
      "|    total_reward_pct   | 16.5     |\n",
      "|    total_trades       | 38927    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 439      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 18.2     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.343    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 443      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 65.6     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 6.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 448      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 266      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 50.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 452      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 34.1     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 457      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 16.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.16e+06 |\n",
      "|    total_cost         | 1.24e+04 |\n",
      "|    total_reward       | 6.58e+05 |\n",
      "|    total_reward_pct   | 43.9     |\n",
      "|    total_trades       | 39728    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 462      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 5.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 466      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -66.9    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 471      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -170     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 19       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 476      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -145     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 20.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.31e+06  |\n",
      "|    total_cost         | 1.23e+04  |\n",
      "|    total_reward       | 8.12e+05  |\n",
      "|    total_reward_pct   | 54.1      |\n",
      "|    total_trades       | 39485     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 480       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | -112      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 8.17      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 485      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -219     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 24.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 490      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 36.3     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 5.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 494      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -92      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 9.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 499       |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | -246      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 81.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.5e+06  |\n",
      "|    total_cost         | 1.1e+04  |\n",
      "|    total_reward       | 9.97e+05 |\n",
      "|    total_reward_pct   | 66.5     |\n",
      "|    total_trades       | 40675    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 503      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 54.9     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 3.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 508      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 211      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 30.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 513      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 30.4     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 4.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 517      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 233      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 27       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 521      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 115      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 17.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.37e+06 |\n",
      "|    total_cost         | 5.57e+03 |\n",
      "|    total_reward       | 8.69e+05 |\n",
      "|    total_reward_pct   | 58       |\n",
      "|    total_trades       | 39358    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 526      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 2.82     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.232    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 531      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 535      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 35.2     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 20.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 540      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -92.8    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 7.95     |\n",
      "------------------------------------\n",
      "day: 2358, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 3131818.68\n",
      "total_reward: 1631818.68\n",
      "total_cost: 20188.98\n",
      "total_trades: 40815\n",
      "Sharpe: 0.389\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.13e+06  |\n",
      "|    total_cost         | 2.02e+04  |\n",
      "|    total_reward       | 1.63e+06  |\n",
      "|    total_reward_pct   | 109       |\n",
      "|    total_trades       | 40815     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 545       |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -39.5     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.922     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 549      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -39.1    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.802    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 554       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | 3.84      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.0163    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 558      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 19.4     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 563       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 68.9      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 7.9       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.46e+06  |\n",
      "|    total_cost         | 3.41e+03  |\n",
      "|    total_reward       | -3.76e+04 |\n",
      "|    total_reward_pct   | -2.5      |\n",
      "|    total_trades       | 41988     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 568       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | 8         |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.109     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 572      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 50.8     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 577      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -389     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 85.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 582      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -128     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 587       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | -30       |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 1.02      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.27e+06  |\n",
      "|    total_cost         | 4.51e+03  |\n",
      "|    total_reward       | -2.34e+05 |\n",
      "|    total_reward_pct   | -15.6     |\n",
      "|    total_trades       | 41009     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 591       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | 122       |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 8.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 596      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -59.9    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 3.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 601      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 47.9     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 606      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -61.1    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 4.46     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 610       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | 99.1      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 8.63      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.51e+06 |\n",
      "|    total_cost         | 3.69e+03 |\n",
      "|    total_reward       | 6.98e+03 |\n",
      "|    total_reward_pct   | 0.465    |\n",
      "|    total_trades       | 40219    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 615      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -2.74    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 619      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -241     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 31.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 624      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 197      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 20.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 629      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 19.1     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.556    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.21e+06  |\n",
      "|    total_cost         | 1.73e+04  |\n",
      "|    total_reward       | -2.91e+05 |\n",
      "|    total_reward_pct   | -19.4     |\n",
      "|    total_trades       | 39779     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 633       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | 99.9      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 6.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 638      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -66.8    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 642      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -5.04    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.505    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 646      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 15.4     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.247    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 650       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | 202       |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 30        |\n",
      "-------------------------------------\n",
      "day: 2358, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1228982.39\n",
      "total_reward: -271017.61\n",
      "total_cost: 5808.36\n",
      "total_trades: 40498\n",
      "Sharpe: -0.327\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.23e+06  |\n",
      "|    total_cost         | 5.81e+03  |\n",
      "|    total_reward       | -2.71e+05 |\n",
      "|    total_reward_pct   | -18.1     |\n",
      "|    total_trades       | 40498     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 654       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | -40.4     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 2.51      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 659      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -13.2    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.148    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 2.2      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.0796   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 667      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 26       |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.569    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 672      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 76.6     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 6.78     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.5e+06   |\n",
      "|    total_cost         | 2.85e+03  |\n",
      "|    total_reward       | -2.42e+03 |\n",
      "|    total_reward_pct   | -0.161    |\n",
      "|    total_trades       | 40688     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 677       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -7.41     |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.0569    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 682       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -217      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 27.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 687       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | -165      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 17        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 692      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -93.7    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 5.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.09e+06  |\n",
      "|    total_cost         | 6.44e+03  |\n",
      "|    total_reward       | -4.08e+05 |\n",
      "|    total_reward_pct   | -27.2     |\n",
      "|    total_trades       | 39683     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 697       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -21       |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.213     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 701      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 7.08     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 706       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | -51.6     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.75      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 710      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -162     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 715       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | 89        |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 13.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.5e+06  |\n",
      "|    total_cost         | 2.97e+03 |\n",
      "|    total_reward       | 4.53e+03 |\n",
      "|    total_reward_pct   | 0.302    |\n",
      "|    total_trades       | 39137    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 720      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 13       |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.138    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 725      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -0.064   |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.201    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 730      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -93.2    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 4.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 734      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -83.4    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 3.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 739      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -488     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 137      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.47e+06  |\n",
      "|    total_cost         | 3.21e+03  |\n",
      "|    total_reward       | -2.81e+04 |\n",
      "|    total_reward_pct   | -1.87     |\n",
      "|    total_trades       | 39496     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 744       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 19.8      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.51      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 749      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 94.1     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 8.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 753      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -162     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 16.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 758      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 262      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 33.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 763      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 116      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 9.69     |\n",
      "------------------------------------\n",
      "day: 2358, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1926734.82\n",
      "total_reward: 426734.82\n",
      "total_cost: 5890.41\n",
      "total_trades: 39171\n",
      "Sharpe: 0.331\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 5.89e+03 |\n",
      "|    total_reward       | 4.27e+05 |\n",
      "|    total_reward_pct   | 28.4     |\n",
      "|    total_trades       | 39171    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 767      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -152     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 772      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 55.1     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 776      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -66.5    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 6.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 781      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 6.37     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.84     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.46e+06  |\n",
      "|    total_cost         | 6.87e+03  |\n",
      "|    total_reward       | -3.93e+04 |\n",
      "|    total_reward_pct   | -2.62     |\n",
      "|    total_trades       | 39907     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 786       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | 14.5      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.499     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 790      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 21.4     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.379    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 794      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -3.09    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 799      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 80       |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 7.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 803      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -61.3    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.55e+06 |\n",
      "|    total_cost         | 4.48e+03 |\n",
      "|    total_reward       | 4.77e+04 |\n",
      "|    total_reward_pct   | 3.18     |\n",
      "|    total_trades       | 38396    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 808      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -28      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.473    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 812      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 48.1     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 816      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 5.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 821      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -215     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 23.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 825      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 171      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 16       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.47e+05  |\n",
      "|    total_cost         | 8.32e+03  |\n",
      "|    total_reward       | -5.53e+05 |\n",
      "|    total_reward_pct   | -36.8     |\n",
      "|    total_trades       | 38425     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 830       |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | -99.6     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 5.38      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 834      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -110     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 8.43     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 839       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 31.5      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 2.6       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 844      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -25.8    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.51     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 848       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -6.83e+03 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 1.99e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.45e+06  |\n",
      "|    total_cost         | 5.68e+03  |\n",
      "|    total_reward       | -4.72e+04 |\n",
      "|    total_reward_pct   | -3.15     |\n",
      "|    total_trades       | 38474     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 852       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | 110       |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 5.93      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 857      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 73       |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 3        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 862      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 216      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 22.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 866      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -94.3    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 5.04     |\n",
      "------------------------------------\n",
      "day: 2358, episode: 40\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1637875.67\n",
      "total_reward: 137875.67\n",
      "total_cost: 10388.51\n",
      "total_trades: 37742\n",
      "Sharpe: 0.338\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.64e+06 |\n",
      "|    total_cost         | 1.04e+04 |\n",
      "|    total_reward       | 1.38e+05 |\n",
      "|    total_reward_pct   | 9.19     |\n",
      "|    total_trades       | 37742    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 871      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -0.735   |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.068    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 875      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 6.65     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0736   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 879      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 33.6     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.826    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 884      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 88.7     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 3.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 888      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -91.4    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.5e+06   |\n",
      "|    total_cost         | 2.84e+03  |\n",
      "|    total_reward       | -2.84e+03 |\n",
      "|    total_reward_pct   | -0.19     |\n",
      "|    total_trades       | 37822     |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 893       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | 27.6      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.645     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 897      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 49.8     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 6.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 902      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 5.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 907      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -54      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 912      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -47.6    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 5.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.64e+06 |\n",
      "|    total_cost         | 1.48e+04 |\n",
      "|    total_reward       | 1.37e+05 |\n",
      "|    total_reward_pct   | 9.16     |\n",
      "|    total_trades       | 39400    |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 917      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -26.7    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 922      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -84      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 5.08     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-06-27 to  2019-09-24\n",
      "A2C Sharpe Ratio:  0.10914335979077643\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_252_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 107  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 19   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.04e+05     |\n",
      "|    total_cost           | 2.19e+06     |\n",
      "|    total_reward         | -1.4e+06     |\n",
      "|    total_reward_pct     | -93.1        |\n",
      "|    total_trades         | 40514        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075072236 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0228      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.45         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "day: 2358, episode: 45\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 29044.97\n",
      "total_reward: -1470955.03\n",
      "total_cost: 793768.61\n",
      "total_trades: 38062\n",
      "Sharpe: -0.642\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.9e+04     |\n",
      "|    total_cost           | 7.94e+05    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98.1       |\n",
      "|    total_trades         | 38062       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021896115 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0227     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+04    |\n",
      "|    total_cost           | 1.12e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.2       |\n",
      "|    total_trades         | 38321       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010246882 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0215      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.27e+04    |\n",
      "|    total_cost           | 1.09e+06    |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -94.5       |\n",
      "|    total_trades         | 38574       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018123655 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.042       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.863       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.55e+04    |\n",
      "|    total_cost           | 1.27e+06    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.6       |\n",
      "|    total_trades         | 39083       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014592513 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.36e+04    |\n",
      "|    total_cost           | 1.28e+06    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -97.8       |\n",
      "|    total_trades         | 38891       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016536454 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.81        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 143        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01581921 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | 0.121      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.554      |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 9.88       |\n",
      "----------------------------------------\n",
      "day: 2358, episode: 50\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 25087.85\n",
      "total_reward: -1474912.15\n",
      "total_cost: 583059.12\n",
      "total_trades: 37376\n",
      "Sharpe: -0.068\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.51e+04    |\n",
      "|    total_cost           | 5.83e+05    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98.3       |\n",
      "|    total_trades         | 37376       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024886224 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.365       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+04    |\n",
      "|    total_cost           | 5.7e+05     |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.4       |\n",
      "|    total_trades         | 37504       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017519688 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0732      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0587     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.13        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.26e+04     |\n",
      "|    total_cost           | 1.27e+06     |\n",
      "|    total_reward         | -1.41e+06    |\n",
      "|    total_reward_pct     | -93.8        |\n",
      "|    total_trades         | 39037        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134321675 |\n",
      "|    clip_fraction        | 0.208        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.2        |\n",
      "|    explained_variance   | 0.0766       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.1         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 7.17         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.38e+04    |\n",
      "|    total_cost           | 1.1e+06     |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.1       |\n",
      "|    total_trades         | 38958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014912924 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0962      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.78        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.83        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 5.15e+03     |\n",
      "|    total_cost           | 1.07e+06     |\n",
      "|    total_reward         | -1.49e+06    |\n",
      "|    total_reward_pct     | -99.7        |\n",
      "|    total_trades         | 38606        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057461374 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.3        |\n",
      "|    explained_variance   | 0.142        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 5.92         |\n",
      "------------------------------------------\n",
      "day: 2358, episode: 55\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 89006.76\n",
      "total_reward: -1410993.24\n",
      "total_cost: 1356152.71\n",
      "total_trades: 39292\n",
      "Sharpe: -0.620\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 8.9e+04      |\n",
      "|    total_cost           | 1.36e+06     |\n",
      "|    total_reward         | -1.41e+06    |\n",
      "|    total_reward_pct     | -94.1        |\n",
      "|    total_trades         | 39292        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016612802 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.4        |\n",
      "|    explained_variance   | 0.192        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 4.62         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.65e+04    |\n",
      "|    total_cost           | 1.19e+06    |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.9       |\n",
      "|    total_trades         | 38911       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013955237 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.434       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 5.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017984688 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.355       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.08e+04    |\n",
      "|    total_cost           | 1.18e+06    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.6       |\n",
      "|    total_trades         | 38638       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004364265 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.64e+04    |\n",
      "|    total_cost           | 1.03e+06    |\n",
      "|    total_reward         | -1.44e+06   |\n",
      "|    total_reward_pct     | -96.2       |\n",
      "|    total_trades         | 38585       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021871904 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.79e+05    |\n",
      "|    total_cost           | 6.39e+05    |\n",
      "|    total_reward         | -1.22e+06   |\n",
      "|    total_reward_pct     | -81.4       |\n",
      "|    total_trades         | 37856       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018589037 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0197      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.4         |\n",
      "-----------------------------------------\n",
      "day: 2358, episode: 60\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 70.38\n",
      "total_reward: -1499929.62\n",
      "total_cost: 373023.60\n",
      "total_trades: 37230\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 70.4       |\n",
      "|    total_cost           | 3.73e+05   |\n",
      "|    total_reward         | -1.5e+06   |\n",
      "|    total_reward_pct     | -100       |\n",
      "|    total_trades         | 37230      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 356        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02100165 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0822     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.019     |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 10.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.25e+04    |\n",
      "|    total_cost           | 1.36e+06    |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.5       |\n",
      "|    total_trades         | 39562       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011716008 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.24e+04    |\n",
      "|    total_cost           | 8.3e+05     |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -94.5       |\n",
      "|    total_trades         | 38659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022037396 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.441       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014049582 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.832       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 4.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.44e+05    |\n",
      "|    total_cost           | 1.45e+06    |\n",
      "|    total_reward         | -1.26e+06   |\n",
      "|    total_reward_pct     | -83.7       |\n",
      "|    total_trades         | 40076       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016502213 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.34        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.27e+04   |\n",
      "|    total_cost           | 1.04e+06   |\n",
      "|    total_reward         | -1.45e+06  |\n",
      "|    total_reward_pct     | -96.5      |\n",
      "|    total_trades         | 39131      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 445        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01645471 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.147      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.702      |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 6.88       |\n",
      "----------------------------------------\n",
      "day: 2358, episode: 65\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: -5957.64\n",
      "total_reward: -1505957.64\n",
      "total_cost: 321198.50\n",
      "total_trades: 37432\n",
      "Sharpe: -0.427\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | -5.96e+03  |\n",
      "|    total_cost           | 3.21e+05   |\n",
      "|    total_reward         | -1.51e+06  |\n",
      "|    total_reward_pct     | -100       |\n",
      "|    total_trades         | 37432      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 463        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00859843 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.161      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.271     |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 8.19       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.77e+05     |\n",
      "|    total_cost           | 1.36e+06     |\n",
      "|    total_reward         | -1.32e+06    |\n",
      "|    total_reward_pct     | -88.2        |\n",
      "|    total_trades         | 40035        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 481          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071112607 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.1        |\n",
      "|    explained_variance   | 0.0869       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.03         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.81e+05   |\n",
      "|    total_cost           | 2e+06      |\n",
      "|    total_reward         | -1.12e+06  |\n",
      "|    total_reward_pct     | -74.6      |\n",
      "|    total_trades         | 41067      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 500        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02257646 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.0665     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.91       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 14.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.94e+05    |\n",
      "|    total_cost           | 2.17e+06    |\n",
      "|    total_reward         | -9.06e+05   |\n",
      "|    total_reward_pct     | -60.4       |\n",
      "|    total_trades         | 41307       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 520         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021128275 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0915      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.81        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.27e+05   |\n",
      "|    total_cost           | 2.95e+06   |\n",
      "|    total_reward         | -9.73e+05  |\n",
      "|    total_reward_pct     | -64.8      |\n",
      "|    total_trades         | 41813      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 539        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04779318 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0776     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.65       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.00788   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 20.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 557         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035701282 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0501      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 61.3        |\n",
      "-----------------------------------------\n",
      "day: 2358, episode: 70\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 188628.01\n",
      "total_reward: -1311371.99\n",
      "total_cost: 958572.26\n",
      "total_trades: 38931\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.89e+05    |\n",
      "|    total_cost           | 9.59e+05    |\n",
      "|    total_reward         | -1.31e+06   |\n",
      "|    total_reward_pct     | -87.4       |\n",
      "|    total_trades         | 38931       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018615944 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 5.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.91e+05    |\n",
      "|    total_cost           | 2.46e+06    |\n",
      "|    total_reward         | -9.09e+05   |\n",
      "|    total_reward_pct     | -60.6       |\n",
      "|    total_trades         | 40980       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016978871 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0303      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.23e+05   |\n",
      "|    total_cost           | 2.04e+06   |\n",
      "|    total_reward         | -5.77e+05  |\n",
      "|    total_reward_pct     | -38.4      |\n",
      "|    total_trades         | 40659      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 611        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06351845 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.4      |\n",
      "|    explained_variance   | 0.0516     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.6       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00237   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 44.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.87e+05    |\n",
      "|    total_cost           | 2.23e+06    |\n",
      "|    total_reward         | -1.01e+06   |\n",
      "|    total_reward_pct     | -67.5       |\n",
      "|    total_trades         | 40742       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012394885 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0993      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.94e+05    |\n",
      "|    total_cost           | 1.74e+06    |\n",
      "|    total_reward         | -8.06e+05   |\n",
      "|    total_reward_pct     | -53.7       |\n",
      "|    total_trades         | 39966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007639628 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "day: 2358, episode: 75\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 310579.25\n",
      "total_reward: -1189420.75\n",
      "total_cost: 1217528.52\n",
      "total_trades: 39375\n",
      "Sharpe: 0.008\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 3.11e+05     |\n",
      "|    total_cost           | 1.22e+06     |\n",
      "|    total_reward         | -1.19e+06    |\n",
      "|    total_reward_pct     | -79.3        |\n",
      "|    total_trades         | 39375        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 669          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0145763885 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.6        |\n",
      "|    explained_variance   | 0.132        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.54         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 686         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017600024 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.68        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.65e+05    |\n",
      "|    total_cost           | 1.94e+06    |\n",
      "|    total_reward         | -1.03e+06   |\n",
      "|    total_reward_pct     | -69         |\n",
      "|    total_trades         | 40120       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 704         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011832664 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | -0.000846   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.000126   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.9e+06    |\n",
      "|    total_cost           | 2.24e+06   |\n",
      "|    total_reward         | 3.98e+05   |\n",
      "|    total_reward_pct     | 26.5       |\n",
      "|    total_trades         | 40745      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 722        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04888263 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.0429     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 63.2       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.00472   |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 48.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.04e+06    |\n",
      "|    total_cost           | 2.1e+06     |\n",
      "|    total_reward         | -4.65e+05   |\n",
      "|    total_reward_pct     | -31         |\n",
      "|    total_trades         | 40657       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014454365 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0469      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.5        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2e+06       |\n",
      "|    total_cost           | 2e+06       |\n",
      "|    total_reward         | 5.03e+05    |\n",
      "|    total_reward_pct     | 33.6        |\n",
      "|    total_trades         | 40333       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 760         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024708213 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "day: 2358, episode: 80\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2666862.06\n",
      "total_reward: 1166862.06\n",
      "total_cost: 2880052.36\n",
      "total_trades: 41577\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.67e+06    |\n",
      "|    total_cost           | 2.88e+06    |\n",
      "|    total_reward         | 1.17e+06    |\n",
      "|    total_reward_pct     | 77.8        |\n",
      "|    total_trades         | 41577       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030391064 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.9        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.8e+05    |\n",
      "|    total_cost           | 1.28e+06   |\n",
      "|    total_reward         | -1.32e+06  |\n",
      "|    total_reward_pct     | -88        |\n",
      "|    total_trades         | 39630      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 795        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03832712 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.0311     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 87.4       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | 0.0109     |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 168        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.95e+05    |\n",
      "|    total_cost           | 1.83e+06    |\n",
      "|    total_reward         | -9.05e+05   |\n",
      "|    total_reward_pct     | -60.3       |\n",
      "|    total_trades         | 40361       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 812         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016286043 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.79        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029674718 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.000552   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.51e+05    |\n",
      "|    total_cost           | 1.58e+06    |\n",
      "|    total_reward         | -7.49e+05   |\n",
      "|    total_reward_pct     | -50         |\n",
      "|    total_trades         | 40368       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 848         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022422006 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.00316     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.53e+06    |\n",
      "|    total_cost           | 2.22e+06    |\n",
      "|    total_reward         | 3.03e+06    |\n",
      "|    total_reward_pct     | 202         |\n",
      "|    total_trades         | 41163       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 866         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009883853 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.000759    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 430         |\n",
      "-----------------------------------------\n",
      "day: 2358, episode: 85\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 232745.60\n",
      "total_reward: -1267254.40\n",
      "total_cost: 1296550.15\n",
      "total_trades: 39948\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.33e+05    |\n",
      "|    total_cost           | 1.3e+06     |\n",
      "|    total_reward         | -1.27e+06   |\n",
      "|    total_reward_pct     | -84.5       |\n",
      "|    total_trades         | 39948       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 884         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012859428 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0323      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.6        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-06-27 to  2019-09-24\n",
      "PPO Sharpe Ratio:  -0.28222091575379005\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_252_1\n",
      "day: 2358, episode: 90\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 683458.80\n",
      "total_reward: -816541.20\n",
      "total_cost: 3783.33\n",
      "total_trades: 25074\n",
      "Sharpe: 0.326\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 6.83e+05  |\n",
      "|    total_cost       | 3.78e+03  |\n",
      "|    total_reward     | -8.17e+05 |\n",
      "|    total_reward_pct | -54.4     |\n",
      "|    total_trades     | 25074     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 40        |\n",
      "|    time_elapsed     | 235       |\n",
      "|    total timesteps  | 9436      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 227       |\n",
      "|    critic_loss      | 47.3      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7077      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.34e+06  |\n",
      "|    total_cost       | 3.53e+03  |\n",
      "|    total_reward     | -1.58e+05 |\n",
      "|    total_reward_pct | -10.5     |\n",
      "|    total_trades     | 25011     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 28        |\n",
      "|    time_elapsed     | 659       |\n",
      "|    total timesteps  | 18872     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 137       |\n",
      "|    critic_loss      | 47.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16513     |\n",
      "-----------------------------------\n",
      "day: 2358, episode: 95\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1283633.15\n",
      "total_reward: -216366.85\n",
      "total_cost: 3728.15\n",
      "total_trades: 25011\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.3e+05  |\n",
      "|    total_cost       | 3.69e+03 |\n",
      "|    total_reward     | -5.7e+05 |\n",
      "|    total_reward_pct | -38      |\n",
      "|    total_trades     | 25010    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 24       |\n",
      "|    time_elapsed     | 1168     |\n",
      "|    total timesteps  | 28308    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 82.9     |\n",
      "|    critic_loss      | 48.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 25949    |\n",
      "----------------------------------\n",
      "day: 2358, episode: 100\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1344035.59\n",
      "total_reward: -155964.41\n",
      "total_cost: 4243.45\n",
      "total_trades: 26797\n",
      "Sharpe: 0.285\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.57e+06 |\n",
      "|    total_cost       | 6.21e+03 |\n",
      "|    total_reward     | 6.69e+04 |\n",
      "|    total_reward_pct | 4.46     |\n",
      "|    total_trades     | 26504    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 1661     |\n",
      "|    total timesteps  | 37744    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 49.5     |\n",
      "|    critic_loss      | 164      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 35385    |\n",
      "----------------------------------\n",
      "day: 2358, episode: 105\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 556850.13\n",
      "total_reward: -943149.87\n",
      "total_cost: 4009.95\n",
      "total_trades: 26407\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.73e+06 |\n",
      "|    total_cost       | 7.61e+03 |\n",
      "|    total_reward     | 2.34e+05 |\n",
      "|    total_reward_pct | 15.6     |\n",
      "|    total_trades     | 26607    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 2126     |\n",
      "|    total timesteps  | 47180    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 28.7     |\n",
      "|    critic_loss      | 47.1     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 44821    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-06-27 to  2019-09-24\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-09-24\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\ensemble_252_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 57.9     |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 5.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 71.1     |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 16.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 154      |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 16.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 5.02e-05 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -455     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 200      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.56e+06  |\n",
      "|    total_cost         | 3.86e+06  |\n",
      "|    total_reward       | 8.06e+06  |\n",
      "|    total_reward_pct   | 538       |\n",
      "|    total_trades       | 41357     |\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 28.5      |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 0.466     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 50       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 94.6     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 5.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 50       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.249    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 9.59     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.0472   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 86        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 48        |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.41      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.11e+05  |\n",
      "|    total_cost         | 1.3e+06   |\n",
      "|    total_reward       | -1.29e+06 |\n",
      "|    total_reward_pct   | -85.9     |\n",
      "|    total_trades       | 39983     |\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -15.3     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.231     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -19.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.459    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 5.82     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 254       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 47.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -93.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.02e+05  |\n",
      "|    total_cost         | 4.78e+05  |\n",
      "|    total_reward       | -7.98e+05 |\n",
      "|    total_reward_pct   | -53.2     |\n",
      "|    total_trades       | 39460     |\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 65.5      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8.75      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -439     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 190      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 138      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 73.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 239      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 60.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -326     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 109      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.55e+06 |\n",
      "|    total_cost         | 8.65e+05 |\n",
      "|    total_reward       | 7.05e+06 |\n",
      "|    total_reward_pct   | 470      |\n",
      "|    total_trades       | 38868    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 2.37     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.426    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 64.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.65     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -885      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 371       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 217       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -334      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 161       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 339       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 104       |\n",
      "-------------------------------------\n",
      "day: 2421, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 3559895.13\n",
      "total_reward: 2059895.13\n",
      "total_cost: 277897.26\n",
      "total_trades: 37114\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.56e+06 |\n",
      "|    total_cost         | 2.78e+05 |\n",
      "|    total_reward       | 2.06e+06 |\n",
      "|    total_reward_pct   | 137      |\n",
      "|    total_trades       | 37114    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -21.8    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 248       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 17.7      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 21.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 1.03e+03 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.05e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -82.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -604     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 221      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.59e+06 |\n",
      "|    total_cost         | 6.62e+04 |\n",
      "|    total_reward       | 5.09e+06 |\n",
      "|    total_reward_pct   | 339      |\n",
      "|    total_trades       | 37555    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -101     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 104      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.03     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 200       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 28.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -429     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 101      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.67e+06 |\n",
      "|    total_cost         | 7.12e+04 |\n",
      "|    total_reward       | 4.17e+06 |\n",
      "|    total_reward_pct   | 278      |\n",
      "|    total_trades       | 37470    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -16.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.44     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 56        |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.34      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 18.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -65.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 361      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 85.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.13e+06 |\n",
      "|    total_cost         | 6.38e+04 |\n",
      "|    total_reward       | 3.63e+06 |\n",
      "|    total_reward_pct   | 242      |\n",
      "|    total_trades       | 37104    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 372      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 34.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.613    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 381      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 71.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 390      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -14.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 25.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 400       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -59.3     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 409       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -118      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 14.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.73e+06 |\n",
      "|    total_cost         | 3.45e+04 |\n",
      "|    total_reward       | 3.23e+06 |\n",
      "|    total_reward_pct   | 215      |\n",
      "|    total_trades       | 39022    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.804    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.262    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 429      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -91.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 438      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 446      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 123      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 448      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 70.8     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 458      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -59.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "day: 2421, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1895976.85\n",
      "total_reward: 395976.85\n",
      "total_cost: 8682.42\n",
      "total_trades: 39516\n",
      "Sharpe: 0.367\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.9e+06  |\n",
      "|    total_cost         | 8.68e+03 |\n",
      "|    total_reward       | 3.96e+05 |\n",
      "|    total_reward_pct   | 26.4     |\n",
      "|    total_trades       | 39516    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 468      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -3.24    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.666    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 478      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -14.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.963    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 488      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -115     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 499      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 44.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 508      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 288      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 56.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.27e+06 |\n",
      "|    total_cost         | 6.6e+04  |\n",
      "|    total_reward       | 2.77e+06 |\n",
      "|    total_reward_pct   | 185      |\n",
      "|    total_trades       | 39187    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 517      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -58.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 526      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -119     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 85.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 534      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 1.81e+03 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.61e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 544       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -1.36e+03 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 953       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 553       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 3.7e-06   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -2.36e+04 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.75e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.52e+06 |\n",
      "|    total_cost         | 5.89e+04 |\n",
      "|    total_reward       | 4.02e+06 |\n",
      "|    total_reward_pct   | 268      |\n",
      "|    total_trades       | 38581    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 562      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 35.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 572      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 133      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 581       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -770      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 540       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 590      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 401      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 95.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.49e+06  |\n",
      "|    total_cost         | 3.71e+04  |\n",
      "|    total_reward       | 1.99e+06  |\n",
      "|    total_reward_pct   | 133       |\n",
      "|    total_trades       | 41304     |\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 600       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -35.8     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1         |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 610      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 338      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 84.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 619      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -194     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 34.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 628      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -188     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 48.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 637       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -50.9     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 26.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.92e+06 |\n",
      "|    total_cost         | 4.48e+04 |\n",
      "|    total_reward       | 5.42e+06 |\n",
      "|    total_reward_pct   | 361      |\n",
      "|    total_trades       | 42550    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 647      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -45.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 22.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 657      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 49.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 666      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -404     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 145      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 676      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 1.06e+03 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 628      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 686       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -85.1     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.1      |\n",
      "-------------------------------------\n",
      "day: 2421, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 3842788.20\n",
      "total_reward: 2342788.20\n",
      "total_cost: 12372.61\n",
      "total_trades: 43005\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.84e+06 |\n",
      "|    total_cost         | 1.24e+04 |\n",
      "|    total_reward       | 2.34e+06 |\n",
      "|    total_reward_pct   | 156      |\n",
      "|    total_trades       | 43005    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 699      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -14.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 709      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 35.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 719      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -630     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 233      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 728      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | -0.234   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -39.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 737      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -37.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.41e+06 |\n",
      "|    total_cost         | 7.17e+03 |\n",
      "|    total_reward       | 9.07e+05 |\n",
      "|    total_reward_pct   | 60.5     |\n",
      "|    total_trades       | 42019    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 746      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 66.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 756      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 46.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 765       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 19        |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 9.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 774      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -35.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 784      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 15.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 25.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.53e+06 |\n",
      "|    total_cost         | 6.13e+03 |\n",
      "|    total_reward       | 1.03e+06 |\n",
      "|    total_reward_pct   | 68.5     |\n",
      "|    total_trades       | 40971    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 795      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 31.9     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 805       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 304       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 130       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 814      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 717      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 391      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 823      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -126     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 833      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -573     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 218      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.44e+06 |\n",
      "|    total_cost         | 6.84e+03 |\n",
      "|    total_reward       | 9.36e+05 |\n",
      "|    total_reward_pct   | 62.4     |\n",
      "|    total_trades       | 40521    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 843      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 43.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.84     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 853       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 91.5      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 23.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 862      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -97.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 873      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 883       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 62        |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.39      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.99e+06 |\n",
      "|    total_cost         | 6.91e+03 |\n",
      "|    total_reward       | 4.88e+05 |\n",
      "|    total_reward_pct   | 32.5     |\n",
      "|    total_trades       | 38148    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 893      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -29.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.781    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 904      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -232     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 27.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 913      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 236      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 71       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 922      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 1.57e+03 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.35e+03 |\n",
      "------------------------------------\n",
      "day: 2421, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 3819107.36\n",
      "total_reward: 2319107.36\n",
      "total_cost: 12790.37\n",
      "total_trades: 35960\n",
      "Sharpe: 0.337\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.82e+06 |\n",
      "|    total_cost         | 1.28e+04 |\n",
      "|    total_reward       | 2.32e+06 |\n",
      "|    total_reward_pct   | 155      |\n",
      "|    total_trades       | 35960    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 931      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -31.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.854    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 940      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 88.3     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 950      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -91.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 16.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 958      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -263     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 42.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 967      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -3.09    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0821   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.1e+06  |\n",
      "|    total_cost         | 5.6e+03  |\n",
      "|    total_reward       | 5.97e+05 |\n",
      "|    total_reward_pct   | 39.8     |\n",
      "|    total_trades       | 37074    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 977      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 44.5     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 987      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -109     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 997      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 1007     |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -88.1    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 6.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 1016     |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -249     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 41.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.87e+06  |\n",
      "|    total_cost         | 6.07e+03  |\n",
      "|    total_reward       | 3.73e+05  |\n",
      "|    total_reward_pct   | 24.9      |\n",
      "|    total_trades       | 39550     |\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 1026      |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | 9.4       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.321     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 1035     |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -53.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 1044     |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -125     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 10       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 1054     |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -268     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 50.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 1064      |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | 229       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 34.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.68e+06 |\n",
      "|    total_cost         | 9.55e+03 |\n",
      "|    total_reward       | 1.79e+05 |\n",
      "|    total_reward_pct   | 11.9     |\n",
      "|    total_trades       | 39021    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 1075     |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 15.5     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.353    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 1085     |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -43.7    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 8.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 1095     |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -206     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 31.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 1106     |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 472      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 133      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 1116     |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 406      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 104      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.13e+06 |\n",
      "|    total_cost         | 1.12e+05 |\n",
      "|    total_reward       | 2.63e+06 |\n",
      "|    total_reward_pct   | 175      |\n",
      "|    total_trades       | 40582    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 1124     |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 26.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.511    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 1133     |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -124     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 1142     |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 13.6     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.764    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 1151     |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 14.1     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 1161     |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 3.49     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.23     |\n",
      "------------------------------------\n",
      "day: 2421, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2995687.74\n",
      "total_reward: 1495687.74\n",
      "total_cost: 48280.36\n",
      "total_trades: 40179\n",
      "Sharpe: 0.584\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3e+06    |\n",
      "|    total_cost         | 4.83e+04 |\n",
      "|    total_reward       | 1.5e+06  |\n",
      "|    total_reward_pct   | 99.7     |\n",
      "|    total_trades       | 40179    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 1172     |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 54.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 1184     |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -56.6    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 31.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 1195     |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 96.8     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 32       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 1203     |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 26.4     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 5.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.1e+06  |\n",
      "|    total_cost         | 1.55e+05 |\n",
      "|    total_reward       | 3.6e+06  |\n",
      "|    total_reward_pct   | 240      |\n",
      "|    total_trades       | 40521    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 1212     |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -38.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 1221     |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 256      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 37.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 1231     |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 436      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 107      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 1240     |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 16.2     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 9.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 1250     |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -231     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 42.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.36e+06  |\n",
      "|    total_cost         | 9.43e+04  |\n",
      "|    total_reward       | 4.86e+06  |\n",
      "|    total_reward_pct   | 324       |\n",
      "|    total_trades       | 37746     |\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 1261      |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 5.05      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.56      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 1273     |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 136      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 1282     |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -66.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 1291      |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | -15       |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.54      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 1301      |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -99.3     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 10.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.55e+06 |\n",
      "|    total_cost         | 4.76e+04 |\n",
      "|    total_reward       | 5.36e+04 |\n",
      "|    total_reward_pct   | 3.57     |\n",
      "|    total_trades       | 35328    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 1309     |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -7.66    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.562    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 1318     |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 139      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 1327      |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 43.7      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 3.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 1336      |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 232       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 32.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 1347      |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -46.5     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.2       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.14e+05  |\n",
      "|    total_cost         | 1.56e+05  |\n",
      "|    total_reward       | -5.86e+05 |\n",
      "|    total_reward_pct   | -39.1     |\n",
      "|    total_trades       | 35582     |\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 1358      |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -67.9     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 3.67      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 1368     |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -60.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 3.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 1379     |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -346     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 65.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 1389      |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 35.1      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.823     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 1398     |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -93.2    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 36.2     |\n",
      "------------------------------------\n",
      "day: 2421, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 3375205.37\n",
      "total_reward: 1875205.37\n",
      "total_cost: 1120254.78\n",
      "total_trades: 33708\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.38e+06 |\n",
      "|    total_cost         | 1.12e+06 |\n",
      "|    total_reward       | 1.88e+06 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 33708    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 1407     |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -78.5    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 3.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 1417     |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -258     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 78.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 1427      |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -1.14e+03 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.11e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 1437     |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -207     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 54.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 1448      |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | 660       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 429       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.26e+06 |\n",
      "|    total_cost         | 5.05e+05 |\n",
      "|    total_reward       | 3.76e+06 |\n",
      "|    total_reward_pct   | 251      |\n",
      "|    total_trades       | 33789    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 1457     |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -98.8    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 6.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 1467     |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -244     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 133      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 1476     |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 1.25e+03 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.02e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 1485     |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -368     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 84.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 1495      |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | 825       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 375       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.31e+06 |\n",
      "|    total_cost         | 1.9e+05  |\n",
      "|    total_reward       | 1.81e+06 |\n",
      "|    total_reward_pct   | 121      |\n",
      "|    total_trades       | 33208    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 1503     |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 88.9     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 4.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 1512     |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 725      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 429      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 1522      |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | -258      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 42.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 1532     |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 537      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 225      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.81e+06 |\n",
      "|    total_cost         | 3.01e+04 |\n",
      "|    total_reward       | 1.31e+06 |\n",
      "|    total_reward_pct   | 87.7     |\n",
      "|    total_trades       | 33075    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 1543     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 34.8     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 1552      |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -66.9     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 4.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 1562     |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 186      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 38.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 1571     |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 279      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 105      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 1581     |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 366      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 69.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.95e+06 |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | 1.45e+06 |\n",
      "|    total_reward_pct   | 96.8     |\n",
      "|    total_trades       | 32732    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 1591     |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -119     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 1600     |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -18      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 1609     |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -130     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 9.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 1618     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 127      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 1628     |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -66      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 6.09     |\n",
      "------------------------------------\n",
      "day: 2421, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2388425.59\n",
      "total_reward: 888425.59\n",
      "total_cost: 22750.90\n",
      "total_trades: 31564\n",
      "Sharpe: 0.368\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.39e+06 |\n",
      "|    total_cost         | 2.28e+04 |\n",
      "|    total_reward       | 8.88e+05 |\n",
      "|    total_reward_pct   | 59.2     |\n",
      "|    total_trades       | 31564    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 1638     |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.977   |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.559    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 1650     |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -50.8    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 1661     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 305      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 73.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 1670     |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 105      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 8.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 1679     |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -6.66    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.58e+06 |\n",
      "|    total_cost         | 2.94e+04 |\n",
      "|    total_reward       | 7.92e+04 |\n",
      "|    total_reward_pct   | 5.28     |\n",
      "|    total_trades       | 31533    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 1688     |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 44.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 1697     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -89.9    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 8.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 1707     |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -49.1    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 1718     |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -12.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 4.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 1727     |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -88      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 16.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.72e+06  |\n",
      "|    total_cost         | 1.54e+04  |\n",
      "|    total_reward       | 2.18e+05  |\n",
      "|    total_reward_pct   | 14.5      |\n",
      "|    total_trades       | 32018     |\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 1736      |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | -14.7     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.197     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 1746     |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -203     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 24.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 1755     |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -265     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 42.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 1765     |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 42.8     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.35     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 1776      |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -171      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.44e+06 |\n",
      "|    total_cost         | 1.53e+04 |\n",
      "|    total_reward       | 9.45e+05 |\n",
      "|    total_reward_pct   | 63       |\n",
      "|    total_trades       | 32591    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 1787     |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 9.71     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 1796     |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -300     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 49.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 1804     |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -255     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 34.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 1814     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 43       |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 21.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.4e+06  |\n",
      "|    total_cost         | 6.12e+03 |\n",
      "|    total_reward       | 8.99e+05 |\n",
      "|    total_reward_pct   | 59.9     |\n",
      "|    total_trades       | 32267    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 1822     |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 24.4     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.454    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 1832     |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 100      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 8.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 1842     |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -155     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 75.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 1852      |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 33.1      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 7.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 1862     |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 41.6     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 5.2      |\n",
      "------------------------------------\n",
      "day: 2421, episode: 40\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 4718916.02\n",
      "total_reward: 3218916.02\n",
      "total_cost: 9785.50\n",
      "total_trades: 33331\n",
      "Sharpe: 0.379\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.72e+06  |\n",
      "|    total_cost         | 9.79e+03  |\n",
      "|    total_reward       | 3.22e+06  |\n",
      "|    total_reward_pct   | 215       |\n",
      "|    total_trades       | 33331     |\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 1871      |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | 79.2      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 4.08      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 1880     |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 9.67     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.454    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 1891     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 53.6     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 1903     |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 92.9     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 1914     |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -141     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.5e+06  |\n",
      "|    total_cost         | 3.56e+03 |\n",
      "|    total_reward       | 327      |\n",
      "|    total_reward_pct   | 0.0218   |\n",
      "|    total_trades       | 34358    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 1924     |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 43.3     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 1938     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 187      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 20       |\n",
      "------------------------------------\n",
      "======Trading from:  2019-09-24 to  2019-12-20\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  397.3376832837864\n",
      "======Model training from:  2000-01-01 to  2019-09-24\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_315_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | -0.0107  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 87.5     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 8.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 50       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 288      |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 55       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 54.4     |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.0361   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -29.1    |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 0.793    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.47e+05  |\n",
      "|    total_cost         | 2.55e+06  |\n",
      "|    total_reward       | -1.05e+06 |\n",
      "|    total_reward_pct   | -70.2     |\n",
      "|    total_trades       | 41905     |\n",
      "| time/                 |           |\n",
      "|    fps                | 42        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 37.2      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 40        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 320       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 84.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 41       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.177    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 259      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 45.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 41       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 78.7     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 4.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 41       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0.0185   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -85.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.69e+06 |\n",
      "|    total_cost         | 9.78e+05 |\n",
      "|    total_reward       | 1.91e+05 |\n",
      "|    total_reward_pct   | 12.7     |\n",
      "|    total_trades       | 37985    |\n",
      "| time/                 |          |\n",
      "|    fps                | 41       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -1.39    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.042    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 41       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -3.63    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0189   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 41       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 10.9     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0847   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 42        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 16.5      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.174     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 42       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -292     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -18.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.241    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.11e+04  |\n",
      "|    total_cost         | 3.44e+05  |\n",
      "|    total_reward       | -1.41e+06 |\n",
      "|    total_reward_pct   | -93.9     |\n",
      "|    total_trades       | 38673     |\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 88.5      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 4.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 1.39     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.192    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -69.5    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 42       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -14.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.968    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 41       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.642    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.14e+05  |\n",
      "|    total_cost         | 1.84e+05  |\n",
      "|    total_reward       | -9.86e+05 |\n",
      "|    total_reward_pct   | -65.7     |\n",
      "|    total_trades       | 40063     |\n",
      "| time/                 |           |\n",
      "|    fps                | 41        |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 35.7      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.04      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 41       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -23      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 42       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -222     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 33.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 42       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0.0244   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -6.75    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 42       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 144      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "day: 2421, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 662865.90\n",
      "total_reward: -837134.10\n",
      "total_cost: 102526.91\n",
      "total_trades: 39990\n",
      "Sharpe: 0.321\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.63e+05  |\n",
      "|    total_cost         | 1.03e+05  |\n",
      "|    total_reward       | -8.37e+05 |\n",
      "|    total_reward_pct   | -55.8     |\n",
      "|    total_trades       | 39990     |\n",
      "| time/                 |           |\n",
      "|    fps                | 42        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 294       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -6.21     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.107     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 42        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -57.7     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.92      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 42       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 240      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 54.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 42       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -38.6    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 42       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 337      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -48      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.13     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.32e+06  |\n",
      "|    total_cost         | 1.13e+05  |\n",
      "|    total_reward       | -1.83e+05 |\n",
      "|    total_reward_pct   | -12.2     |\n",
      "|    total_trades       | 41543     |\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 347       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -40.3     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.89      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 357       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 396       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 86.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 369       |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 67.7      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 5.74      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 381      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 8.93     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 7.34     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.43e+06  |\n",
      "|    total_cost         | 4.47e+04  |\n",
      "|    total_reward       | -7.16e+04 |\n",
      "|    total_reward_pct   | -4.77     |\n",
      "|    total_trades       | 39560     |\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 393       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 4.2       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0163    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 403      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 70.1     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 4.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 413       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 27.5      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.96      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 424       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 21.4      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.21      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 435      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 87.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 8.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.02e+06 |\n",
      "|    total_cost         | 2.82e+04 |\n",
      "|    total_reward       | 5.2e+05  |\n",
      "|    total_reward_pct   | 34.7     |\n",
      "|    total_trades       | 39847    |\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 446      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 214      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 25.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 456      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 164      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 33.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 467      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -302     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 354      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 477      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -250     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 86.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 488      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 85.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.86e+06  |\n",
      "|    total_cost         | 2.03e+05  |\n",
      "|    total_reward       | 3.36e+06  |\n",
      "|    total_reward_pct   | 224       |\n",
      "|    total_trades       | 41609     |\n",
      "| time/                 |           |\n",
      "|    fps                | 44        |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 499       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 16        |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.339     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 510      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -25.6    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.18     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 523       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 177       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 16.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 534      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 361      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 76.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 544      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 561      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 144      |\n",
      "------------------------------------\n",
      "day: 2421, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2248937.85\n",
      "total_reward: 748937.85\n",
      "total_cost: 138349.98\n",
      "total_trades: 41975\n",
      "Sharpe: 0.414\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.25e+06  |\n",
      "|    total_cost         | 1.38e+05  |\n",
      "|    total_reward       | 7.49e+05  |\n",
      "|    total_reward_pct   | 49.9      |\n",
      "|    total_trades       | 41975     |\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 557       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -78.7     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 7         |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 573      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 613      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 205      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 583      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -76      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 19.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 593      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -151     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 18       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 603       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 304       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 45.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.46e+06 |\n",
      "|    total_cost         | 2.61e+04 |\n",
      "|    total_reward       | 1.96e+06 |\n",
      "|    total_reward_pct   | 131      |\n",
      "|    total_trades       | 41805    |\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 617      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -64.1    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 631       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 129       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 13.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 641      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -92.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 6.72     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 652       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 258       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 37.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 664      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -568     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 172      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.12e+06  |\n",
      "|    total_cost         | 1.92e+04  |\n",
      "|    total_reward       | 6.25e+05  |\n",
      "|    total_reward_pct   | 41.7      |\n",
      "|    total_trades       | 40002     |\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 48.8      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.97      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 692      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -27      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.542    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 703      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -48.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 713      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 3.07     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.224    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.21e+05  |\n",
      "|    total_cost         | 6.15e+03  |\n",
      "|    total_reward       | -7.79e+05 |\n",
      "|    total_reward_pct   | -52       |\n",
      "|    total_trades       | 38711     |\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 724       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -15.1     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.188     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 737      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 204      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 25.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 749      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -1.91    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.928    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 761      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -15.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 6.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 772      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -124     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 21.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.36e+06  |\n",
      "|    total_cost         | 2.77e+04  |\n",
      "|    total_reward       | 2.86e+06  |\n",
      "|    total_reward_pct   | 191       |\n",
      "|    total_trades       | 38959     |\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 782       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -18.9     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.836     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 795      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -176     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 18       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 807      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 117      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 8.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 819      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.835    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 832      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 12.9     |\n",
      "------------------------------------\n",
      "day: 2421, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1124776.96\n",
      "total_reward: -375223.04\n",
      "total_cost: 12751.28\n",
      "total_trades: 37604\n",
      "Sharpe: 0.308\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.12e+06  |\n",
      "|    total_cost         | 1.28e+04  |\n",
      "|    total_reward       | -3.75e+05 |\n",
      "|    total_reward_pct   | -25       |\n",
      "|    total_trades       | 37604     |\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 843       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -83.3     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 3.98      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 854       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 168       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 27.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 866      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -271     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 54.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 878       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 538       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 150       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 890      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 463      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 157      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.71e+06 |\n",
      "|    total_cost         | 1.85e+04 |\n",
      "|    total_reward       | 2.21e+06 |\n",
      "|    total_reward_pct   | 147      |\n",
      "|    total_trades       | 35933    |\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 901      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 81.2     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 3.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 912      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -282     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 55.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 922      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 227      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 34.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 933      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -190     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 36.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 944       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 194       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 31.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.8e+06  |\n",
      "|    total_cost         | 1.92e+04 |\n",
      "|    total_reward       | 2.3e+06  |\n",
      "|    total_reward_pct   | 153      |\n",
      "|    total_trades       | 34998    |\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 956      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 127      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 9.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 966      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -99.6    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 8.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 977      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 187      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 21       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 988      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 61.7     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 13.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 999       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -271      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 56.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.74e+06  |\n",
      "|    total_cost         | 1.61e+04  |\n",
      "|    total_reward       | 1.24e+06  |\n",
      "|    total_reward_pct   | 82.5      |\n",
      "|    total_trades       | 35225     |\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 1011      |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 137       |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 12.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 1023     |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 79.3     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 72.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 1034     |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -206     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 26.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 1040      |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 31.9      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 3.98      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 43       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 1046     |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 483      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 140      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.25e+06 |\n",
      "|    total_cost         | 1.84e+04 |\n",
      "|    total_reward       | 1.75e+06 |\n",
      "|    total_reward_pct   | 117      |\n",
      "|    total_trades       | 34892    |\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 1051     |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -22.6    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.345    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 44        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 1057      |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -94.9     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 5.08      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 1063     |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 79       |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 8.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 44       |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 1068     |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 597      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 199      |\n",
      "------------------------------------\n",
      "day: 2421, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1711501.79\n",
      "total_reward: 211501.79\n",
      "total_cost: 7551.87\n",
      "total_trades: 33004\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.71e+06 |\n",
      "|    total_cost         | 7.55e+03 |\n",
      "|    total_reward       | 2.12e+05 |\n",
      "|    total_reward_pct   | 14.1     |\n",
      "|    total_trades       | 33004    |\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 1074     |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 35.2     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 45       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 1080     |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 59.8     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 5.06     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 45        |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 1085      |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -14.9     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 3.6       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 45        |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 1091      |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -167      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 16.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 1096     |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 40.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.37e+06 |\n",
      "|    total_cost         | 4.8e+03  |\n",
      "|    total_reward       | -1.3e+05 |\n",
      "|    total_reward_pct   | -8.65    |\n",
      "|    total_trades       | 32830    |\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 1101     |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 90       |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 4.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 1107     |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -161     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 17.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 1112     |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 41.8     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 46       |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 1117     |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 133      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 14.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 1122     |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -418     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 132      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.74e+06 |\n",
      "|    total_cost         | 1.37e+04 |\n",
      "|    total_reward       | 2.42e+05 |\n",
      "|    total_reward_pct   | 16.1     |\n",
      "|    total_trades       | 32475    |\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 1128     |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 188      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 44.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 1134     |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -55.8    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 47       |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 1139     |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -272     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 39.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 1145     |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -677     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 286      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 1152     |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -161     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 67.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.92e+06  |\n",
      "|    total_cost         | 1.44e+04  |\n",
      "|    total_reward       | 1.42e+06  |\n",
      "|    total_reward_pct   | 94.7      |\n",
      "|    total_trades       | 32286     |\n",
      "| time/                 |           |\n",
      "|    fps                | 48        |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 1157      |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | -16.5     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.305     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 1163     |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -18.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 1169     |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 23.2     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 48       |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 1175     |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 14.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 1181     |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 245      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 38       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.73e+06 |\n",
      "|    total_cost         | 3.42e+04 |\n",
      "|    total_reward       | 2.23e+06 |\n",
      "|    total_reward_pct   | 148      |\n",
      "|    total_trades       | 30559    |\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 1187     |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 127      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 8.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 1193     |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -264     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 47.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 1199     |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 409      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 92.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 49       |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 1205     |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -104     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 25.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 49        |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 1210      |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | -45.6     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 10        |\n",
      "-------------------------------------\n",
      "day: 2421, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2363050.74\n",
      "total_reward: 863050.74\n",
      "total_cost: 62710.25\n",
      "total_trades: 33509\n",
      "Sharpe: 0.340\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.36e+06 |\n",
      "|    total_cost         | 6.27e+04 |\n",
      "|    total_reward       | 8.63e+05 |\n",
      "|    total_reward_pct   | 57.5     |\n",
      "|    total_trades       | 33509    |\n",
      "| time/                 |          |\n",
      "|    fps                | 50       |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 1216     |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 44.1     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 50        |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 1221      |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -67.1     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 8.1       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 50        |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 1227      |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -48.4     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 50        |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 1232      |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -39.1     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 4.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.25e+06  |\n",
      "|    total_cost         | 3.88e+04  |\n",
      "|    total_reward       | 7.51e+05  |\n",
      "|    total_reward_pct   | 50.1      |\n",
      "|    total_trades       | 33304     |\n",
      "| time/                 |           |\n",
      "|    fps                | 50        |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 1237      |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | -55       |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 2.97      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 1243     |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 3.1      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.882    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 1248     |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 66.6     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 1254     |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 83.9     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 4.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 1260     |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -513     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 134      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.7e+06  |\n",
      "|    total_cost         | 1.43e+04 |\n",
      "|    total_reward       | 2.02e+05 |\n",
      "|    total_reward_pct   | 13.5     |\n",
      "|    total_trades       | 32489    |\n",
      "| time/                 |          |\n",
      "|    fps                | 51       |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 1266     |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 99.4     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 17.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 51        |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 1271      |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | 174       |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 34.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 1277     |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 43.9     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 1282     |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 109      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 9.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 1287     |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -9.2     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 18.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.91e+06 |\n",
      "|    total_cost         | 1.09e+04 |\n",
      "|    total_reward       | 4.09e+05 |\n",
      "|    total_reward_pct   | 27.3     |\n",
      "|    total_trades       | 31167    |\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 1293     |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 85.2     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 4.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 52       |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 1298     |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -29.9    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 52        |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 1303      |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 101       |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 5.64      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 1309     |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 43.8     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 4.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 1315     |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 124      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 9.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.84e+06 |\n",
      "|    total_cost         | 1.43e+04 |\n",
      "|    total_reward       | 3.43e+05 |\n",
      "|    total_reward_pct   | 22.9     |\n",
      "|    total_trades       | 31106    |\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 1320     |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -18.7    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.504    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 1326     |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -66.3    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 4.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 1332     |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -92.1    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 1338     |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -179     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 25       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 53       |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 1345     |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 258      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 65.3     |\n",
      "------------------------------------\n",
      "day: 2421, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2174429.64\n",
      "total_reward: 674429.64\n",
      "total_cost: 25065.43\n",
      "total_trades: 30633\n",
      "Sharpe: 0.321\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.17e+06 |\n",
      "|    total_cost         | 2.51e+04 |\n",
      "|    total_reward       | 6.74e+05 |\n",
      "|    total_reward_pct   | 45       |\n",
      "|    total_trades       | 30633    |\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 1351     |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -27.8    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.627    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 1357     |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -89.8    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 8.07     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 1362      |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -162      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 24.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 1367     |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -57.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 5.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 1372     |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 245      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 38.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.48e+06  |\n",
      "|    total_cost         | 4.46e+04  |\n",
      "|    total_reward       | 1.98e+06  |\n",
      "|    total_reward_pct   | 132       |\n",
      "|    total_trades       | 30360     |\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 1378      |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -27.1     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.2       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 1383     |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -72.3    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 1388     |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 291      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 56.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 1394     |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -29.9    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 1400     |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 77.4     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.6e+06  |\n",
      "|    total_cost         | 1.42e+04 |\n",
      "|    total_reward       | 1.02e+05 |\n",
      "|    total_reward_pct   | 6.8      |\n",
      "|    total_trades       | 30487    |\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 1405     |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -12.5    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 1411     |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 76.2     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 17.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 1416     |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -59.2    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 1422     |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 55       |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.23e+06 |\n",
      "|    total_cost         | 2.09e+04 |\n",
      "|    total_reward       | 7.31e+05 |\n",
      "|    total_reward_pct   | 48.7     |\n",
      "|    total_trades       | 30733    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 1427     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 75.8     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.75     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 1432      |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -30.3     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.491     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 1437     |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 196      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 22.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 1442     |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 117      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 8.17     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 1448      |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -9.87     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 60.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.69e+06 |\n",
      "|    total_cost         | 1.41e+04 |\n",
      "|    total_reward       | 1.9e+05  |\n",
      "|    total_reward_pct   | 12.7     |\n",
      "|    total_trades       | 30938    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 1454     |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 7.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 1459     |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -66.9    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 1466      |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -81.7     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 3.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 1472     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 59.9     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 1479     |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -284     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 39.8     |\n",
      "------------------------------------\n",
      "day: 2421, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1873863.73\n",
      "total_reward: 373863.73\n",
      "total_cost: 17694.08\n",
      "total_trades: 29884\n",
      "Sharpe: 0.286\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.87e+06  |\n",
      "|    total_cost         | 1.77e+04  |\n",
      "|    total_reward       | 3.74e+05  |\n",
      "|    total_reward_pct   | 24.9      |\n",
      "|    total_trades       | 29884     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 1484      |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | -26       |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 5.5       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 1490     |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -33.6    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 1495     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 26.1     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.369    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 1500     |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -137     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 1505      |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | -294      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 48.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.83e+06 |\n",
      "|    total_cost         | 5.25e+03 |\n",
      "|    total_reward       | 3.32e+05 |\n",
      "|    total_reward_pct   | 22.1     |\n",
      "|    total_trades       | 30089    |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 1510     |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -55      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 1516     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -29.6    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 1521     |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 18.4     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 1527     |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 25.3     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 17.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 1533     |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -98.4    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 7.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.56e+06 |\n",
      "|    total_cost         | 3.14e+03 |\n",
      "|    total_reward       | 6.05e+04 |\n",
      "|    total_reward_pct   | 4.03     |\n",
      "|    total_trades       | 31004    |\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 1539     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 36.1     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.797    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 1545     |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -16.1    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 1550     |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -204     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 26.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 1555     |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 189      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 25.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 1560     |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -318     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 50.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.49e+06  |\n",
      "|    total_cost         | 3.85e+03  |\n",
      "|    total_reward       | -8.48e+03 |\n",
      "|    total_reward_pct   | -0.565    |\n",
      "|    total_trades       | 31129     |\n",
      "| time/                 |           |\n",
      "|    fps                | 59        |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 1566      |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | 4.7       |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 4.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 1572     |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -147     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 14.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 1577     |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -262     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 42       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 1584     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 150      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 21.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.81e+06 |\n",
      "|    total_cost         | 9.73e+03 |\n",
      "|    total_reward       | 3.09e+05 |\n",
      "|    total_reward_pct   | 20.6     |\n",
      "|    total_trades       | 30739    |\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 1589     |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -19      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.696    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 1596     |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 27.1     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 1603     |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | 27.6     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 1609     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 137      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 1615     |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 38.1     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.56     |\n",
      "------------------------------------\n",
      "day: 2421, episode: 40\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2037701.92\n",
      "total_reward: 537701.92\n",
      "total_cost: 7081.73\n",
      "total_trades: 30366\n",
      "Sharpe: 0.307\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.04e+06 |\n",
      "|    total_cost         | 7.08e+03 |\n",
      "|    total_reward       | 5.38e+05 |\n",
      "|    total_reward_pct   | 35.8     |\n",
      "|    total_trades       | 30366    |\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 1621     |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 142      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 9.51     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 59        |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 1627      |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | -143      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 12.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 1633     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -162     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 1639     |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 222      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 41.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 1645     |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -198     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 21       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.77e+06 |\n",
      "|    total_cost         | 8.5e+03  |\n",
      "|    total_reward       | 2.69e+05 |\n",
      "|    total_reward_pct   | 17.9     |\n",
      "|    total_trades       | 30453    |\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 1651     |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 60.5     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 1656     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 71.3     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.04     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-09-24 to  2019-12-20\n",
      "A2C Sharpe Ratio:  0.2480891206251829\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_315_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 92   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 22   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.07e+04    |\n",
      "|    total_cost           | 1.51e+06    |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.6       |\n",
      "|    total_trades         | 40193       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015492026 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0311      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.15        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 6.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.47e+04    |\n",
      "|    total_cost           | 8.6e+05     |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -97.7       |\n",
      "|    total_trades         | 39247       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015446648 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0461      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 6.96        |\n",
      "-----------------------------------------\n",
      "day: 2421, episode: 45\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 102513.46\n",
      "total_reward: -1397486.54\n",
      "total_cost: 1678570.98\n",
      "total_trades: 40806\n",
      "Sharpe: -0.304\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 1.68e+06    |\n",
      "|    total_reward         | -1.4e+06    |\n",
      "|    total_reward_pct     | -93.2       |\n",
      "|    total_trades         | 40806       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014151722 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.077       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.21        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.57        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 5.96e+04     |\n",
      "|    total_cost           | 1.03e+06     |\n",
      "|    total_reward         | -1.44e+06    |\n",
      "|    total_reward_pct     | -96          |\n",
      "|    total_trades         | 39280        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077933315 |\n",
      "|    clip_fraction        | 0.227        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.8        |\n",
      "|    explained_variance   | 0.0418       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.88         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 8.05e+04     |\n",
      "|    total_cost           | 8.53e+05     |\n",
      "|    total_reward         | -1.42e+06    |\n",
      "|    total_reward_pct     | -94.6        |\n",
      "|    total_trades         | 39251        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155629255 |\n",
      "|    clip_fraction        | 0.221        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.9        |\n",
      "|    explained_variance   | 0.0613       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.393        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.65         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 89         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 159        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02228789 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.056      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.29       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 9.86       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.93e+04    |\n",
      "|    total_cost           | 4.11e+05    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.7       |\n",
      "|    total_trades         | 38329       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020083696 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.294      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.332       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+05    |\n",
      "|    total_cost           | 1.26e+06    |\n",
      "|    total_reward         | -1.27e+06   |\n",
      "|    total_reward_pct     | -84.9       |\n",
      "|    total_trades         | 40329       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014755841 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0494      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.56        |\n",
      "-----------------------------------------\n",
      "day: 2421, episode: 50\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 34.50\n",
      "total_reward: -1499965.50\n",
      "total_cost: 1326520.44\n",
      "total_trades: 40496\n",
      "Sharpe: 0.392\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 34.5        |\n",
      "|    total_cost           | 1.33e+06    |\n",
      "|    total_reward         | -1.5e+06    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 40496       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013665536 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0905      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.48        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.9         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.37e+04     |\n",
      "|    total_cost           | 1.28e+06     |\n",
      "|    total_reward         | -1.46e+06    |\n",
      "|    total_reward_pct     | -97.1        |\n",
      "|    total_trades         | 40411        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107459985 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.5        |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.777        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 6.69         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.52e+04   |\n",
      "|    total_cost           | 1.12e+06   |\n",
      "|    total_reward         | -1.44e+06  |\n",
      "|    total_reward_pct     | -96.3      |\n",
      "|    total_trades         | 40110      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 88         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 277        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02634021 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.143      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.26       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 6.45       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024966769 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0678      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.437       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.19e+04   |\n",
      "|    total_cost           | 6.21e+05    |\n",
      "|    total_reward         | -1.51e+06   |\n",
      "|    total_reward_pct     | -101        |\n",
      "|    total_trades         | 39040       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022081275 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.172      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.608       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.37e+05    |\n",
      "|    total_cost           | 1.23e+06    |\n",
      "|    total_reward         | -1.36e+06   |\n",
      "|    total_reward_pct     | -90.9       |\n",
      "|    total_trades         | 40983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010597838 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.076       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.79        |\n",
      "-----------------------------------------\n",
      "day: 2421, episode: 55\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 209088.60\n",
      "total_reward: -1290911.40\n",
      "total_cost: 1380680.55\n",
      "total_trades: 41043\n",
      "Sharpe: -0.164\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.09e+05    |\n",
      "|    total_cost           | 1.38e+06    |\n",
      "|    total_reward         | -1.29e+06   |\n",
      "|    total_reward_pct     | -86.1       |\n",
      "|    total_trades         | 41043       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021294601 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0884      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.36        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.55e+04    |\n",
      "|    total_cost           | 7.13e+05    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98.3       |\n",
      "|    total_trades         | 39413       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011009255 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.096       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.511       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.02e+04    |\n",
      "|    total_cost           | 8.46e+05    |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -94.7       |\n",
      "|    total_trades         | 39656       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014782408 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.855       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.6e+05     |\n",
      "|    total_cost           | 1.56e+06    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.3       |\n",
      "|    total_trades         | 41198       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019928783 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.455       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.99        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 456         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019736547 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.08        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.25        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.75        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.18e+05   |\n",
      "|    total_cost           | 2.26e+06   |\n",
      "|    total_reward         | -1.08e+06  |\n",
      "|    total_reward_pct     | -72.1      |\n",
      "|    total_trades         | 41953      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 89         |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 480        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01035261 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.024      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.7       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 32.1       |\n",
      "----------------------------------------\n",
      "day: 2421, episode: 60\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 290559.91\n",
      "total_reward: -1209440.09\n",
      "total_cost: 1931610.79\n",
      "total_trades: 42139\n",
      "Sharpe: 0.317\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.91e+05    |\n",
      "|    total_cost           | 1.93e+06    |\n",
      "|    total_reward         | -1.21e+06   |\n",
      "|    total_reward_pct     | -80.6       |\n",
      "|    total_trades         | 42139       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 505         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023004033 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.38e+06    |\n",
      "|    total_cost           | 3.52e+06    |\n",
      "|    total_reward         | -1.16e+05   |\n",
      "|    total_reward_pct     | -7.73       |\n",
      "|    total_trades         | 43993       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018107936 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0751      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.58e+05   |\n",
      "|    total_cost           | 1.06e+06   |\n",
      "|    total_reward         | -1.34e+06  |\n",
      "|    total_reward_pct     | -89.5      |\n",
      "|    total_trades         | 40654      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 89         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 551        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02067935 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.209      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.8       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.00752   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 29.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.27e+05    |\n",
      "|    total_cost           | 2.7e+06     |\n",
      "|    total_reward         | -7.73e+05   |\n",
      "|    total_reward_pct     | -51.5       |\n",
      "|    total_trades         | 42848       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021892415 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.34        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 88         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 600        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08624929 |\n",
      "|    clip_fraction        | 0.394      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.245      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.3       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | 0.0316     |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 42.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.35e+05    |\n",
      "|    total_cost           | 2.29e+06    |\n",
      "|    total_reward         | -9.65e+05   |\n",
      "|    total_reward_pct     | -64.3       |\n",
      "|    total_trades         | 42835       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015722778 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "day: 2421, episode: 65\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 425028.40\n",
      "total_reward: -1074971.60\n",
      "total_cost: 1564778.35\n",
      "total_trades: 41859\n",
      "Sharpe: 0.049\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.25e+05     |\n",
      "|    total_cost           | 1.56e+06     |\n",
      "|    total_reward         | -1.07e+06    |\n",
      "|    total_reward_pct     | -71.7        |\n",
      "|    total_trades         | 41859        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 648          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039708167 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.3        |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 8.14         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | -1.47e+03   |\n",
      "|    total_cost           | 4.22e+05    |\n",
      "|    total_reward         | -1.5e+06    |\n",
      "|    total_reward_pct     | -100        |\n",
      "|    total_trades         | 38983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012225991 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.454       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 7.9         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.46e+05   |\n",
      "|    total_cost           | 1.73e+06   |\n",
      "|    total_reward         | -1.35e+06  |\n",
      "|    total_reward_pct     | -90.3      |\n",
      "|    total_trades         | 42212      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 85         |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 717        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01522718 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.439      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.5        |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 21.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.79e+05   |\n",
      "|    total_cost           | 1.97e+06   |\n",
      "|    total_reward         | -9.21e+05  |\n",
      "|    total_reward_pct     | -61.4      |\n",
      "|    total_trades         | 42431      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 84         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 747        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02807331 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.58       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 23.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.02e+05    |\n",
      "|    total_cost           | 4.5e+05     |\n",
      "|    total_reward         | -1.4e+06    |\n",
      "|    total_reward_pct     | -93.2       |\n",
      "|    total_trades         | 39179       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018229641 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.8        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 83        |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 812       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0332355 |\n",
      "|    clip_fraction        | 0.242     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -44.8     |\n",
      "|    explained_variance   | 0.758     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.513     |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -0.00827  |\n",
      "|    std                  | 1.08      |\n",
      "|    value_loss           | 3.82      |\n",
      "---------------------------------------\n",
      "day: 2421, episode: 70\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1699787.18\n",
      "total_reward: 199787.18\n",
      "total_cost: 1735803.42\n",
      "total_trades: 42045\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.7e+06     |\n",
      "|    total_cost           | 1.74e+06    |\n",
      "|    total_reward         | 2e+05       |\n",
      "|    total_reward_pct     | 13.3        |\n",
      "|    total_trades         | 42045       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 847         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018060967 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.00783     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.54e+05     |\n",
      "|    total_cost           | 1.33e+06     |\n",
      "|    total_reward         | -7.46e+05    |\n",
      "|    total_reward_pct     | -49.7        |\n",
      "|    total_trades         | 41286        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 887          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118045155 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.9        |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.9          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 19.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.42e+06    |\n",
      "|    total_cost           | 1.43e+06    |\n",
      "|    total_reward         | -7.66e+04   |\n",
      "|    total_reward_pct     | -5.11       |\n",
      "|    total_trades         | 41496       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 919         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012517277 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.47e+05    |\n",
      "|    total_cost           | 1.47e+06    |\n",
      "|    total_reward         | -7.53e+05   |\n",
      "|    total_reward_pct     | -50.2       |\n",
      "|    total_trades         | 41462       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 955         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013639787 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.79e+05    |\n",
      "|    total_cost           | 9.83e+05    |\n",
      "|    total_reward         | -1.32e+06   |\n",
      "|    total_reward_pct     | -88         |\n",
      "|    total_trades         | 40792       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 988         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033387534 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.67        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1022        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049729712 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "day: 2421, episode: 75\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 17278.63\n",
      "total_reward: -1482721.37\n",
      "total_cost: 388004.41\n",
      "total_trades: 39380\n",
      "Sharpe: 0.313\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.73e+04    |\n",
      "|    total_cost           | 3.88e+05    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.8       |\n",
      "|    total_trades         | 39380       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 1053        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013688147 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0754      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.95        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+05    |\n",
      "|    total_cost           | 1.11e+06    |\n",
      "|    total_reward         | -1.28e+06   |\n",
      "|    total_reward_pct     | -85.2       |\n",
      "|    total_trades         | 40757       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1082        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011196734 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.88e+06   |\n",
      "|    total_cost           | 1.67e+06   |\n",
      "|    total_reward         | 1.38e+06   |\n",
      "|    total_reward_pct     | 91.7       |\n",
      "|    total_trades         | 41778      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 77         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 1112       |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01353292 |\n",
      "|    clip_fraction        | 0.0885     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | 0.22       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.1       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00879   |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 99.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.64e+05    |\n",
      "|    total_cost           | 1.12e+06    |\n",
      "|    total_reward         | -1.24e+06   |\n",
      "|    total_reward_pct     | -82.4       |\n",
      "|    total_trades         | 40821       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1148        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010849569 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.19e+06    |\n",
      "|    total_cost           | 1.57e+06    |\n",
      "|    total_reward         | -3.06e+05   |\n",
      "|    total_reward_pct     | -20.4       |\n",
      "|    total_trades         | 41567       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1183        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021907661 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "day: 2421, episode: 80\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1796265.31\n",
      "total_reward: 296265.31\n",
      "total_cost: 1474631.79\n",
      "total_trades: 41653\n",
      "Sharpe: 0.291\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.8e+06     |\n",
      "|    total_cost           | 1.47e+06    |\n",
      "|    total_reward         | 2.96e+05    |\n",
      "|    total_reward_pct     | 19.8        |\n",
      "|    total_trades         | 41653       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1219        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022297958 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1256        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013258632 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.23e+06    |\n",
      "|    total_cost           | 1.21e+06    |\n",
      "|    total_reward         | -2.67e+05   |\n",
      "|    total_reward_pct     | -17.8       |\n",
      "|    total_trades         | 41060       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1282        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014136283 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.13e+06     |\n",
      "|    total_cost           | 1.2e+06      |\n",
      "|    total_reward         | 6.29e+05     |\n",
      "|    total_reward_pct     | 41.9         |\n",
      "|    total_trades         | 41065        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 1319         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093089435 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.5        |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.73e+06    |\n",
      "|    total_cost           | 1.13e+06    |\n",
      "|    total_reward         | 1.23e+06    |\n",
      "|    total_reward_pct     | 81.8        |\n",
      "|    total_trades         | 41040       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1348        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009755114 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-09-24 to  2019-12-20\n",
      "PPO Sharpe Ratio:  -0.17577125585330386\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_315_1\n",
      "day: 2421, episode: 85\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 5198968.49\n",
      "total_reward: 3698968.49\n",
      "total_cost: 131416.71\n",
      "total_trades: 29380\n",
      "Sharpe: 0.524\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.4e+06  |\n",
      "|    total_cost       | 4.91e+03 |\n",
      "|    total_reward     | 8.97e+05 |\n",
      "|    total_reward_pct | 59.8     |\n",
      "|    total_trades     | 29031    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 26       |\n",
      "|    time_elapsed     | 369      |\n",
      "|    total timesteps  | 9688     |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -235     |\n",
      "|    critic_loss      | 108      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7266     |\n",
      "----------------------------------\n",
      "day: 2421, episode: 90\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1511621.34\n",
      "total_reward: 11621.34\n",
      "total_cost: 2848.26\n",
      "total_trades: 28541\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.3e+06   |\n",
      "|    total_cost       | 3.8e+03   |\n",
      "|    total_reward     | -2.02e+05 |\n",
      "|    total_reward_pct | -13.5     |\n",
      "|    total_trades     | 33757     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 24        |\n",
      "|    time_elapsed     | 786       |\n",
      "|    total timesteps  | 19376     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -145      |\n",
      "|    critic_loss      | 99.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 16954     |\n",
      "-----------------------------------\n",
      "day: 2421, episode: 95\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 4917476.66\n",
      "total_reward: 3417476.66\n",
      "total_cost: 7486.11\n",
      "total_trades: 33546\n",
      "Sharpe: 0.399\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.3e+06   |\n",
      "|    total_cost       | 3.2e+03   |\n",
      "|    total_reward     | -1.96e+05 |\n",
      "|    total_reward_pct | -13.1     |\n",
      "|    total_trades     | 33717     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 24        |\n",
      "|    time_elapsed     | 1207      |\n",
      "|    total timesteps  | 29064     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -92.3     |\n",
      "|    critic_loss      | 43        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 26642     |\n",
      "-----------------------------------\n",
      "day: 2421, episode: 100\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 3833411.87\n",
      "total_reward: 2333411.87\n",
      "total_cost: 5198.80\n",
      "total_trades: 33922\n",
      "Sharpe: 0.337\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 3.83e+06 |\n",
      "|    total_cost       | 5.2e+03  |\n",
      "|    total_reward     | 2.33e+06 |\n",
      "|    total_reward_pct | 156      |\n",
      "|    total_trades     | 33922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 24       |\n",
      "|    time_elapsed     | 1583     |\n",
      "|    total timesteps  | 38752    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -59.7    |\n",
      "|    critic_loss      | 83       |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 36330    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.94e+06 |\n",
      "|    total_cost       | 4.06e+03 |\n",
      "|    total_reward     | 4.41e+05 |\n",
      "|    total_reward_pct | 29.4     |\n",
      "|    total_trades     | 34093    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 24       |\n",
      "|    time_elapsed     | 1964     |\n",
      "|    total timesteps  | 48440    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -39.8    |\n",
      "|    critic_loss      | 39.5     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 46018    |\n",
      "----------------------------------\n",
      "day: 2421, episode: 105\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1397579.11\n",
      "total_reward: -102420.89\n",
      "total_cost: 2970.32\n",
      "total_trades: 34056\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "======DDPG Validation from:  2019-09-24 to  2019-12-20\n",
      "======Best Model Retraining from:  2000-01-01 to  2019-12-20\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\ensemble_315_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 73       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 266      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 49.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -568     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 148      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.94e+03 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 2.36e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -269     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.34e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+07 |\n",
      "|    total_cost         | 2.4e+06  |\n",
      "|    total_reward       | 8.67e+06 |\n",
      "|    total_reward_pct   | 578      |\n",
      "|    total_trades       | 40818    |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.164    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 15.2     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.213    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 7.03      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.0304    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 4.15     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0215   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 19.5     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.269    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -17.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.205    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.15e+05  |\n",
      "|    total_cost         | 2.99e+05  |\n",
      "|    total_reward       | -1.38e+06 |\n",
      "|    total_reward_pct   | -92.3     |\n",
      "|    total_trades       | 35362     |\n",
      "| time/                 |           |\n",
      "|    fps                | 80        |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -65.2     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 82.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 66.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.04     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.07e-06 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -30       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -179     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 24.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+06     |\n",
      "|    total_cost         | 4.05e+05  |\n",
      "|    total_reward       | -4.98e+05 |\n",
      "|    total_reward_pct   | -33.2     |\n",
      "|    total_trades       | 36879     |\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 8.93      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.107     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -3.43     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.0207    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.995    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -102     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 6.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 6.8      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.164    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.79e+04 |\n",
      "|    total_cost         | 3.61e+05 |\n",
      "|    total_reward       | -1.4e+06 |\n",
      "|    total_reward_pct   | -93.5    |\n",
      "|    total_trades       | 38023    |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 54.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 36.1     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.732    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 31       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -79.9    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -5.32     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.22      |\n",
      "-------------------------------------\n",
      "day: 2484, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 661552.01\n",
      "total_reward: -838447.99\n",
      "total_cost: 285921.93\n",
      "total_trades: 38673\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.62e+05  |\n",
      "|    total_cost         | 2.86e+05  |\n",
      "|    total_reward       | -8.38e+05 |\n",
      "|    total_reward_pct   | -55.9     |\n",
      "|    total_trades       | 38673     |\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 0.977     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0138    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0705   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -7.87    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 41.9     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -307     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 65.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.33e+06 |\n",
      "|    total_cost         | 1.6e+05  |\n",
      "|    total_reward       | 2.83e+06 |\n",
      "|    total_reward_pct   | 189      |\n",
      "|    total_trades       | 38706    |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -67.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -38.9    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.851    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.51     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.00504  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -14.3    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.117    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 25.8     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 6.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.08e+06 |\n",
      "|    total_cost         | 1.51e+05 |\n",
      "|    total_reward       | 1.58e+06 |\n",
      "|    total_reward_pct   | 105      |\n",
      "|    total_trades       | 37134    |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | -0.0642  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 7.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 45.5     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -2.07    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0145   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 84.2     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 6.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 237      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 307      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 51.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.68e+05  |\n",
      "|    total_cost         | 1.71e+05  |\n",
      "|    total_reward       | -5.32e+05 |\n",
      "|    total_reward_pct   | -35.5     |\n",
      "|    total_trades       | 37555     |\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 243       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 124       |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 9.06      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -60.8    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -29.2    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 268      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 57       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -55.9    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 20.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.07e+06 |\n",
      "|    total_cost         | 7.84e+04 |\n",
      "|    total_reward       | 5.71e+05 |\n",
      "|    total_reward_pct   | 38       |\n",
      "|    total_trades       | 36676    |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 51.9     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 82        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -15.4     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.162     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 35.6     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -95.7    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 5.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -193     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 23.5     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1526380.33\n",
      "total_reward: 26380.33\n",
      "total_cost: 15418.33\n",
      "total_trades: 35753\n",
      "Sharpe: 0.320\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.53e+06 |\n",
      "|    total_cost         | 1.54e+04 |\n",
      "|    total_reward       | 2.64e+04 |\n",
      "|    total_reward_pct   | 1.76     |\n",
      "|    total_trades       | 35753    |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 6.63     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.169    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 4.96     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.739    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 17.6     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.658    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 38       |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -63.3    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.9e+05   |\n",
      "|    total_cost         | 3.06e+04  |\n",
      "|    total_reward       | -6.1e+05  |\n",
      "|    total_reward_pct   | -40.7     |\n",
      "|    total_trades       | 36148     |\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 336       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -7.08     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.339     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 342      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -38      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -213     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 23.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 354      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 199      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 28.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 504      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 132      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.48e+06  |\n",
      "|    total_cost         | 2.26e+04  |\n",
      "|    total_reward       | -1.52e+04 |\n",
      "|    total_reward_pct   | -1.01     |\n",
      "|    total_trades       | 37300     |\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 366       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 80.4      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 10.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 372       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -79.1     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 5.68      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 378      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 319      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 55.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -225     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 36.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.93e+06 |\n",
      "|    total_cost         | 1.8e+04  |\n",
      "|    total_reward       | 4.26e+05 |\n",
      "|    total_reward_pct   | 28.4     |\n",
      "|    total_trades       | 38910    |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 398      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -8.64    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0729   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 405      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 14.9     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.135    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 411      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -49.8    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 416      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 73.1     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 423      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -137     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.56e+05  |\n",
      "|    total_cost         | 7.55e+03  |\n",
      "|    total_reward       | -8.44e+05 |\n",
      "|    total_reward_pct   | -56.3     |\n",
      "|    total_trades       | 34176     |\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 429       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 10.6      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.03      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 435       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 4.11      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.408     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 442      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -52.1    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 449      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 6.39     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 455      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -268     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 72.9     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2061668.69\n",
      "total_reward: 561668.69\n",
      "total_cost: 14683.12\n",
      "total_trades: 33115\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.06e+06 |\n",
      "|    total_cost         | 1.47e+04 |\n",
      "|    total_reward       | 5.62e+05 |\n",
      "|    total_reward_pct   | 37.4     |\n",
      "|    total_trades       | 33115    |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 464      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 13.1     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.144    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 471      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -14.6    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.991    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 479      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 131      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 14.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 487      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 169      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 15.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 494      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -41.6    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 25.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.28e+06 |\n",
      "|    total_cost         | 7.09e+03 |\n",
      "|    total_reward       | 7.85e+05 |\n",
      "|    total_reward_pct   | 52.3     |\n",
      "|    total_trades       | 32521    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 502      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0.0677   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -408     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 94.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 512      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 29.1     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 7.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 519      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0.00664  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -38.2    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 525      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 53.5     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 531      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 231      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 24.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.51e+06 |\n",
      "|    total_cost         | 1.36e+04 |\n",
      "|    total_reward       | 1.01e+06 |\n",
      "|    total_reward_pct   | 67.4     |\n",
      "|    total_trades       | 33497    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 537      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -415     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 85.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 544       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 225       |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 28.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 550       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -127      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 13.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 556      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 37.6     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 3.58     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 28.7      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 4.95      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.44e+06  |\n",
      "|    total_cost         | 1.08e+04  |\n",
      "|    total_reward       | 1.94e+06  |\n",
      "|    total_reward_pct   | 129       |\n",
      "|    total_trades       | 33486     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 570       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -80.8     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 578      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 6.89     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 3.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 585      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -39.3    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 591       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -126      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 8.23      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 597      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -441     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 104      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.85e+06  |\n",
      "|    total_cost         | 1.84e+04  |\n",
      "|    total_reward       | 2.35e+06  |\n",
      "|    total_reward_pct   | 157       |\n",
      "|    total_trades       | 33832     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 603       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 95.6      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 7.19      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 609      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 28.4     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 4.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 616      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -39.2    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 621      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -178     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 26.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 627      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 132      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 39.3     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2918919.72\n",
      "total_reward: 1418919.72\n",
      "total_cost: 17914.26\n",
      "total_trades: 32488\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.92e+06 |\n",
      "|    total_cost         | 1.79e+04 |\n",
      "|    total_reward       | 1.42e+06 |\n",
      "|    total_reward_pct   | 94.6     |\n",
      "|    total_trades       | 32488    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 634      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 22.7     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 640      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -130     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 647      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -54.7    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 653      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 56.9     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 659      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -225     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 41       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.66e+06 |\n",
      "|    total_cost         | 1.05e+04 |\n",
      "|    total_reward       | 1.6e+05  |\n",
      "|    total_reward_pct   | 10.7     |\n",
      "|    total_trades       | 29028    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 665      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 24.5     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.432    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 671      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -2.52    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0191   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 677      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -5.01    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.354    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 684      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -40.1    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.59     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 691       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -4.73     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.0986    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.49e+05  |\n",
      "|    total_cost         | 6.23e+03  |\n",
      "|    total_reward       | -8.51e+05 |\n",
      "|    total_reward_pct   | -56.7     |\n",
      "|    total_trades       | 30399     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 697       |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -5.09     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.155     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 703      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -1.7     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.00992  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 708      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 15.9     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 713      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -5.89    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 719      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 22.4     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.489    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.62e+05  |\n",
      "|    total_cost         | 7.77e+03  |\n",
      "|    total_reward       | -1.04e+06 |\n",
      "|    total_reward_pct   | -69.2     |\n",
      "|    total_trades       | 28949     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 724       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | 36.5      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 730      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -93.1    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 5.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 737      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -35.4    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 743      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 3.14     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.00558  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 749      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 52.6     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.24e+05  |\n",
      "|    total_cost         | 1.34e+04  |\n",
      "|    total_reward       | -8.76e+05 |\n",
      "|    total_reward_pct   | -58.4     |\n",
      "|    total_trades       | 27305     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 757       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -106      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 5.75      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 763      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 3.56     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 770      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -213     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 25       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 776      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 234      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 34.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 782      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0.126    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 695      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.04e+03 |\n",
      "------------------------------------\n",
      "day: 2484, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1004761.34\n",
      "total_reward: -495238.66\n",
      "total_cost: 17377.85\n",
      "total_trades: 26509\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+06     |\n",
      "|    total_cost         | 1.74e+04  |\n",
      "|    total_reward       | -4.95e+05 |\n",
      "|    total_reward_pct   | -33       |\n",
      "|    total_trades       | 26509     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 788       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 44.3      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 2.72      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 795       |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | 12.2      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.608     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 801      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 56.8     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 808       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -37       |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.818     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 815       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | -99.1     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 5.31      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.16e+05  |\n",
      "|    total_cost         | 5.13e+03  |\n",
      "|    total_reward       | -8.84e+05 |\n",
      "|    total_reward_pct   | -59       |\n",
      "|    total_trades       | 26113     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 822       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.3     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | 42.9      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 827      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -42.4    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.925    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 834      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | 93.1     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 4.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 839      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -78      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 3.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 845      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -92      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 4.73     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.58e+05  |\n",
      "|    total_cost         | 5.06e+03  |\n",
      "|    total_reward       | -9.42e+05 |\n",
      "|    total_reward_pct   | -62.8     |\n",
      "|    total_trades       | 27667     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 851       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 19.2      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.91      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 857      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 43.3     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 863      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 17.9     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.212    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 869      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -16.5    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.614    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 875      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 51.7     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.39e+05  |\n",
      "|    total_cost         | 5.19e+03  |\n",
      "|    total_reward       | -1.16e+06 |\n",
      "|    total_reward_pct   | -77.4     |\n",
      "|    total_trades       | 29476     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 881       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -24.6     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.447     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 887      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 5.55     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0224   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 893      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 55       |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 900      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 5.69     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.0247   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 905       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -26.4     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.711     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.23e+05  |\n",
      "|    total_cost         | 5.31e+03  |\n",
      "|    total_reward       | -1.28e+06 |\n",
      "|    total_reward_pct   | -85.1     |\n",
      "|    total_trades       | 31496     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 911       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -186      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 20.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 917      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 160      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 924      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -86.3    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 930       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | 57.4      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 2.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 935      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 22.9     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1368328.61\n",
      "total_reward: -131671.39\n",
      "total_cost: 14419.94\n",
      "total_trades: 30776\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.37e+06  |\n",
      "|    total_cost         | 1.44e+04  |\n",
      "|    total_reward       | -1.32e+05 |\n",
      "|    total_reward_pct   | -8.78     |\n",
      "|    total_trades       | 30776     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 941       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | 88.2      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 6.58      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 947      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -56.2    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 953      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0.179   |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 3.34     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 959       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | -98.1     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 6.64      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 965      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -2.96    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.54e+06 |\n",
      "|    total_cost         | 1.53e+04 |\n",
      "|    total_reward       | 4.38e+04 |\n",
      "|    total_reward_pct   | 2.92     |\n",
      "|    total_trades       | 28657    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 970      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -82.6    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 6.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 976       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | -176      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 16.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 981      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -72.9    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 3.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 986      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 171      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 47       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 991      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0.00217  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -251     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 75.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.35e+06  |\n",
      "|    total_cost         | 1.83e+04  |\n",
      "|    total_reward       | 8.53e+05  |\n",
      "|    total_reward_pct   | 56.9      |\n",
      "|    total_trades       | 27688     |\n",
      "| time/                 |           |\n",
      "|    fps                | 80        |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 997       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | 33.7      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.914     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 1003     |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 5.83     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.536    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 1011     |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 57.6     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 3.66     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 1019      |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | 142       |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 9.12      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 1026     |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 112      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 8.56     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.11e+06  |\n",
      "|    total_cost         | 4.77e+03  |\n",
      "|    total_reward       | -3.9e+05  |\n",
      "|    total_reward_pct   | -26       |\n",
      "|    total_trades       | 27864     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 1032      |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | 2.35      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.0491    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 1038     |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 100      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 5.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 1043     |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 70.7     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 3.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 1048     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 198      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 57       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.51e+06 |\n",
      "|    total_cost         | 7.69e+03 |\n",
      "|    total_reward       | 1.33e+04 |\n",
      "|    total_reward_pct   | 0.889    |\n",
      "|    total_trades       | 29213    |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 1056     |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0.0738   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -791     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.25e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 1063     |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 88.1     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 3.93     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 1069      |\n",
      "|    total_timesteps    | 85500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | 46.1      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 2.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 1075     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -127     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 1084     |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 7.19     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2111521.44\n",
      "total_reward: 611521.44\n",
      "total_cost: 8818.21\n",
      "total_trades: 28684\n",
      "Sharpe: 0.300\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 8.82e+03 |\n",
      "|    total_reward       | 6.12e+05 |\n",
      "|    total_reward_pct   | 40.8     |\n",
      "|    total_trades       | 28684    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 1092     |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -46.3    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 1098     |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -10      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.535    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 1104      |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | -215      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 27.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 1111     |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0.0477   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -98.3    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 7.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 1120     |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -152     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 55.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.39e+06 |\n",
      "|    total_cost         | 8.48e+03 |\n",
      "|    total_reward       | 8.94e+05 |\n",
      "|    total_reward_pct   | 59.6     |\n",
      "|    total_trades       | 29077    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 1128     |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -7.65    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.116    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 1135     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 21       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.448    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 1142     |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -35.1    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.49     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 1151      |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 15.1      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.674     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 1158     |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 98.6     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 5.49     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.09e+05  |\n",
      "|    total_cost         | 6.76e+03  |\n",
      "|    total_reward       | -7.91e+05 |\n",
      "|    total_reward_pct   | -52.7     |\n",
      "|    total_trades       | 28084     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 1164      |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.6     |\n",
      "|    explained_variance | 2.98e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | 87.5      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 3.39      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 1170      |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -48.9     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 1.19      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 1178     |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 79.3     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 3.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 1188      |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -36.4     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 1.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 1195      |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -72       |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 3.57      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.43e+06  |\n",
      "|    total_cost         | 1.25e+04  |\n",
      "|    total_reward       | -7.37e+04 |\n",
      "|    total_reward_pct   | -4.92     |\n",
      "|    total_trades       | 28182     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 1202      |\n",
      "|    total_timesteps    | 94500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | -12.2     |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.756     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 1209     |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 8.85     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.405    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 1218     |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -3.12    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.947    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 1225     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -85.7    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 5.85     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 1232      |\n",
      "|    total_timesteps    | 96500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | 185       |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 31.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.45e+06 |\n",
      "|    total_cost         | 1.8e+04  |\n",
      "|    total_reward       | 9.47e+05 |\n",
      "|    total_reward_pct   | 63.2     |\n",
      "|    total_trades       | 29059    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 1240     |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -24.7    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 1250     |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 1.46     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.0495   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 1257     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -18.9    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 1264     |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -63.8    |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 4.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 1271     |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 117      |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 40\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1591606.58\n",
      "total_reward: 91606.58\n",
      "total_cost: 5440.95\n",
      "total_trades: 27965\n",
      "Sharpe: 0.324\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.59e+06 |\n",
      "|    total_cost         | 5.44e+03 |\n",
      "|    total_reward       | 9.16e+04 |\n",
      "|    total_reward_pct   | 6.11     |\n",
      "|    total_trades       | 27965    |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 1279     |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -160     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 11.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 77        |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 1285      |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -183      |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 15.1      |\n",
      "-------------------------------------\n",
      "======Trading from:  2019-12-20 to  2020-03-24\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  397.3376832837864\n",
      "======Model training from:  2000-01-01 to  2019-12-20\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_378_1\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 71        |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 180       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 20.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 113      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 8.84     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 80        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 449       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 116       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -60.7    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.79     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.47e+06  |\n",
      "|    total_cost         | 2.56e+06  |\n",
      "|    total_reward       | -3.19e+04 |\n",
      "|    total_reward_pct   | -2.13     |\n",
      "|    total_trades       | 44670     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -19.2     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.363     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 55.8      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 8.17     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.704    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 15.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.689    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.85     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.4e+06   |\n",
      "|    total_cost         | 5.44e+05  |\n",
      "|    total_reward       | -9.85e+04 |\n",
      "|    total_reward_pct   | -6.57     |\n",
      "|    total_trades       | 39566     |\n",
      "| time/                 |           |\n",
      "|    fps                | 83        |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -43.6     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 7.47     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.0573   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 86       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 94.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 13.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -61.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.55     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.05e+05  |\n",
      "|    total_cost         | 1.26e+05  |\n",
      "|    total_reward       | -1.09e+06 |\n",
      "|    total_reward_pct   | -73       |\n",
      "|    total_trades       | 39531     |\n",
      "| time/                 |           |\n",
      "|    fps                | 85        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 3.36      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.111     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 46.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 50.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -966     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 635      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 423      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 104      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.02e+06 |\n",
      "|    total_cost         | 2.37e+05 |\n",
      "|    total_reward       | 7.52e+06 |\n",
      "|    total_reward_pct   | 501      |\n",
      "|    total_trades       | 42082    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -57.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.95     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 166       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 27.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -163     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 59.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -350      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 71.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.0287  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -35.4    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.58     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 9362462.12\n",
      "total_reward: 7862462.12\n",
      "total_cost: 92403.81\n",
      "total_trades: 43816\n",
      "Sharpe: 0.413\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.36e+06 |\n",
      "|    total_cost         | 9.24e+04 |\n",
      "|    total_reward       | 7.86e+06 |\n",
      "|    total_reward_pct   | 524      |\n",
      "|    total_trades       | 43816    |\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 153      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -79.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 75.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 438      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 130      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 227      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 48.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.71e+06 |\n",
      "|    total_cost         | 4.67e+04 |\n",
      "|    total_reward       | 5.21e+06 |\n",
      "|    total_reward_pct   | 347      |\n",
      "|    total_trades       | 43729    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -70.7    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -89.2    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.14     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -4.66     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.58      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 155      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 16.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.37e+06 |\n",
      "|    total_cost         | 2.28e+04 |\n",
      "|    total_reward       | 1.87e+06 |\n",
      "|    total_reward_pct   | 125      |\n",
      "|    total_trades       | 43635    |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 29.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.628    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -5.99    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.54     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 77        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 237       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -22.9     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.318     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 52       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -62.4    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 66.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.5e+06  |\n",
      "|    total_cost         | 2.31e+04 |\n",
      "|    total_reward       | 2e+06    |\n",
      "|    total_reward_pct   | 133      |\n",
      "|    total_trades       | 46389    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 116      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 7.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -24.7    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.654    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 120      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 656      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 216      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -132     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.63e+06  |\n",
      "|    total_cost         | 1.86e+04  |\n",
      "|    total_reward       | 2.13e+06  |\n",
      "|    total_reward_pct   | 142       |\n",
      "|    total_trades       | 44723     |\n",
      "| time/                 |           |\n",
      "|    fps                | 76        |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 292       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 3.18      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.082     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 76        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 299       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 0.273     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.00415   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 32.6     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -61.6    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 57.8     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.55     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1778498.60\n",
      "total_reward: 278498.60\n",
      "total_cost: 5344.35\n",
      "total_trades: 46367\n",
      "Sharpe: 0.366\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.78e+06 |\n",
      "|    total_cost         | 5.34e+03 |\n",
      "|    total_reward       | 2.78e+05 |\n",
      "|    total_reward_pct   | 18.6     |\n",
      "|    total_trades       | 46367    |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 20.5     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.896    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 3.2      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.358    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 76        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 338       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -9.04     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.54      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 344      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 100      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 14.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -45.2    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+06  |\n",
      "|    total_cost         | 1.88e+04 |\n",
      "|    total_reward       | 1.3e+06  |\n",
      "|    total_reward_pct   | 86.8     |\n",
      "|    total_trades       | 48805    |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 11       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.0796   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 361      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.208   |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.0814   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -84.2    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 4.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 372      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 65.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 378      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 167      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.4e+06   |\n",
      "|    total_cost         | 6.98e+03  |\n",
      "|    total_reward       | -9.98e+04 |\n",
      "|    total_reward_pct   | -6.65     |\n",
      "|    total_trades       | 47190     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 384       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 20.7      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.665     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 390       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -21.1     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.43      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 399      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -19.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.272    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 77        |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 405       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 28.4      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 4.56      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 411      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 40.3     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.38e+06 |\n",
      "|    total_cost         | 9.37e+03 |\n",
      "|    total_reward       | 8.83e+05 |\n",
      "|    total_reward_pct   | 58.9     |\n",
      "|    total_trades       | 45396    |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 417      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -35.3    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 423      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 22.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.408    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 429      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -2.29    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.446    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 435      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -13      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 441      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 35       |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.63     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.22e+06  |\n",
      "|    total_cost         | 1.36e+04  |\n",
      "|    total_reward       | -2.79e+05 |\n",
      "|    total_reward_pct   | -18.6     |\n",
      "|    total_trades       | 44826     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 447       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -22.6     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.293     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 77        |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 457       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 19.8      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.253     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 464      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 24.7     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.389    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 470      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -54.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 476      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 147      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2340625.96\n",
      "total_reward: 840625.96\n",
      "total_cost: 7049.54\n",
      "total_trades: 45210\n",
      "Sharpe: 0.437\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.34e+06 |\n",
      "|    total_cost         | 7.05e+03 |\n",
      "|    total_reward       | 8.41e+05 |\n",
      "|    total_reward_pct   | 56       |\n",
      "|    total_trades       | 45210    |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 481      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -67.2    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 77        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 487       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 28.3      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.619     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 493      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 220      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 25.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 499      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -84.8    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 8.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 504      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 127      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 19       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.63e+06 |\n",
      "|    total_cost         | 2.27e+04 |\n",
      "|    total_reward       | 2.13e+06 |\n",
      "|    total_reward_pct   | 142      |\n",
      "|    total_trades       | 47940    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 512      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -154     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 13.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 521      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 66.5     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 9.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 527      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -254     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 36.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 533      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 17.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 539      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0.0125   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 1.01e+03 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 541      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.52e+06 |\n",
      "|    total_cost         | 2.67e+04 |\n",
      "|    total_reward       | 3.02e+06 |\n",
      "|    total_reward_pct   | 201      |\n",
      "|    total_trades       | 49200    |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 545      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -190     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 18.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 550       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -47.7     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.77      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 557      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -94.7    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 562      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 11       |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.316    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 569      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 99.3     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.4e+06   |\n",
      "|    total_cost         | 7.1e+03   |\n",
      "|    total_reward       | -1.02e+05 |\n",
      "|    total_reward_pct   | -6.82     |\n",
      "|    total_trades       | 48405     |\n",
      "| time/                 |           |\n",
      "|    fps                | 77        |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 577       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -32.4     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.671     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 77        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -10.6     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.0554    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 590      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 0.717    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.00277  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 596      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 3.89     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0146   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 601      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -7.87    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.91     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.16e+06  |\n",
      "|    total_cost         | 4.41e+03  |\n",
      "|    total_reward       | -3.42e+05 |\n",
      "|    total_reward_pct   | -22.8     |\n",
      "|    total_trades       | 48141     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 606       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 11.9      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.144     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 612      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -6.95    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0606   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 618      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -1.97    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.00586  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 624      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -36.7    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 1.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 631      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 5.12     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.88     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1232172.17\n",
      "total_reward: -267827.83\n",
      "total_cost: 10969.76\n",
      "total_trades: 47705\n",
      "Sharpe: 0.429\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.23e+06  |\n",
      "|    total_cost         | 1.1e+04   |\n",
      "|    total_reward       | -2.68e+05 |\n",
      "|    total_reward_pct   | -17.9     |\n",
      "|    total_trades       | 47705     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 638       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 20.4      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.373     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 644       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | 184       |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 26.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 649      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 7.06     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 32.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 655      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 91       |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 7.58     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 660      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | 413      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 91.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.79e+06 |\n",
      "|    total_cost         | 8.81e+03 |\n",
      "|    total_reward       | 2.88e+05 |\n",
      "|    total_reward_pct   | 19.2     |\n",
      "|    total_trades       | 46378    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 666      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 10       |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.144    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 671      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -4.65    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 677      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 35       |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 683      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 112      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 5.62     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 690       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -119      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 10.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.6e+06  |\n",
      "|    total_cost         | 9.93e+03 |\n",
      "|    total_reward       | 1e+05    |\n",
      "|    total_reward_pct   | 6.69     |\n",
      "|    total_trades       | 44263    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 696      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -17.8    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.203    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 703      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 114      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 709      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 55.8     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 3.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 716      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -192     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 32       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 722      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 74.6     |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 8.7      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.81e+06  |\n",
      "|    total_cost         | 1.32e+04  |\n",
      "|    total_reward       | 1.31e+06  |\n",
      "|    total_reward_pct   | 87.6      |\n",
      "|    total_trades       | 42421     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 729       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -24.4     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 735      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -77.9    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 741      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -34.3    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 749      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -4.64    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.0129   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 756      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 56.9     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 1.43     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.6e+06   |\n",
      "|    total_cost         | 1.08e+04  |\n",
      "|    total_reward       | 9.76e+04  |\n",
      "|    total_reward_pct   | 6.51      |\n",
      "|    total_trades       | 43132     |\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 761       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.56      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 767      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -80.7    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 4        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 773      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 18.7     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.798    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 778      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 153      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 15.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 784      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 0.0294   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 915      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 2.59e+03 |\n",
      "------------------------------------\n",
      "day: 2484, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1134178.99\n",
      "total_reward: -365821.01\n",
      "total_cost: 16010.93\n",
      "total_trades: 43174\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.13e+06  |\n",
      "|    total_cost         | 1.6e+04   |\n",
      "|    total_reward       | -3.66e+05 |\n",
      "|    total_reward_pct   | -24.4     |\n",
      "|    total_trades       | 43174     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 790       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.3     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 35.9      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 796      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 24.2     |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 802      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 13.2     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.237    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 809      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 25.7     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 2.45     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 816      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -102     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 5.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.72e+06 |\n",
      "|    total_cost         | 1.1e+04  |\n",
      "|    total_reward       | 2.17e+05 |\n",
      "|    total_reward_pct   | 14.4     |\n",
      "|    total_trades       | 42419    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 823      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 16.1     |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.321    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 830       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | -34.2     |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.616     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 78        |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 836       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | 57.6      |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.75      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 842      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -21      |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 0.421    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 847       |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | -48.1     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.09      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.75e+05  |\n",
      "|    total_cost         | 1.26e+04  |\n",
      "|    total_reward       | -1.03e+06 |\n",
      "|    total_reward_pct   | -68.3     |\n",
      "|    total_trades       | 41427     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 853       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 29.8      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.744     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 859       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 292       |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 63        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 865       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | 125       |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 7.59      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 872      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -85.1    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 20.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 879      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 81.9     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.63e+06  |\n",
      "|    total_cost         | 1.77e+04  |\n",
      "|    total_reward       | 1.13e+06  |\n",
      "|    total_reward_pct   | 75.3      |\n",
      "|    total_trades       | 41439     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 884       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -220      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 26.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 890      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 331      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 69.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 895       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | 496       |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 163       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 900       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | 25.8      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 2.57      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 905      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 98.1     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.44e+06 |\n",
      "|    total_cost         | 1.54e+04 |\n",
      "|    total_reward       | 9.38e+05 |\n",
      "|    total_reward_pct   | 62.5     |\n",
      "|    total_trades       | 40891    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 911      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -58      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 2.93     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 917       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 63.3      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 12        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 923       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -917      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 387       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 931      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -46.3    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 7.12     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 939       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | -156      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 15.6      |\n",
      "-------------------------------------\n",
      "day: 2484, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2380232.63\n",
      "total_reward: 880232.63\n",
      "total_cost: 7574.07\n",
      "total_trades: 41433\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.38e+06 |\n",
      "|    total_cost         | 7.57e+03 |\n",
      "|    total_reward       | 8.8e+05  |\n",
      "|    total_reward_pct   | 58.7     |\n",
      "|    total_trades       | 41433    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 946      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 73.8     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 3.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 952      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -532     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 178      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 958      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 259      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 59.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 963      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -364     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 69       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 969      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 370      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 118      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.81e+06  |\n",
      "|    total_cost         | 1.05e+04  |\n",
      "|    total_reward       | 2.31e+06  |\n",
      "|    total_reward_pct   | 154       |\n",
      "|    total_trades       | 39295     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 975       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -44.2     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 4.6       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 981      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -262     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 60.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 988       |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -602      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 185       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 994      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 407      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 113      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 1001     |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 523      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 146      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.09e+06 |\n",
      "|    total_cost         | 1.41e+04 |\n",
      "|    total_reward       | 2.59e+06 |\n",
      "|    total_reward_pct   | 173      |\n",
      "|    total_trades       | 38716    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 1007     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 89.9     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 5        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 1013     |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 81.7     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 6.4      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 1020      |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 623       |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 326       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 1026     |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 154      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 19.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 1032     |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 1.39e+03 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 956      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.32e+06 |\n",
      "|    total_cost         | 1.66e+04 |\n",
      "|    total_reward       | 2.82e+06 |\n",
      "|    total_reward_pct   | 188      |\n",
      "|    total_trades       | 40475    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 1038     |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -8.02    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.213    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 1044     |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 539      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 158      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 1051     |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -17.1    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.696    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 1058     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 314      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 71.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.68e+06  |\n",
      "|    total_cost         | 5.55e+03  |\n",
      "|    total_reward       | 1.82e+05  |\n",
      "|    total_reward_pct   | 12.2      |\n",
      "|    total_trades       | 39460     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 1064      |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | 0.113     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | -1.28e+03 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 3.07e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 1070     |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 64.1     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 1075     |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 168      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 1081     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -206     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 22.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 1087     |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 10.9     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1397630.23\n",
      "total_reward: -102369.77\n",
      "total_cost: 4060.81\n",
      "total_trades: 40658\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.4e+06   |\n",
      "|    total_cost         | 4.06e+03  |\n",
      "|    total_reward       | -1.02e+05 |\n",
      "|    total_reward_pct   | -6.82     |\n",
      "|    total_trades       | 40658     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 1093      |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | -39.2     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.847     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 1098     |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -28.8    |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.401    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 1104     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 106      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 6.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 1111     |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 19.3     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.446    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 1119     |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 13.3     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 4.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 3.51e+03 |\n",
      "|    total_reward       | 2.14e+04 |\n",
      "|    total_reward_pct   | 1.43     |\n",
      "|    total_trades       | 41175    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 1126     |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 22       |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.312    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 1131     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 44.4     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 1137     |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -243     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 42.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 1142     |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 5.96     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.24     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 1147      |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | -52.8     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 1.7       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.59e+06 |\n",
      "|    total_cost         | 6.62e+03 |\n",
      "|    total_reward       | 8.62e+04 |\n",
      "|    total_reward_pct   | 5.75     |\n",
      "|    total_trades       | 39004    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 1153     |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 3.67     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.0105   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 1159     |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 28.4     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.49     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 1164      |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -224      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 27.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 1172     |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -27.5    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.505    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 1179     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 59.4     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.2e+06   |\n",
      "|    total_cost         | 4.39e+03  |\n",
      "|    total_reward       | -2.98e+05 |\n",
      "|    total_reward_pct   | -19.8     |\n",
      "|    total_trades       | 39202     |\n",
      "| time/                 |           |\n",
      "|    fps                | 79        |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 1184      |\n",
      "|    total_timesteps    | 94500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | -0.214    |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.0902    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 1189     |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 31.7     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.776    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 1194     |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -46.8    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 1200     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -196     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 27.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 1205     |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 156      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 14.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 5.42e+03 |\n",
      "|    total_reward       | 2.44e+04 |\n",
      "|    total_reward_pct   | 1.62     |\n",
      "|    total_trades       | 38025    |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 1210     |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -2.94    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.0188   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 1215     |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 21.6     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 1221     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -33.2    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.735    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 1226     |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -11.3    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 1235     |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 34.6     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 0.61     |\n",
      "------------------------------------\n",
      "day: 2484, episode: 40\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1701343.82\n",
      "total_reward: 201343.82\n",
      "total_cost: 3944.50\n",
      "total_trades: 37580\n",
      "Sharpe: 0.343\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.7e+06  |\n",
      "|    total_cost         | 3.94e+03 |\n",
      "|    total_reward       | 2.01e+05 |\n",
      "|    total_reward_pct   | 13.4     |\n",
      "|    total_trades       | 37580    |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 1242     |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -207     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 18.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 1248     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -364     |\n",
      "|    std                | 1.2      |\n",
      "|    value_loss         | 63       |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-12-20 to  2020-03-24\n",
      "A2C Sharpe Ratio:  -0.7087641018721408\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_378_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 86   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 23   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.13e+04    |\n",
      "|    total_cost           | 1.44e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.2       |\n",
      "|    total_trades         | 41541       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007033985 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.37        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.81e+04    |\n",
      "|    total_cost           | 1.69e+06    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98.1       |\n",
      "|    total_trades         | 41566       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017274631 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0229      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2           |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.28e+04    |\n",
      "|    total_cost           | 7.84e+05    |\n",
      "|    total_reward         | -1.41e+06   |\n",
      "|    total_reward_pct     | -93.8       |\n",
      "|    total_trades         | 40158       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019855661 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0806      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.17        |\n",
      "-----------------------------------------\n",
      "day: 2484, episode: 45\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 116212.08\n",
      "total_reward: -1383787.92\n",
      "total_cost: 2234037.82\n",
      "total_trades: 42728\n",
      "Sharpe: -0.293\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.16e+05    |\n",
      "|    total_cost           | 2.23e+06    |\n",
      "|    total_reward         | -1.38e+06   |\n",
      "|    total_reward_pct     | -92.3       |\n",
      "|    total_trades         | 42728       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023529433 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0401      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.44        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.95        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026135648 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0777      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.41e+05    |\n",
      "|    total_cost           | 2.23e+06    |\n",
      "|    total_reward         | -1.36e+06   |\n",
      "|    total_reward_pct     | -90.6       |\n",
      "|    total_trades         | 42858       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019577418 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0421      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.39        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 8.45        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 9.84e+04  |\n",
      "|    total_cost           | 8.79e+05  |\n",
      "|    total_reward         | -1.4e+06  |\n",
      "|    total_reward_pct     | -93.4     |\n",
      "|    total_trades         | 40047     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 72        |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 225       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0448016 |\n",
      "|    clip_fraction        | 0.333     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.1     |\n",
      "|    explained_variance   | 0.114     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.494     |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -0.000584 |\n",
      "|    std                  | 1.02      |\n",
      "|    value_loss           | 8.04      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+04    |\n",
      "|    total_cost           | 1.22e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.3       |\n",
      "|    total_trades         | 40870       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009807527 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.94        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.31e+03    |\n",
      "|    total_cost           | 2.83e+05    |\n",
      "|    total_reward         | -1.5e+06    |\n",
      "|    total_reward_pct     | -99.8       |\n",
      "|    total_trades         | 38518       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012553552 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.183      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.2         |\n",
      "-----------------------------------------\n",
      "day: 2484, episode: 50\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 50351.12\n",
      "total_reward: -1449648.88\n",
      "total_cost: 689780.23\n",
      "total_trades: 40061\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.04e+04    |\n",
      "|    total_cost           | 6.9e+05     |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.6       |\n",
      "|    total_trades         | 40061       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026399225 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.79        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 73         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 332        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02571188 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.161      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0587    |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 7.4        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.29e+04   |\n",
      "|    total_cost           | 6.27e+05   |\n",
      "|    total_reward         | -1.45e+06  |\n",
      "|    total_reward_pct     | -96.5      |\n",
      "|    total_trades         | 39843      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 73         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 362        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03468828 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0531     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.98       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00299   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 2.45       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.23e+04    |\n",
      "|    total_cost           | 9.3e+05     |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.5       |\n",
      "|    total_trades         | 40457       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015652893 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.653       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.75        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.28e+05  |\n",
      "|    total_cost           | 9.15e+05  |\n",
      "|    total_reward         | -1.37e+06 |\n",
      "|    total_reward_pct     | -91.5     |\n",
      "|    total_trades         | 40730     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 73        |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 419       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0163987 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.7     |\n",
      "|    explained_variance   | 0.15      |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.323     |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -0.0155   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 9.19      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.75e+04    |\n",
      "|    total_cost           | 5.15e+05    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98.2       |\n",
      "|    total_trades         | 39429       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009865701 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.17        |\n",
      "-----------------------------------------\n",
      "day: 2484, episode: 55\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 34235.18\n",
      "total_reward: -1465764.82\n",
      "total_cost: 225560.90\n",
      "total_trades: 38853\n",
      "Sharpe: 0.455\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.42e+04    |\n",
      "|    total_cost           | 2.26e+05    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -97.7       |\n",
      "|    total_trades         | 38853       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020958388 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018106414 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.272      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.24e+04    |\n",
      "|    total_cost           | 1.44e+06    |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.5       |\n",
      "|    total_trades         | 42000       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 524         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012311636 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0864      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.18e+04    |\n",
      "|    total_cost           | 1.37e+06    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.5       |\n",
      "|    total_trades         | 41392       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014228918 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.98e+03    |\n",
      "|    total_cost           | 5.89e+05    |\n",
      "|    total_reward         | -1.5e+06    |\n",
      "|    total_reward_pct     | -99.9       |\n",
      "|    total_trades         | 39833       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016244711 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.77e+04    |\n",
      "|    total_cost           | 9.04e+05    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.8       |\n",
      "|    total_trades         | 40860       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016875695 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.2         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 5.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 620         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024670003 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.273       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 6.16        |\n",
      "-----------------------------------------\n",
      "day: 2484, episode: 60\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 16059.01\n",
      "total_reward: -1483940.99\n",
      "total_cost: 669044.74\n",
      "total_trades: 39793\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.61e+04    |\n",
      "|    total_cost           | 6.69e+05    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.9       |\n",
      "|    total_trades         | 39793       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 643         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016959833 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.71e+04    |\n",
      "|    total_cost           | 1.76e+06    |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -94.9       |\n",
      "|    total_trades         | 42216       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 666         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014590172 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.35        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 9.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.28e+04    |\n",
      "|    total_cost           | 4.37e+05    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.5       |\n",
      "|    total_trades         | 39297       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 693         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029000055 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.408       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 8.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.25e+04    |\n",
      "|    total_cost           | 5.58e+05    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.2       |\n",
      "|    total_trades         | 39782       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016097166 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0959     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 6.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.54e+05    |\n",
      "|    total_cost           | 3e+06       |\n",
      "|    total_reward         | -1.15e+06   |\n",
      "|    total_reward_pct     | -76.4       |\n",
      "|    total_trades         | 43963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 739         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018564004 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 9.94        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 77           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 762          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133402925 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.6        |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.99         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "day: 2484, episode: 65\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 40100.62\n",
      "total_reward: -1459899.38\n",
      "total_cost: 1678621.01\n",
      "total_trades: 42101\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.01e+04    |\n",
      "|    total_cost           | 1.68e+06    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.3       |\n",
      "|    total_trades         | 42101       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 784         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011884948 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | -0.0161     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.45        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 8           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.24e+04    |\n",
      "|    total_cost           | 1.04e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.2       |\n",
      "|    total_trades         | 40837       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 806         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015887195 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 8.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.27e+05    |\n",
      "|    total_cost           | 2.27e+06    |\n",
      "|    total_reward         | -1.27e+06   |\n",
      "|    total_reward_pct     | -84.8       |\n",
      "|    total_trades         | 42963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 833         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016991923 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.42        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.68e+04    |\n",
      "|    total_cost           | 7.12e+05    |\n",
      "|    total_reward         | -1.44e+06   |\n",
      "|    total_reward_pct     | -96.2       |\n",
      "|    total_trades         | 39784       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 856         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025539549 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.56e+05    |\n",
      "|    total_cost           | 7.93e+05    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.6       |\n",
      "|    total_trades         | 39835       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 879         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010491036 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.043       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 6.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 903         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013965389 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.779       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.95        |\n",
      "-----------------------------------------\n",
      "day: 2484, episode: 70\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 661562.00\n",
      "total_reward: -838438.00\n",
      "total_cost: 3429436.23\n",
      "total_trades: 44209\n",
      "Sharpe: 0.192\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.62e+05    |\n",
      "|    total_cost           | 3.43e+06    |\n",
      "|    total_reward         | -8.38e+05   |\n",
      "|    total_reward_pct     | -55.9       |\n",
      "|    total_trades         | 44209       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 926         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009374401 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.00958     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.2        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.53e+05    |\n",
      "|    total_cost           | 3.32e+06    |\n",
      "|    total_reward         | -8.47e+05   |\n",
      "|    total_reward_pct     | -56.5       |\n",
      "|    total_trades         | 43765       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009534666 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0929      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.56e+05    |\n",
      "|    total_cost           | 1.23e+06    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.6       |\n",
      "|    total_trades         | 40629       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 974         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014098214 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.81        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.97e+05   |\n",
      "|    total_cost           | 2.23e+06   |\n",
      "|    total_reward         | -1e+06     |\n",
      "|    total_reward_pct     | -66.9      |\n",
      "|    total_trades         | 42150      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 80         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 997        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01893275 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.467      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.42       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 14.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 1020        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009215292 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.1e+05    |\n",
      "|    total_cost           | 3.26e+06   |\n",
      "|    total_reward         | -8.9e+05   |\n",
      "|    total_reward_pct     | -59.4      |\n",
      "|    total_trades         | 43822      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 80         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 1042       |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01077996 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.134      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.3       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 73.6       |\n",
      "----------------------------------------\n",
      "day: 2484, episode: 75\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 272605.63\n",
      "total_reward: -1227394.37\n",
      "total_cost: 2391792.21\n",
      "total_trades: 42731\n",
      "Sharpe: 0.115\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.73e+05    |\n",
      "|    total_cost           | 2.39e+06    |\n",
      "|    total_reward         | -1.23e+06   |\n",
      "|    total_reward_pct     | -81.8       |\n",
      "|    total_trades         | 42731       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1064        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018908666 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.11e+05    |\n",
      "|    total_cost           | 3.5e+06     |\n",
      "|    total_reward         | -6.89e+05   |\n",
      "|    total_reward_pct     | -45.9       |\n",
      "|    total_trades         | 43550       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1086        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017944615 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.89e+05    |\n",
      "|    total_cost           | 3.6e+06     |\n",
      "|    total_reward         | -5.11e+05   |\n",
      "|    total_reward_pct     | -34         |\n",
      "|    total_trades         | 43642       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1109        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018487936 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.26e+06     |\n",
      "|    total_cost           | 4.3e+06      |\n",
      "|    total_reward         | -2.43e+05    |\n",
      "|    total_reward_pct     | -16.2        |\n",
      "|    total_trades         | 44414        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 1134         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097457785 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45          |\n",
      "|    explained_variance   | 0.254        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.1         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 93.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1159        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009766638 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.39e+05    |\n",
      "|    total_cost           | 3.52e+06    |\n",
      "|    total_reward         | -6.61e+05   |\n",
      "|    total_reward_pct     | -44         |\n",
      "|    total_trades         | 43342       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1182        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014481602 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.1        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "day: 2484, episode: 80\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 3927421.69\n",
      "total_reward: 2427421.69\n",
      "total_cost: 6834139.98\n",
      "total_trades: 45905\n",
      "Sharpe: 0.329\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 3.93e+06   |\n",
      "|    total_cost           | 6.83e+06   |\n",
      "|    total_reward         | 2.43e+06   |\n",
      "|    total_reward_pct     | 162        |\n",
      "|    total_trades         | 45905      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 81         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 1205       |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01590875 |\n",
      "|    clip_fraction        | 0.0944     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.144      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 221        |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 380        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.33e+05   |\n",
      "|    total_cost           | 7.84e+05   |\n",
      "|    total_reward         | -1.37e+06  |\n",
      "|    total_reward_pct     | -91.1      |\n",
      "|    total_trades         | 40095      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 81         |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 1228       |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00477474 |\n",
      "|    clip_fraction        | 0.0663     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.207      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 66.6       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 221        |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2019-12-20 to  2020-03-24\n",
      "PPO Sharpe Ratio:  -0.5842311497654431\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_378_1\n",
      "day: 2484, episode: 85\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1499108.61\n",
      "total_reward: -891.39\n",
      "total_cost: 2853.98\n",
      "total_trades: 41130\n",
      "Sharpe: 0.305\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.39e+06  |\n",
      "|    total_cost       | 3.89e+03  |\n",
      "|    total_reward     | -1.05e+05 |\n",
      "|    total_reward_pct | -7.01     |\n",
      "|    total_trades     | 40213     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 32        |\n",
      "|    time_elapsed     | 309       |\n",
      "|    total timesteps  | 9940      |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -216      |\n",
      "|    critic_loss      | 202       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7455      |\n",
      "-----------------------------------\n",
      "day: 2484, episode: 90\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1384635.76\n",
      "total_reward: -115364.24\n",
      "total_cost: 3809.14\n",
      "total_trades: 40146\n",
      "Sharpe: 0.332\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.38e+06  |\n",
      "|    total_cost       | 3.81e+03  |\n",
      "|    total_reward     | -1.15e+05 |\n",
      "|    total_reward_pct | -7.69     |\n",
      "|    total_trades     | 40146     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 28        |\n",
      "|    time_elapsed     | 690       |\n",
      "|    total timesteps  | 19880     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -131      |\n",
      "|    critic_loss      | 111       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 17395     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.05e+06  |\n",
      "|    total_cost       | 3.07e+03  |\n",
      "|    total_reward     | -4.54e+05 |\n",
      "|    total_reward_pct | -30.3     |\n",
      "|    total_trades     | 39962     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 28        |\n",
      "|    time_elapsed     | 1056      |\n",
      "|    total timesteps  | 29820     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -79.9     |\n",
      "|    critic_loss      | 60.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 27335     |\n",
      "-----------------------------------\n",
      "day: 2484, episode: 95\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1500230.61\n",
      "total_reward: 230.61\n",
      "total_cost: 2845.81\n",
      "total_trades: 40081\n",
      "Sharpe: 0.313\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.48e+06  |\n",
      "|    total_cost       | 3.81e+03  |\n",
      "|    total_reward     | -1.78e+04 |\n",
      "|    total_reward_pct | -1.18     |\n",
      "|    total_trades     | 40079     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 29        |\n",
      "|    time_elapsed     | 1351      |\n",
      "|    total timesteps  | 39760     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -49.6     |\n",
      "|    critic_loss      | 53.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 37275     |\n",
      "-----------------------------------\n",
      "day: 2484, episode: 100\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1622173.07\n",
      "total_reward: 122173.07\n",
      "total_cost: 3027.55\n",
      "total_trades: 40090\n",
      "Sharpe: 0.301\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.35e+06  |\n",
      "|    total_cost       | 3.81e+03  |\n",
      "|    total_reward     | -1.51e+05 |\n",
      "|    total_reward_pct | -10       |\n",
      "|    total_trades     | 40168     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 29        |\n",
      "|    time_elapsed     | 1677      |\n",
      "|    total timesteps  | 49700     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -31.2     |\n",
      "|    critic_loss      | 53.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 47215     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-12-20 to  2020-03-24\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-03-24\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ensemble_378_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 103  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 19   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.72e+05   |\n",
      "|    total_cost           | 3.41e+06   |\n",
      "|    total_reward         | -1.33e+06  |\n",
      "|    total_reward_pct     | -88.5      |\n",
      "|    total_trades         | 45534      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01524548 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | -0.0042    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.1       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 26.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.34e+03    |\n",
      "|    total_cost           | 7.84e+05    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.5       |\n",
      "|    total_trades         | 41014       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025732102 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.00309    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.03e+05    |\n",
      "|    total_cost           | 2.5e+06     |\n",
      "|    total_reward         | -1.4e+06    |\n",
      "|    total_reward_pct     | -93.1       |\n",
      "|    total_trades         | 43983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010364031 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0188      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.81        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.24e+04    |\n",
      "|    total_cost           | 1.55e+06    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.5       |\n",
      "|    total_trades         | 42477       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031844735 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.78        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.54        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 191        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02420276 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.26       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 4.7        |\n",
      "----------------------------------------\n",
      "day: 2547, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 33096.17\n",
      "total_reward: -1466903.83\n",
      "total_cost: 3022264.12\n",
      "total_trades: 44827\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.31e+04    |\n",
      "|    total_cost           | 3.02e+06    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -97.8       |\n",
      "|    total_trades         | 44827       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027146323 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0339      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.06e+04   |\n",
      "|    total_cost           | 1.44e+06   |\n",
      "|    total_reward         | -1.44e+06  |\n",
      "|    total_reward_pct     | -96        |\n",
      "|    total_trades         | 42583      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02219781 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.108      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.53       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | 0.00078    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 7.71       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.62e+03    |\n",
      "|    total_cost           | 1.55e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.5       |\n",
      "|    total_trades         | 42837       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022947932 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.72        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.25e+04    |\n",
      "|    total_cost           | 1.87e+06    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.2       |\n",
      "|    total_trades         | 43548       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022629337 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020256182 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.58        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.81e+04    |\n",
      "|    total_cost           | 2.17e+06    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98.1       |\n",
      "|    total_trades         | 43972       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018170284 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.55        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 114996.41\n",
      "total_reward: -1385003.59\n",
      "total_cost: 3832052.16\n",
      "total_trades: 46541\n",
      "Sharpe: 0.236\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.15e+05   |\n",
      "|    total_cost           | 3.83e+06   |\n",
      "|    total_reward         | -1.39e+06  |\n",
      "|    total_reward_pct     | -92.3      |\n",
      "|    total_trades         | 46541      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 411        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01647044 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.6      |\n",
      "|    explained_variance   | 0.0653     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.2       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 35.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.4e+05    |\n",
      "|    total_cost           | 1.23e+06   |\n",
      "|    total_reward         | -1.36e+06  |\n",
      "|    total_reward_pct     | -90.7      |\n",
      "|    total_trades         | 42012      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 441        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02269114 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.121      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.53       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 11.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.32e+04    |\n",
      "|    total_cost           | 2.31e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.1       |\n",
      "|    total_trades         | 44086       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033559106 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0973      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.65        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 65         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 502        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05537846 |\n",
      "|    clip_fraction        | 0.421      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | 0.36       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.75       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | 0.00652    |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 6.84       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.56e+04    |\n",
      "|    total_cost           | 2.31e+06    |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -95         |\n",
      "|    total_trades         | 44358       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011945862 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.79        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.58e+05    |\n",
      "|    total_cost           | 2.55e+06    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.5       |\n",
      "|    total_trades         | 44942       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018033981 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 84104.20\n",
      "total_reward: -1415895.80\n",
      "total_cost: 2035505.78\n",
      "total_trades: 44387\n",
      "Sharpe: 0.277\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.41e+04    |\n",
      "|    total_cost           | 2.04e+06    |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -94.4       |\n",
      "|    total_trades         | 44387       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009987904 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.32        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.23e+05   |\n",
      "|    total_cost           | 2.35e+06   |\n",
      "|    total_reward         | -1.38e+06  |\n",
      "|    total_reward_pct     | -91.8      |\n",
      "|    total_trades         | 44631      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 635        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01835785 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.267      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.1       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 8.26       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 666         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022853144 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.76        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.34e+04    |\n",
      "|    total_cost           | 1.21e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.1       |\n",
      "|    total_trades         | 41994       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 697         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030676939 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.868       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.57e+04    |\n",
      "|    total_cost           | 2.68e+06    |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.6       |\n",
      "|    total_trades         | 45003       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 728         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033403173 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0914      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.86        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.49e+05    |\n",
      "|    total_cost           | 2.51e+06    |\n",
      "|    total_reward         | -1.35e+06   |\n",
      "|    total_reward_pct     | -90.1       |\n",
      "|    total_trades         | 44927       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 759         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019343294 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.52        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 40560.24\n",
      "total_reward: -1459439.76\n",
      "total_cost: 1493961.77\n",
      "total_trades: 42704\n",
      "Sharpe: -0.438\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.06e+04    |\n",
      "|    total_cost           | 1.49e+06    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.3       |\n",
      "|    total_trades         | 42704       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 791         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020955756 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.92        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 821         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019427888 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 7.11        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.41e+04     |\n",
      "|    total_cost           | 1.7e+06      |\n",
      "|    total_reward         | -1.46e+06    |\n",
      "|    total_reward_pct     | -97.1        |\n",
      "|    total_trades         | 43005        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 851          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033039842 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.7        |\n",
      "|    explained_variance   | -0.0353      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.2          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 5.23         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.22e+04    |\n",
      "|    total_cost           | 2.04e+06    |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.5       |\n",
      "|    total_trades         | 43673       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 884         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013330471 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0447      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.92        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.4e+04    |\n",
      "|    total_cost           | 1.49e+06   |\n",
      "|    total_reward         | -1.45e+06  |\n",
      "|    total_reward_pct     | -96.4      |\n",
      "|    total_trades         | 42585      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 914        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02007312 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.0855     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.49       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 8.44       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.77e+04    |\n",
      "|    total_cost           | 1.24e+06    |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98.2       |\n",
      "|    total_trades         | 42256       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 945         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025765477 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0756      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.13        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 974         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011432139 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0569      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.68        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 9.54        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 106151.32\n",
      "total_reward: -1393848.68\n",
      "total_cost: 2966985.21\n",
      "total_trades: 45211\n",
      "Sharpe: 0.314\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.06e+05    |\n",
      "|    total_cost           | 2.97e+06    |\n",
      "|    total_reward         | -1.39e+06   |\n",
      "|    total_reward_pct     | -92.9       |\n",
      "|    total_trades         | 45211       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1005        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014319599 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | -0.00171    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.18e+05    |\n",
      "|    total_cost           | 2.47e+06    |\n",
      "|    total_reward         | -1.38e+06   |\n",
      "|    total_reward_pct     | -92.2       |\n",
      "|    total_trades         | 44189       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1037        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022377165 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.28        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.33e+05     |\n",
      "|    total_cost           | 3.14e+06     |\n",
      "|    total_reward         | -1.27e+06    |\n",
      "|    total_reward_pct     | -84.5        |\n",
      "|    total_trades         | 45381        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 1067         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068262722 |\n",
      "|    clip_fraction        | 0.0972       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.4        |\n",
      "|    explained_variance   | 0.0511       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.72e+04    |\n",
      "|    total_cost           | 9.61e+05    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.5       |\n",
      "|    total_trades         | 41872       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1096        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023068834 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.65        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 65         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 1127       |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01791392 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.5      |\n",
      "|    explained_variance   | 0.197      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.74       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 6.92       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.63e+05    |\n",
      "|    total_cost           | 2.68e+06    |\n",
      "|    total_reward         | -1.24e+06   |\n",
      "|    total_reward_pct     | -82.5       |\n",
      "|    total_trades         | 44839       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1159        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018793201 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0904      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 513309.84\n",
      "total_reward: -986690.16\n",
      "total_cost: 2932115.75\n",
      "total_trades: 44993\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.13e+05    |\n",
      "|    total_cost           | 2.93e+06    |\n",
      "|    total_reward         | -9.87e+05   |\n",
      "|    total_reward_pct     | -65.8       |\n",
      "|    total_trades         | 44993       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1190        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015259203 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.2e+05     |\n",
      "|    total_cost           | 2.32e+06    |\n",
      "|    total_reward         | -9.8e+05    |\n",
      "|    total_reward_pct     | -65.3       |\n",
      "|    total_trades         | 44438       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1221        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018014815 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.41e+05    |\n",
      "|    total_cost           | 3.01e+06    |\n",
      "|    total_reward         | -8.59e+05   |\n",
      "|    total_reward_pct     | -57.3       |\n",
      "|    total_trades         | 44881       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 1253        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012438534 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1283        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017577257 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48          |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 75.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.3e+05    |\n",
      "|    total_cost           | 2.44e+06   |\n",
      "|    total_reward         | -8.7e+05   |\n",
      "|    total_reward_pct     | -58        |\n",
      "|    total_trades         | 44165      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 65         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 1314       |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02123893 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.7      |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.3       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 61.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+05    |\n",
      "|    total_cost           | 1.37e+06    |\n",
      "|    total_reward         | -1.38e+06   |\n",
      "|    total_reward_pct     | -92.2       |\n",
      "|    total_trades         | 42890       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1346        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030003158 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.93        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 641148.04\n",
      "total_reward: -858851.96\n",
      "total_cost: 2004490.45\n",
      "total_trades: 43353\n",
      "Sharpe: 0.001\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 6.41e+05     |\n",
      "|    total_cost           | 2e+06        |\n",
      "|    total_reward         | -8.59e+05    |\n",
      "|    total_reward_pct     | -57.3        |\n",
      "|    total_trades         | 43353        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 65           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 1377         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109326355 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.8        |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 63.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.29e+06   |\n",
      "|    total_cost           | 2.04e+06   |\n",
      "|    total_reward         | -2.08e+05  |\n",
      "|    total_reward_pct     | -13.9      |\n",
      "|    total_trades         | 43805      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 65         |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 1406       |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01130612 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.9      |\n",
      "|    explained_variance   | 0.527      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.7       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 91.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1436        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006564429 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57          |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.93e+06    |\n",
      "|    total_cost           | 2.35e+06    |\n",
      "|    total_reward         | 4.34e+05    |\n",
      "|    total_reward_pct     | 29          |\n",
      "|    total_trades         | 43631       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1468        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019298833 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.31e+05    |\n",
      "|    total_cost           | 1.36e+06    |\n",
      "|    total_reward         | -8.69e+05   |\n",
      "|    total_reward_pct     | -57.9       |\n",
      "|    total_trades         | 42223       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1499        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011954766 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.74e+05    |\n",
      "|    total_cost           | 1.47e+06    |\n",
      "|    total_reward         | -1.13e+06   |\n",
      "|    total_reward_pct     | -75         |\n",
      "|    total_trades         | 42745       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1529        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013717022 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "======Trading from:  2020-03-24 to  2020-07-01\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  397.3376832837864\n",
      "======Model training from:  2000-01-01 to  2020-03-24\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_441_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 147      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 18.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 194      |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 24.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 232      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 45.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 70        |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -401      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 345       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 76        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -0.000123 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 896       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 3.72e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.13e+06  |\n",
      "|    total_cost         | 2.37e+06  |\n",
      "|    total_reward       | 6.63e+06  |\n",
      "|    total_reward_pct   | 442       |\n",
      "|    total_trades       | 41525     |\n",
      "| time/                 |           |\n",
      "|    fps                | 80        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 169       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 21.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 255      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 57.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 85        |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 114       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 19.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 86        |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -92.2     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 15.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 88        |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 299       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 73.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.32e+06 |\n",
      "|    total_cost         | 5.85e+05 |\n",
      "|    total_reward       | 8.22e+05 |\n",
      "|    total_reward_pct   | 54.8     |\n",
      "|    total_trades       | 38796    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 347      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 157      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 472      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 420      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -361     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 88.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 427       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 214       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 1.65e+03  |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.88e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.99e+06 |\n",
      "|    total_cost         | 8.63e+05 |\n",
      "|    total_reward       | 5.49e+06 |\n",
      "|    total_reward_pct   | 366      |\n",
      "|    total_trades       | 42129    |\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -90.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 14.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 509       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 200       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 293      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 45.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 451      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 118      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -644     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 242      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.9e+06  |\n",
      "|    total_cost         | 7.53e+05 |\n",
      "|    total_reward       | 3.4e+06  |\n",
      "|    total_reward_pct   | 227      |\n",
      "|    total_trades       | 41093    |\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 9.33     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 20.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -203     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 29.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 84.4      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 5.17      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00478  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 509      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 138      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 502      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 163      |\n",
      "------------------------------------\n",
      "day: 2547, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 4093340.78\n",
      "total_reward: 2593340.78\n",
      "total_cost: 398755.88\n",
      "total_trades: 38543\n",
      "Sharpe: 0.404\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.09e+06 |\n",
      "|    total_cost         | 3.99e+05 |\n",
      "|    total_reward       | 2.59e+06 |\n",
      "|    total_reward_pct   | 173      |\n",
      "|    total_trades       | 38543    |\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 97.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.79     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -90.7     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 88       |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -178     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 23.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 98        |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 63.3      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 39.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.2e+06  |\n",
      "|    total_cost         | 1.01e+05 |\n",
      "|    total_reward       | 2.7e+06  |\n",
      "|    total_reward_pct   | 180      |\n",
      "|    total_trades       | 34670    |\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 152      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 17.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -249     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 42.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -77.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -252     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -823     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 437      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.58e+06  |\n",
      "|    total_cost         | 6.62e+04  |\n",
      "|    total_reward       | 8.47e+04  |\n",
      "|    total_reward_pct   | 5.65      |\n",
      "|    total_trades       | 31392     |\n",
      "| time/                 |           |\n",
      "|    fps                | 100       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -35.6     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.986     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -171     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 28.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -29.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.58     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -86       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.17      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 160      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.52e+06 |\n",
      "|    total_cost         | 1.05e+05 |\n",
      "|    total_reward       | 1.51e+04 |\n",
      "|    total_reward_pct   | 1.01     |\n",
      "|    total_trades       | 32121    |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 169      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 19.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -137      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -42.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 882      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 451      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -204     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 29.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.67e+06  |\n",
      "|    total_cost         | 6.08e+04  |\n",
      "|    total_reward       | 1.17e+06  |\n",
      "|    total_reward_pct   | 77.9      |\n",
      "|    total_trades       | 33005     |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 50.7      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -86.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 80.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -73.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 243      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -32.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.3      |\n",
      "------------------------------------\n",
      "day: 2547, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 776710.32\n",
      "total_reward: -723289.68\n",
      "total_cost: 14259.18\n",
      "total_trades: 31471\n",
      "Sharpe: 0.314\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.77e+05  |\n",
      "|    total_cost         | 1.43e+04  |\n",
      "|    total_reward       | -7.23e+05 |\n",
      "|    total_reward_pct   | -48.2     |\n",
      "|    total_trades       | 31471     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -153      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 17.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 92.3     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 54       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.81     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 261       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -25.1     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.26      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -128     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 16.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -138     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 20.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 1.41e+04 |\n",
      "|    total_reward       | -4.8e+05 |\n",
      "|    total_reward_pct   | -32      |\n",
      "|    total_trades       | 28441    |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -336     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 62.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 79.4     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 200      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 44.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -441     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 117      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.34e+06  |\n",
      "|    total_cost         | 1.04e+04  |\n",
      "|    total_reward       | -1.64e+05 |\n",
      "|    total_reward_pct   | -10.9     |\n",
      "|    total_trades       | 31987     |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 298       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -86.2     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 6.74      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -71.6    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -74.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 27.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -46.8    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 5.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 317      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -447     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 116      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.15e+06  |\n",
      "|    total_cost         | 7.11e+05  |\n",
      "|    total_reward       | -3.49e+05 |\n",
      "|    total_reward_pct   | -23.3     |\n",
      "|    total_trades       | 32893     |\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 322       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -22.8     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.509     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 61       |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 37.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.825    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 336       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 1.94      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.209     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 4.12     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.049    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.79e+04  |\n",
      "|    total_cost         | 6.72e+05  |\n",
      "|    total_reward       | -1.42e+06 |\n",
      "|    total_reward_pct   | -94.8     |\n",
      "|    total_trades       | 38213     |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 346       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -63.4     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.93      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 350      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 194      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 89.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 354      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 495      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 159      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 359      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -276     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 67.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 363       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -1.29e+03 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.53e+03  |\n",
      "-------------------------------------\n",
      "day: 2547, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1482890.31\n",
      "total_reward: -17109.69\n",
      "total_cost: 210983.92\n",
      "total_trades: 39316\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.48e+06  |\n",
      "|    total_cost         | 2.11e+05  |\n",
      "|    total_reward       | -1.71e+04 |\n",
      "|    total_reward_pct   | -1.14     |\n",
      "|    total_trades       | 39316     |\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 368       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 44.7      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 6.5       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 372      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 487      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 141      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 376       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -2.06e+03 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 2.66e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 381      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 1.99e+03 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.48e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -117     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 84.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.99e+06 |\n",
      "|    total_cost         | 2.71e+05 |\n",
      "|    total_reward       | 1.49e+06 |\n",
      "|    total_reward_pct   | 99.4     |\n",
      "|    total_trades       | 39862    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 390      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -5.05    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 4.67     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 395       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -203      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 23.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 400       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -145      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 16.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 404      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -172     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 31.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 409      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -385     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 143      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 9.88e+05 |\n",
      "|    total_reward       | 6.08e+05 |\n",
      "|    total_reward_pct   | 40.5     |\n",
      "|    total_trades       | 40134    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 414      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 201      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 23       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 419      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 50.4     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 424      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 307      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 57.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 429      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -272     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 86.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 434      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 8.32e+03 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.61e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.25e+07 |\n",
      "|    total_cost         | 9.69e+05 |\n",
      "|    total_reward       | 1.1e+07  |\n",
      "|    total_reward_pct   | 735      |\n",
      "|    total_trades       | 36065    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 439      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -34.6    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 444      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -28.8    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 448      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 38.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 453      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 1.09e+03 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 688      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 457      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -167     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 275      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.42e+06 |\n",
      "|    total_cost         | 7.62e+04 |\n",
      "|    total_reward       | 7.92e+06 |\n",
      "|    total_reward_pct   | 528      |\n",
      "|    total_trades       | 34150    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 462      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -36.5    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 467      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 1.28     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 472      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -16.6    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.326    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 477       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 65.1      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 2.64      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 482      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -1.6e+03 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.28e+03 |\n",
      "------------------------------------\n",
      "day: 2547, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 15001778.22\n",
      "total_reward: 13501778.22\n",
      "total_cost: 177167.66\n",
      "total_trades: 31666\n",
      "Sharpe: 0.317\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.5e+07  |\n",
      "|    total_cost         | 1.77e+05 |\n",
      "|    total_reward       | 1.35e+07 |\n",
      "|    total_reward_pct   | 900      |\n",
      "|    total_trades       | 31666    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 486      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 18.9     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 491      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -59.3    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.55     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 495       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 31.3      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.39      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 500      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.459   |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.000146 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 504      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 477      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 400      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 509       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -1.12e+03 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 818       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.08e+07 |\n",
      "|    total_cost         | 7.35e+04 |\n",
      "|    total_reward       | 9.26e+06 |\n",
      "|    total_reward_pct   | 618      |\n",
      "|    total_trades       | 34371    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 514      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -39.5    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 519      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -114     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 13.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 524      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -40.8    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 529      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 141      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 533       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | 416       |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 114       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.8e+06  |\n",
      "|    total_cost         | 1.45e+05 |\n",
      "|    total_reward       | 1.3e+06  |\n",
      "|    total_reward_pct   | 86.4     |\n",
      "|    total_trades       | 35748    |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 538      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 5.37     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 4.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 543      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -66.9    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 548      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -168     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 13.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 552      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -162     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 18.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 557      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -531     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 151      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.31e+05  |\n",
      "|    total_cost         | 9.52e+04  |\n",
      "|    total_reward       | -7.69e+05 |\n",
      "|    total_reward_pct   | -51.3     |\n",
      "|    total_trades       | 34546     |\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -130      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 7.96      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 567      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 5.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 572      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -73.6    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 5.95     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 577       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | -10       |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.123     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 582       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 251       |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 37.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.62e+05  |\n",
      "|    total_cost         | 3.97e+04  |\n",
      "|    total_reward       | -1.14e+06 |\n",
      "|    total_reward_pct   | -75.9     |\n",
      "|    total_trades       | 34810     |\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 587       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -62.3     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 3.68      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 591      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -56.8    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 5.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 596      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -208     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 24.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 601      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 58.5     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 605      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 17       |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.288    |\n",
      "------------------------------------\n",
      "day: 2547, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 665894.57\n",
      "total_reward: -834105.43\n",
      "total_cost: 33353.72\n",
      "total_trades: 33055\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.66e+05  |\n",
      "|    total_cost         | 3.34e+04  |\n",
      "|    total_reward       | -8.34e+05 |\n",
      "|    total_reward_pct   | -55.6     |\n",
      "|    total_trades       | 33055     |\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 609       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -140      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 16        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 614       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | -380      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 163       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 618      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -137     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 15.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 623      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -204     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 29.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 627      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -154     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 92.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.63e+06 |\n",
      "|    total_cost         | 8.4e+04  |\n",
      "|    total_reward       | 1.31e+05 |\n",
      "|    total_reward_pct   | 8.75     |\n",
      "|    total_trades       | 35058    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 631      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 636      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 336      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 81.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 641      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -774     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 351      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 645      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 607      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 187      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 650      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -59.8    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 159      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.66e+06 |\n",
      "|    total_cost         | 1.58e+05 |\n",
      "|    total_reward       | 1.16e+06 |\n",
      "|    total_reward_pct   | 77.3     |\n",
      "|    total_trades       | 35336    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 655      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 28.7     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.69     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 660       |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | -235      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 31.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 665      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 421      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 92.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 671      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | 919      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 535      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 675      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 52.5     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 73.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.97e+06 |\n",
      "|    total_cost         | 7.28e+04 |\n",
      "|    total_reward       | 4.74e+05 |\n",
      "|    total_reward_pct   | 31.6     |\n",
      "|    total_trades       | 39185    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 680      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 55.2     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 9.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 685      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -435     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 94       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 689      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -237     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 56.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 694      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 22.1     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 698      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -269     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 121      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.51e+06 |\n",
      "|    total_cost         | 3.43e+04 |\n",
      "|    total_reward       | 7.49e+03 |\n",
      "|    total_reward_pct   | 0.499    |\n",
      "|    total_trades       | 41216    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 703      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 60.4     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 708      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -1.35    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.01     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 713       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | 65        |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.98      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 718      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 105      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 6.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 723      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 27.2     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 5.32     |\n",
      "------------------------------------\n",
      "day: 2547, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 737989.08\n",
      "total_reward: -762010.92\n",
      "total_cost: 26441.13\n",
      "total_trades: 41762\n",
      "Sharpe: 0.314\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.38e+05  |\n",
      "|    total_cost         | 2.64e+04  |\n",
      "|    total_reward       | -7.62e+05 |\n",
      "|    total_reward_pct   | -50.8     |\n",
      "|    total_trades       | 41762     |\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 728       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 68.7      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 3.96      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 733       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | 187       |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 23.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 738      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -50.5    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 9.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 742      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 59.4     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 4.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 747      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -169     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 40.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.67e+06 |\n",
      "|    total_cost         | 6.33e+04 |\n",
      "|    total_reward       | 1.17e+06 |\n",
      "|    total_reward_pct   | 77.8     |\n",
      "|    total_trades       | 46749    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 751      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 4.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 756      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 84.2     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 20.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 760      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 71.4     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 14.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 765       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -537      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 225       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 770       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 596       |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 229       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 774      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -613     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 180      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.68e+06 |\n",
      "|    total_cost         | 4.76e+04 |\n",
      "|    total_reward       | 1.85e+05 |\n",
      "|    total_reward_pct   | 12.3     |\n",
      "|    total_trades       | 48852    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 779      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 2.59     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.793    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 784      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -389     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 94.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 789      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -445     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 114      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 793      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 516      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 135      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 798      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -173     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 25       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.24e+06 |\n",
      "|    total_cost         | 6.47e+04 |\n",
      "|    total_reward       | 7.41e+05 |\n",
      "|    total_reward_pct   | 49.4     |\n",
      "|    total_trades       | 49211    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 803      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 70.5     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 807      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 353      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 87.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 812      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 705      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 264      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 817      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 22       |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 2.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 822      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 60.9     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 3.6      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.31e+06  |\n",
      "|    total_cost         | 9.87e+03  |\n",
      "|    total_reward       | -1.93e+05 |\n",
      "|    total_reward_pct   | -12.9     |\n",
      "|    total_trades       | 51710     |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 827       |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | 70        |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 3.95      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 832      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -475     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 123      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 836      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -697     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 207      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 841      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 114      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 845      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 0.584    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.643    |\n",
      "------------------------------------\n",
      "day: 2547, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1976773.33\n",
      "total_reward: 476773.33\n",
      "total_cost: 32540.78\n",
      "total_trades: 51478\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.98e+06 |\n",
      "|    total_cost         | 3.25e+04 |\n",
      "|    total_reward       | 4.77e+05 |\n",
      "|    total_reward_pct   | 31.8     |\n",
      "|    total_trades       | 51478    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 849      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 38.9     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 3.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 853      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 324      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 54.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 858       |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 7.57      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 863      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -46.2    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 9.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 867      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -236     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.51e+06 |\n",
      "|    total_cost         | 2.24e+04 |\n",
      "|    total_reward       | 8.5e+03  |\n",
      "|    total_reward_pct   | 0.567    |\n",
      "|    total_trades       | 51446    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 872      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 22.1     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.789    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 876      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 178      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 16.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 881      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -277     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 37.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 886      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | -142     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 20.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 891       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -353      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 150       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.83e+06 |\n",
      "|    total_cost         | 1.91e+04 |\n",
      "|    total_reward       | 3.33e+05 |\n",
      "|    total_reward_pct   | 22.2     |\n",
      "|    total_trades       | 50926    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 895      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 50.9     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 4.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 900      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.4    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 236      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 31.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 905      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -98.1    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 43.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 910      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 151      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 914      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 10.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.55e+05  |\n",
      "|    total_cost         | 1.13e+04  |\n",
      "|    total_reward       | -5.45e+05 |\n",
      "|    total_reward_pct   | -36.4     |\n",
      "|    total_trades       | 52566     |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 919       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | 505       |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 115       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 924      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 132      |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 928       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | 247       |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 73.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 932      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -19.8    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 36.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 937      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -792     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 412      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.24e+06 |\n",
      "|    total_cost         | 2.21e+04 |\n",
      "|    total_reward       | 7.38e+05 |\n",
      "|    total_reward_pct   | 49.2     |\n",
      "|    total_trades       | 53343    |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 941      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -6.76    |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.452    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 946      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -183     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-03-24 to  2020-07-01\n",
      "A2C Sharpe Ratio:  0.3890024461207807\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_441_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 117  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 17   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.33e+04    |\n",
      "|    total_cost           | 1.64e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.1       |\n",
      "|    total_trades         | 42696       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015096836 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00905    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.9         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4e+04       |\n",
      "|    total_cost           | 2.72e+06    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.3       |\n",
      "|    total_trades         | 44245       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016204236 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0486      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.45e+04    |\n",
      "|    total_cost           | 1.38e+06    |\n",
      "|    total_reward         | -1.41e+06   |\n",
      "|    total_reward_pct     | -93.7       |\n",
      "|    total_trades         | 42201       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025265083 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0308      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.664       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.98        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.67e+04    |\n",
      "|    total_cost           | 2.4e+06     |\n",
      "|    total_reward         | -1.44e+06   |\n",
      "|    total_reward_pct     | -96.2       |\n",
      "|    total_trades         | 43738       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023962615 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0348     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018611971 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.64        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 45\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 51238.15\n",
      "total_reward: -1448761.85\n",
      "total_cost: 1775709.82\n",
      "total_trades: 42937\n",
      "Sharpe: -0.707\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.12e+04    |\n",
      "|    total_cost           | 1.78e+06    |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.6       |\n",
      "|    total_trades         | 42937       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009947684 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0384      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 5.51e+03   |\n",
      "|    total_cost           | 1.24e+06   |\n",
      "|    total_reward         | -1.49e+06  |\n",
      "|    total_reward_pct     | -99.6      |\n",
      "|    total_trades         | 41731      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 142        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02053864 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43        |\n",
      "|    explained_variance   | 0.0967     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.63       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 6.94       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.47e+04    |\n",
      "|    total_cost           | 2.93e+06    |\n",
      "|    total_reward         | -1.42e+06   |\n",
      "|    total_reward_pct     | -94.4       |\n",
      "|    total_trades         | 44783       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023379076 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.00843     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.62        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.22e+05    |\n",
      "|    total_cost           | 3.08e+06    |\n",
      "|    total_reward         | -1.28e+06   |\n",
      "|    total_reward_pct     | -85.2       |\n",
      "|    total_trades         | 44838       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023526546 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.072       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.49        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02152586 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.00253   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.18       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 17.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.38e+04    |\n",
      "|    total_cost           | 1.41e+06    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.4       |\n",
      "|    total_trades         | 41966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014967399 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.64        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.36        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 50\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 57216.78\n",
      "total_reward: -1442783.22\n",
      "total_cost: 2819377.93\n",
      "total_trades: 44245\n",
      "Sharpe: -0.375\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.72e+04    |\n",
      "|    total_cost           | 2.82e+06    |\n",
      "|    total_reward         | -1.44e+06   |\n",
      "|    total_reward_pct     | -96.2       |\n",
      "|    total_trades         | 44245       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009416942 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.61e+05    |\n",
      "|    total_cost           | 3.38e+06    |\n",
      "|    total_reward         | -1.24e+06   |\n",
      "|    total_reward_pct     | -82.6       |\n",
      "|    total_trades         | 45392       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019817282 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 8.91e+04    |\n",
      "|    total_cost           | 2.39e+06    |\n",
      "|    total_reward         | -1.41e+06   |\n",
      "|    total_reward_pct     | -94.1       |\n",
      "|    total_trades         | 44031       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030786783 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021540305 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 6.13e+04   |\n",
      "|    total_cost           | 2.27e+06   |\n",
      "|    total_reward         | -1.44e+06  |\n",
      "|    total_reward_pct     | -95.9      |\n",
      "|    total_trades         | 43674      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02552611 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.77       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 13.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.81e+04    |\n",
      "|    total_cost           | 2.74e+06    |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.8       |\n",
      "|    total_trades         | 44192       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008024232 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 55\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 43351.45\n",
      "total_reward: -1456648.55\n",
      "total_cost: 1767586.63\n",
      "total_trades: 42639\n",
      "Sharpe: -0.075\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.34e+04    |\n",
      "|    total_cost           | 1.77e+06    |\n",
      "|    total_reward         | -1.46e+06   |\n",
      "|    total_reward_pct     | -97.1       |\n",
      "|    total_trades         | 42639       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014557976 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.46        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.18e+05    |\n",
      "|    total_cost           | 3.2e+06     |\n",
      "|    total_reward         | -1.18e+06   |\n",
      "|    total_reward_pct     | -78.8       |\n",
      "|    total_trades         | 44960       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021927962 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.5         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014794845 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.97e+05    |\n",
      "|    total_cost           | 4.41e+06    |\n",
      "|    total_reward         | -5.03e+05   |\n",
      "|    total_reward_pct     | -33.5       |\n",
      "|    total_trades         | 46537       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012578774 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.01e+05    |\n",
      "|    total_cost           | 2.79e+06    |\n",
      "|    total_reward         | -1.3e+06    |\n",
      "|    total_reward_pct     | -86.6       |\n",
      "|    total_trades         | 44226       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008774748 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 70.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.92e+04    |\n",
      "|    total_cost           | 1.3e+06     |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.4       |\n",
      "|    total_trades         | 41977       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016553385 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.05        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 60\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1373369.99\n",
      "total_reward: -126630.01\n",
      "total_cost: 4713963.92\n",
      "total_trades: 45826\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.37e+06    |\n",
      "|    total_cost           | 4.71e+06    |\n",
      "|    total_reward         | -1.27e+05   |\n",
      "|    total_reward_pct     | -8.44       |\n",
      "|    total_trades         | 45826       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025348047 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 472          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063834954 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.8        |\n",
      "|    explained_variance   | 0.201        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 292          |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 463          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.29e+05    |\n",
      "|    total_cost           | 3.18e+06    |\n",
      "|    total_reward         | -1.07e+06   |\n",
      "|    total_reward_pct     | -71.4       |\n",
      "|    total_trades         | 44842       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016896777 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.8        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.4e+06     |\n",
      "|    total_cost           | 5.41e+06    |\n",
      "|    total_reward         | -1.04e+05   |\n",
      "|    total_reward_pct     | -6.96       |\n",
      "|    total_trades         | 46245       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 510         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007934982 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 288         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 492         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.87e+04    |\n",
      "|    total_cost           | 9.85e+05    |\n",
      "|    total_reward         | -1.44e+06   |\n",
      "|    total_reward_pct     | -96.1       |\n",
      "|    total_trades         | 41002       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 529         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009208018 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 93          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.05e+05    |\n",
      "|    total_cost           | 1.43e+06    |\n",
      "|    total_reward         | -1.4e+06    |\n",
      "|    total_reward_pct     | -93         |\n",
      "|    total_trades         | 42120       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017806197 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.72        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009562226 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.85        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 65\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1734033.37\n",
      "total_reward: 234033.37\n",
      "total_cost: 4513733.62\n",
      "total_trades: 45817\n",
      "Sharpe: 0.253\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.73e+06    |\n",
      "|    total_cost           | 4.51e+06    |\n",
      "|    total_reward         | 2.34e+05    |\n",
      "|    total_reward_pct     | 15.6        |\n",
      "|    total_trades         | 45817       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012204664 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 493         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.78e+06   |\n",
      "|    total_cost           | 4.01e+06   |\n",
      "|    total_reward         | 1.28e+06   |\n",
      "|    total_reward_pct     | 85.3       |\n",
      "|    total_trades         | 45213      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 600        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00886892 |\n",
      "|    clip_fraction        | 0.0335     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 242        |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0099    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 670        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.25e+06    |\n",
      "|    total_cost           | 3.28e+06    |\n",
      "|    total_reward         | -2.45e+05   |\n",
      "|    total_reward_pct     | -16.3       |\n",
      "|    total_trades         | 44165       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 618         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008177659 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 252         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 367         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.08e+05   |\n",
      "|    total_cost           | 1.14e+06   |\n",
      "|    total_reward         | -1.39e+06  |\n",
      "|    total_reward_pct     | -92.8      |\n",
      "|    total_trades         | 42292      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 637        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09209277 |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.737      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.7       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | 0.0339     |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 104        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 656          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082201995 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.1        |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 6.1e+05      |\n",
      "|    total_cost           | 3.71e+06     |\n",
      "|    total_reward         | -8.9e+05     |\n",
      "|    total_reward_pct     | -59.4        |\n",
      "|    total_trades         | 45860        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 675          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026540179 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.1        |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.9         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00918     |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "day: 2547, episode: 70\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 250790.07\n",
      "total_reward: -1249209.93\n",
      "total_cost: 2384435.87\n",
      "total_trades: 44595\n",
      "Sharpe: -0.094\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 2.51e+05   |\n",
      "|    total_cost           | 2.38e+06   |\n",
      "|    total_reward         | -1.25e+06  |\n",
      "|    total_reward_pct     | -83.3      |\n",
      "|    total_trades         | 44595      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 693        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02247875 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.873      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.5       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 22.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.92e+04    |\n",
      "|    total_cost           | 5.34e+05    |\n",
      "|    total_reward         | -1.48e+06   |\n",
      "|    total_reward_pct     | -98.7       |\n",
      "|    total_trades         | 40913       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 711         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022503959 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.8         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.44e+05    |\n",
      "|    total_cost           | 3.59e+06    |\n",
      "|    total_reward         | -1.16e+06   |\n",
      "|    total_reward_pct     | -77.1       |\n",
      "|    total_trades         | 46145       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 729         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013598286 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.52        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 747         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016638374 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 49.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.58e+05    |\n",
      "|    total_cost           | 1.05e+06    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.4       |\n",
      "|    total_trades         | 42153       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4           |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 21049       |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025633046 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 4.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.67e+05    |\n",
      "|    total_cost           | 3.07e+06    |\n",
      "|    total_reward         | -1.13e+06   |\n",
      "|    total_reward_pct     | -75.5       |\n",
      "|    total_trades         | 45532       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4           |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 21070       |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012774119 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "day: 2547, episode: 75\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 208595.26\n",
      "total_reward: -1291404.74\n",
      "total_cost: 3282028.44\n",
      "total_trades: 45669\n",
      "Sharpe: 0.075\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.09e+05     |\n",
      "|    total_cost           | 3.28e+06     |\n",
      "|    total_reward         | -1.29e+06    |\n",
      "|    total_reward_pct     | -86.1        |\n",
      "|    total_trades         | 45669        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4            |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 21086        |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115953535 |\n",
      "|    clip_fraction        | 0.0986       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.5        |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.4         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0137      |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.93e+05    |\n",
      "|    total_cost           | 3.2e+06     |\n",
      "|    total_reward         | -9.07e+05   |\n",
      "|    total_reward_pct     | -60.4       |\n",
      "|    total_trades         | 45658       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4           |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 21103       |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.118250325 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.0551      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 92.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4           |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 21120       |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005554639 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.2        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.32e+05    |\n",
      "|    total_cost           | 1.91e+06    |\n",
      "|    total_reward         | -1.37e+06   |\n",
      "|    total_reward_pct     | -91.2       |\n",
      "|    total_trades         | 43860       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4           |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 21136       |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025271745 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.27        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.69e+06     |\n",
      "|    total_cost           | 5.24e+06     |\n",
      "|    total_reward         | 1.85e+05     |\n",
      "|    total_reward_pct     | 12.4         |\n",
      "|    total_trades         | 48034        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4            |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 21154        |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064741503 |\n",
      "|    clip_fraction        | 0.0841       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.6        |\n",
      "|    explained_variance   | 0.288        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 121          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00786     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 215          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+05    |\n",
      "|    total_cost           | 2.07e+06    |\n",
      "|    total_reward         | -1.4e+06    |\n",
      "|    total_reward_pct     | -93.3       |\n",
      "|    total_trades         | 44508       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4           |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 21173       |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009142231 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-03-24 to  2020-07-01\n",
      "PPO Sharpe Ratio:  0.25008888077436014\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_441_1\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.49e+06  |\n",
      "|    total_cost       | 3.16e+03  |\n",
      "|    total_reward     | -1.11e+04 |\n",
      "|    total_reward_pct | -0.74     |\n",
      "|    total_trades     | 34756     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 37        |\n",
      "|    time_elapsed     | 272       |\n",
      "|    total timesteps  | 10192     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -88.4     |\n",
      "|    critic_loss      | 82        |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7644      |\n",
      "-----------------------------------\n",
      "day: 2547, episode: 85\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1767747.46\n",
      "total_reward: 267747.46\n",
      "total_cost: 4007.20\n",
      "total_trades: 34758\n",
      "Sharpe: 0.313\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.52e+06 |\n",
      "|    total_cost       | 3.15e+03 |\n",
      "|    total_reward     | 2e+04    |\n",
      "|    total_reward_pct | 1.34     |\n",
      "|    total_trades     | 34756    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 678      |\n",
      "|    total timesteps  | 20384    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -53.4    |\n",
      "|    critic_loss      | 49.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 17836    |\n",
      "----------------------------------\n",
      "day: 2547, episode: 90\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1498631.46\n",
      "total_reward: -1368.54\n",
      "total_cost: 4639.04\n",
      "total_trades: 34759\n",
      "Sharpe: 0.306\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.64e+06 |\n",
      "|    total_cost       | 4.01e+03 |\n",
      "|    total_reward     | 1.39e+05 |\n",
      "|    total_reward_pct | 9.3      |\n",
      "|    total_trades     | 34758    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 1096     |\n",
      "|    total timesteps  | 30576    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -32.3    |\n",
      "|    critic_loss      | 109      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 28028    |\n",
      "----------------------------------\n",
      "day: 2547, episode: 95\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1902955.02\n",
      "total_reward: 402955.02\n",
      "total_cost: 4748.70\n",
      "total_trades: 34759\n",
      "Sharpe: 0.308\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.49e+06  |\n",
      "|    total_cost       | 3.16e+03  |\n",
      "|    total_reward     | -1.07e+04 |\n",
      "|    total_reward_pct | -0.716    |\n",
      "|    total_trades     | 34756     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 26        |\n",
      "|    time_elapsed     | 1553      |\n",
      "|    total timesteps  | 40768     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -20.5     |\n",
      "|    critic_loss      | 27.4      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 38220     |\n",
      "-----------------------------------\n",
      "day: 2547, episode: 100\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2122917.70\n",
      "total_reward: 622917.70\n",
      "total_cost: 4538.26\n",
      "total_trades: 34760\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.12e+06 |\n",
      "|    total_cost       | 4.54e+03 |\n",
      "|    total_reward     | 6.23e+05 |\n",
      "|    total_reward_pct | 41.5     |\n",
      "|    total_trades     | 34760    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 25       |\n",
      "|    time_elapsed     | 2009     |\n",
      "|    total timesteps  | 50960    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | -13.5    |\n",
      "|    critic_loss      | 73.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 48412    |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-03-24 to  2020-07-01\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-07-01\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ensemble_441_1\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.83e+06 |\n",
      "|    total_cost       | 8.26e+03 |\n",
      "|    total_reward     | 1.33e+06 |\n",
      "|    total_reward_pct | 88.9     |\n",
      "|    total_trades     | 35766    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total timesteps  | 10444    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 46       |\n",
      "|    critic_loss      | 102      |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 7833     |\n",
      "----------------------------------\n",
      "day: 2610, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1665413.07\n",
      "total_reward: 165413.07\n",
      "total_cost: 5349.10\n",
      "total_trades: 35765\n",
      "Sharpe: 0.308\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 2.55e+06 |\n",
      "|    total_cost       | 4.09e+03 |\n",
      "|    total_reward     | 1.05e+06 |\n",
      "|    total_reward_pct | 70.2     |\n",
      "|    total_trades     | 35767    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 667      |\n",
      "|    total timesteps  | 20888    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 23.7     |\n",
      "|    critic_loss      | 95.4     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 18277    |\n",
      "----------------------------------\n",
      "day: 2610, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1870818.14\n",
      "total_reward: 370818.14\n",
      "total_cost: 6133.98\n",
      "total_trades: 35764\n",
      "Sharpe: 0.291\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.5e+06   |\n",
      "|    total_cost       | 2.84e+03  |\n",
      "|    total_reward     | -2.84e+03 |\n",
      "|    total_reward_pct | -0.19     |\n",
      "|    total_trades     | 37052     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 30        |\n",
      "|    time_elapsed     | 1027      |\n",
      "|    total timesteps  | 31332     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 11.4      |\n",
      "|    critic_loss      | 84.6      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 28721     |\n",
      "-----------------------------------\n",
      "day: 2610, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1950452.66\n",
      "total_reward: 450452.66\n",
      "total_cost: 4090.56\n",
      "total_trades: 37055\n",
      "Sharpe: 0.281\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.42e+06  |\n",
      "|    total_cost       | 2.99e+03  |\n",
      "|    total_reward     | -7.71e+04 |\n",
      "|    total_reward_pct | -5.14     |\n",
      "|    total_trades     | 37056     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 29        |\n",
      "|    time_elapsed     | 1396      |\n",
      "|    total timesteps  | 41776     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | 4.26      |\n",
      "|    critic_loss      | 63.2      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 39165     |\n",
      "-----------------------------------\n",
      "day: 2610, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1536875.70\n",
      "total_reward: 36875.70\n",
      "total_cost: 2903.42\n",
      "total_trades: 37054\n",
      "Sharpe: 0.339\n",
      "=================================\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.54e+06 |\n",
      "|    total_cost       | 2.9e+03  |\n",
      "|    total_reward     | 3.69e+04 |\n",
      "|    total_reward_pct | 2.46     |\n",
      "|    total_trades     | 37054    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 1769     |\n",
      "|    total timesteps  | 52220    |\n",
      "| train/              |          |\n",
      "|    actor_loss       | 0.118    |\n",
      "|    critic_loss      | 72.7     |\n",
      "|    learning_rate    | 5e-06    |\n",
      "|    n_updates        | 49609    |\n",
      "----------------------------------\n",
      "======Trading from:  2020-07-01 to  2020-10-02\n",
      "============================================\n",
      "nan\n",
      "turbulence_threshold:  397.3376832837864\n",
      "======Model training from:  2000-01-01 to  2020-07-01\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_504_1\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0.00532  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -9       |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 0.402    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 21.7     |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 0.306    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 21.2     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.433    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 31.5      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.708     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -183     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 27.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.54e+05  |\n",
      "|    total_cost         | 1.99e+06  |\n",
      "|    total_reward       | -7.46e+05 |\n",
      "|    total_reward_pct   | -49.7     |\n",
      "|    total_trades       | 46567     |\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 49        |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.59      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 132      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00215 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 19.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -116     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -97.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.84     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.06e+05  |\n",
      "|    total_cost         | 8.58e+05  |\n",
      "|    total_reward       | -8.94e+05 |\n",
      "|    total_reward_pct   | -59.6     |\n",
      "|    total_trades       | 44467     |\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -311      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 86.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 331       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 70.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -300     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 61.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 395      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 194      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -36.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 113      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.98e+06 |\n",
      "|    total_cost         | 1.89e+06 |\n",
      "|    total_reward       | 5.48e+06 |\n",
      "|    total_reward_pct   | 365      |\n",
      "|    total_trades       | 44534    |\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 115      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 8.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -17.7    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.798    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -233     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 30.8      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.557     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -0.000955 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -1.45e+03 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.63e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.1e+06  |\n",
      "|    total_cost         | 4.95e+05 |\n",
      "|    total_reward       | 6.6e+06  |\n",
      "|    total_reward_pct   | 440      |\n",
      "|    total_trades       | 40017    |\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 42.6     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 24.3     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.603    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -23.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.84     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 98        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -132      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.53      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 2.02e+03 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.67e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.00808 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 1.3e+03  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.03e+03 |\n",
      "------------------------------------\n",
      "day: 2610, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 5159165.25\n",
      "total_reward: 3659165.25\n",
      "total_cost: 148632.65\n",
      "total_trades: 39371\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.16e+06  |\n",
      "|    total_cost         | 1.49e+05  |\n",
      "|    total_reward       | 3.66e+06  |\n",
      "|    total_reward_pct   | 244       |\n",
      "|    total_trades       | 39371     |\n",
      "| time/                 |           |\n",
      "|    fps                | 98        |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 25        |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.567     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 66.5     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 11.7     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 51.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -147     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 56.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.41e+06 |\n",
      "|    total_cost         | 5.45e+05 |\n",
      "|    total_reward       | 4.91e+06 |\n",
      "|    total_reward_pct   | 328      |\n",
      "|    total_trades       | 39763    |\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -12.3    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0994   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 4.98     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0499   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -138     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 19.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 80.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 4.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 181       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -549      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 184       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.33e+05  |\n",
      "|    total_cost         | 5.38e+05  |\n",
      "|    total_reward       | -7.67e+05 |\n",
      "|    total_reward_pct   | -51.1     |\n",
      "|    total_trades       | 39260     |\n",
      "| time/                 |           |\n",
      "|    fps                | 98        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 48.2      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.71      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 596      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 235      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -760     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 314      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 114      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 45.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 1.46e+03  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.25e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.89e+06 |\n",
      "|    total_cost         | 2.27e+05 |\n",
      "|    total_reward       | 3.39e+06 |\n",
      "|    total_reward_pct   | 226      |\n",
      "|    total_trades       | 35738    |\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 3.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -213     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 62.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 1.08e+03 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 818      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -97.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 34.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 138      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 364      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.88e+07  |\n",
      "|    total_cost         | 7.28e+05  |\n",
      "|    total_reward       | 1.73e+07  |\n",
      "|    total_reward_pct   | 1.16e+03  |\n",
      "|    total_trades       | 34139     |\n",
      "| time/                 |           |\n",
      "|    fps                | 100       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -3.29e+03 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.51e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 16       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 30.2     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -1.49    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0483   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -84.1    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 109      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 7.68     |\n",
      "------------------------------------\n",
      "day: 2610, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 717726.18\n",
      "total_reward: -782273.82\n",
      "total_cost: 94619.10\n",
      "total_trades: 32120\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.18e+05  |\n",
      "|    total_cost         | 9.46e+04  |\n",
      "|    total_reward       | -7.82e+05 |\n",
      "|    total_reward_pct   | -52.2     |\n",
      "|    total_trades       | 32120     |\n",
      "| time/                 |           |\n",
      "|    fps                | 100       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 263       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -9.39     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 268      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 37.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 8.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 30       |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 154      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -299     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 76.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -597     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 221      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.18e+06 |\n",
      "|    total_cost         | 1.37e+05 |\n",
      "|    total_reward       | 1.68e+06 |\n",
      "|    total_reward_pct   | 112      |\n",
      "|    total_trades       | 30749    |\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -55.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -6.93    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.09     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 100       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 297       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -734      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 408       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -136     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 56.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -99      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 31.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.73e+06 |\n",
      "|    total_cost         | 1.14e+05 |\n",
      "|    total_reward       | 1.23e+06 |\n",
      "|    total_reward_pct   | 82.1     |\n",
      "|    total_trades       | 30986    |\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 61.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 530      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 186      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 44.7     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 788      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 100       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 326       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -55.6     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 101       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -387     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 91.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.81e+06  |\n",
      "|    total_cost         | 3.42e+04  |\n",
      "|    total_reward       | 2.31e+06  |\n",
      "|    total_reward_pct   | 154       |\n",
      "|    total_trades       | 27970     |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 336       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 114       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 10.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 224      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 41       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 346      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -83.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.15e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -704     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 308      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -165     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 360       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 473       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 342       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.78e+06  |\n",
      "|    total_cost         | 3.26e+04  |\n",
      "|    total_reward       | 2.28e+06  |\n",
      "|    total_reward_pct   | 152       |\n",
      "|    total_trades       | 28402     |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 365       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -95.6     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6.22      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 370      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -22      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 16.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 375       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 229       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 39.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 380      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -182     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 27.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 424      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 128      |\n",
      "------------------------------------\n",
      "day: 2610, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1961415.58\n",
      "total_reward: 461415.58\n",
      "total_cost: 26969.59\n",
      "total_trades: 30040\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.96e+06 |\n",
      "|    total_cost         | 2.7e+04  |\n",
      "|    total_reward       | 4.61e+05 |\n",
      "|    total_reward_pct   | 30.8     |\n",
      "|    total_trades       | 30040    |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 390      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 108      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 395      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -99.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 8.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 399      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -19.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 45.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 405      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 21.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 20.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -635     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 676      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.21e+06  |\n",
      "|    total_cost         | 1.69e+04  |\n",
      "|    total_reward       | 7.14e+05  |\n",
      "|    total_reward_pct   | 47.6      |\n",
      "|    total_trades       | 27705     |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 415       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -107      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 11.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 419       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 845       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 436       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 424       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 15.3      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 225       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 429      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 448      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 202      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 434       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 1.13e+03  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.01e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.05e+06 |\n",
      "|    total_cost         | 2.58e+04 |\n",
      "|    total_reward       | 2.55e+06 |\n",
      "|    total_reward_pct   | 170      |\n",
      "|    total_trades       | 26940    |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 438      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 170      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 443      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -230     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 69.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 448       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 882       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 818       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 453      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 1.61e+03 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.22e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 458      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 290      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 137      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.21e+06 |\n",
      "|    total_cost         | 1.96e+04 |\n",
      "|    total_reward       | 1.71e+06 |\n",
      "|    total_reward_pct   | 114      |\n",
      "|    total_trades       | 25900    |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 462      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -173     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 40.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 467      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 80.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 472       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -11.5     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 48.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 477      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -84.3    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 20.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 481       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -1.26e+03 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 985       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 486      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 520      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 196      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.22e+06  |\n",
      "|    total_cost         | 3.01e+04  |\n",
      "|    total_reward       | 1.72e+06  |\n",
      "|    total_reward_pct   | 114       |\n",
      "|    total_trades       | 25789     |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 491       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -58.8     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.6       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 496      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -164     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 23.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 500       |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | 654       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 446       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 505      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -536     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 145      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 510       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | -1.16e+03 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 805       |\n",
      "-------------------------------------\n",
      "day: 2610, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2558809.96\n",
      "total_reward: 1058809.96\n",
      "total_cost: 18264.01\n",
      "total_trades: 25902\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.56e+06 |\n",
      "|    total_cost         | 1.83e+04 |\n",
      "|    total_reward       | 1.06e+06 |\n",
      "|    total_reward_pct   | 70.6     |\n",
      "|    total_trades       | 25902    |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 516      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -1.58    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 520      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -32.5    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 4.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 525      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -428     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 113      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 530      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 189      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 29.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 535      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 485      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 170      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.51e+06 |\n",
      "|    total_cost         | 1.47e+04 |\n",
      "|    total_reward       | 1.01e+06 |\n",
      "|    total_reward_pct   | 67.1     |\n",
      "|    total_trades       | 24276    |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 540      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 140      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 545      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 35.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 550      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -176     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 25.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 554      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -85      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 5.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 559      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -44.6    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.39     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.18e+06  |\n",
      "|    total_cost         | 5.47e+03  |\n",
      "|    total_reward       | -3.23e+05 |\n",
      "|    total_reward_pct   | -21.5     |\n",
      "|    total_trades       | 23258     |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 564       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -12.4     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.508     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 569      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 237      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 32.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 574      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -11.1    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 84.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 579      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -435     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 106      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 583      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -36.7    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.784    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 588      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 85.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 31.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.25e+06  |\n",
      "|    total_cost         | 8.26e+03  |\n",
      "|    total_reward       | -2.53e+05 |\n",
      "|    total_reward_pct   | -16.8     |\n",
      "|    total_trades       | 23077     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 592       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | -79       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 6.23      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 597      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -719     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 285      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 602      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 53.8     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 20.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 607       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -83.7     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.07      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 612       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 408       |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 153       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.24e+06 |\n",
      "|    total_cost         | 1.51e+04 |\n",
      "|    total_reward       | 7.39e+05 |\n",
      "|    total_reward_pct   | 49.3     |\n",
      "|    total_trades       | 20643    |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 617      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 54.3     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 621       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | -216      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 26.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 626      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -379     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 97.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 631      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -218     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 41       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 635      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 75.7     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 148      |\n",
      "------------------------------------\n",
      "day: 2610, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2019751.78\n",
      "total_reward: 519751.78\n",
      "total_cost: 14905.91\n",
      "total_trades: 19332\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.02e+06 |\n",
      "|    total_cost         | 1.49e+04 |\n",
      "|    total_reward       | 5.2e+05  |\n",
      "|    total_reward_pct   | 34.7     |\n",
      "|    total_trades       | 19332    |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 640      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -23.5    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 17.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 645      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -141     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 18.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 650      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 94.2     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 8.34     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 655       |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | 173       |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 15.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 660      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 117      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 8.92     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.3e+06   |\n",
      "|    total_cost         | 8.86e+03  |\n",
      "|    total_reward       | -1.99e+05 |\n",
      "|    total_reward_pct   | -13.2     |\n",
      "|    total_trades       | 18264     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 665       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 46.6      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 670      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 27.2     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 675      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 143      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 680      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 44.2     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 685      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 7.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.23e+05  |\n",
      "|    total_cost         | 4.95e+03  |\n",
      "|    total_reward       | -8.77e+05 |\n",
      "|    total_reward_pct   | -58.5     |\n",
      "|    total_trades       | 14713     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 690       |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -17.7     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.584     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 695       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | 331       |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 61.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 700      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -448     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 118      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 705      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 709       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -74.2     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 20.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 714      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 303      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 92.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.7e+06  |\n",
      "|    total_cost         | 1.32e+04 |\n",
      "|    total_reward       | 1.98e+05 |\n",
      "|    total_reward_pct   | 13.2     |\n",
      "|    total_trades       | 17125    |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 719      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 122      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 723      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 167      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 14.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 728      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 272      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 37.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 733      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 14.9     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.36     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 738      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -309     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 55.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.67e+05  |\n",
      "|    total_cost         | 6.72e+03  |\n",
      "|    total_reward       | -8.33e+05 |\n",
      "|    total_reward_pct   | -55.6     |\n",
      "|    total_trades       | 16380     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 743       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | 2.48      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.341     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 748       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 39        |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.5       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 752      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -29.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 757      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -6.53    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.984    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 762      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 4.24     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 8.5      |\n",
      "------------------------------------\n",
      "day: 2610, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 987774.74\n",
      "total_reward: -512225.26\n",
      "total_cost: 7000.84\n",
      "total_trades: 15007\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.88e+05  |\n",
      "|    total_cost         | 7e+03     |\n",
      "|    total_reward       | -5.12e+05 |\n",
      "|    total_reward_pct   | -34.1     |\n",
      "|    total_trades       | 15007     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 767       |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -38.7     |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 772      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 57.2     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 4.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 777      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 7.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 782      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 73.2     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 3.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 787      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 149      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 22.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.78e+05  |\n",
      "|    total_cost         | 1.11e+04  |\n",
      "|    total_reward       | -6.22e+05 |\n",
      "|    total_reward_pct   | -41.4     |\n",
      "|    total_trades       | 16796     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 792       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | -14.2     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.231     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 797      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 61.5     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 801      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 32.4     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.881    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 806      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -9.36    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.642    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 811      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 112      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 9.91     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 816       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | 171       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 22        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.44e+05  |\n",
      "|    total_cost         | 1.01e+04  |\n",
      "|    total_reward       | -9.56e+05 |\n",
      "|    total_reward_pct   | -63.8     |\n",
      "|    total_trades       | 18926     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 821       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | 100       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 6.47      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 826      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -164     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 17.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 831      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -45.8    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 836      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -23.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 14.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 841      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 253      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 34.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.27e+06  |\n",
      "|    total_cost         | 1.33e+04  |\n",
      "|    total_reward       | -2.28e+05 |\n",
      "|    total_reward_pct   | -15.2     |\n",
      "|    total_trades       | 18982     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 846       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -83.2     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 5.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 850      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 54.7     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 855      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 56.1     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 860      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -35.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 865      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | -92.3    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 10.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.22e+06  |\n",
      "|    total_cost         | 8.4e+03   |\n",
      "|    total_reward       | -2.79e+05 |\n",
      "|    total_reward_pct   | -18.6     |\n",
      "|    total_trades       | 19815     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 870       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | -79.8     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 43.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 875      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -108     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 15       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 880      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 182      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 26.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 885      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 170      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 26.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 889      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -219     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 31.3     |\n",
      "------------------------------------\n",
      "day: 2610, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 2587889.96\n",
      "total_reward: 1087889.96\n",
      "total_cost: 13560.73\n",
      "total_trades: 19683\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.59e+06 |\n",
      "|    total_cost         | 1.36e+04 |\n",
      "|    total_reward       | 1.09e+06 |\n",
      "|    total_reward_pct   | 72.5     |\n",
      "|    total_trades       | 19683    |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 894      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 85.1     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 899      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 8.89     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.451    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 904      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -21.3    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 2.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 909      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 36.3     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 913      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 22.5     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8e+05    |\n",
      "|    total_cost         | 8.1e+03  |\n",
      "|    total_reward       | -7e+05   |\n",
      "|    total_reward_pct   | -46.7    |\n",
      "|    total_trades       | 18478    |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 918      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -23.2    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.558    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 923      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 86       |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 6.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 928      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -175     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 23.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 934      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -115     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 7.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 939      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 38.3     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 5.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 943      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -47.2    |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 8.26     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.7e+05   |\n",
      "|    total_cost         | 5.37e+03  |\n",
      "|    total_reward       | -7.3e+05  |\n",
      "|    total_reward_pct   | -48.7     |\n",
      "|    total_trades       | 19200     |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 949       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | 289       |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 93.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 954       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | 444       |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 143       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 959      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 473      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 182      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 964      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -0.551   |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 8.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 969      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -673     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 317      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.11e+06 |\n",
      "|    total_cost         | 1.4e+04  |\n",
      "|    total_reward       | 6.08e+05 |\n",
      "|    total_reward_pct   | 40.5     |\n",
      "|    total_trades       | 18621    |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 974      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 53.9     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 3.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 978      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 43.1     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2020-07-01 to  2020-10-02\n",
      "A2C Sharpe Ratio:  0.30150049350655406\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_504_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 105  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 19   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "day: 2610, episode: 40\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 7262.02\n",
      "total_reward: -1492737.98\n",
      "total_cost: 1122416.08\n",
      "total_trades: 42505\n",
      "Sharpe: -0.851\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.26e+03    |\n",
      "|    total_cost           | 1.12e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.5       |\n",
      "|    total_trades         | 42505       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018337457 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0687     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.48e+04    |\n",
      "|    total_cost           | 1.91e+06    |\n",
      "|    total_reward         | -1.44e+06   |\n",
      "|    total_reward_pct     | -95.7       |\n",
      "|    total_trades         | 43932       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009949584 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00105     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.02        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.96        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.92e+03    |\n",
      "|    total_cost           | 1.06e+06    |\n",
      "|    total_reward         | -1.5e+06    |\n",
      "|    total_reward_pct     | -99.7       |\n",
      "|    total_trades         | 42853       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029095318 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010179993 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.91        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.76e+04    |\n",
      "|    total_cost           | 2.3e+06     |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98.2       |\n",
      "|    total_trades         | 44909       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013612429 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0243      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.27        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.87e+04    |\n",
      "|    total_cost           | 1.03e+06    |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.4       |\n",
      "|    total_trades         | 42891       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015902963 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0215      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "day: 2610, episode: 45\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 46129.63\n",
      "total_reward: -1453870.37\n",
      "total_cost: 1344561.75\n",
      "total_trades: 43701\n",
      "Sharpe: -0.519\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.61e+04    |\n",
      "|    total_cost           | 1.34e+06    |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.9       |\n",
      "|    total_trades         | 43701       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011088865 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0601      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.91        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.52e+03    |\n",
      "|    total_cost           | 1.09e+06    |\n",
      "|    total_reward         | -1.5e+06    |\n",
      "|    total_reward_pct     | -99.8       |\n",
      "|    total_trades         | 43274       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015083319 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0881      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.68        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.77        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01163259 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.0799     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.115      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 3.41       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 4.51e+04     |\n",
      "|    total_cost           | 1.94e+06     |\n",
      "|    total_reward         | -1.45e+06    |\n",
      "|    total_reward_pct     | -97          |\n",
      "|    total_trades         | 44146        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074478667 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.6        |\n",
      "|    explained_variance   | 0.0403       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.75         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 9.19         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.84e+04     |\n",
      "|    total_cost           | 2.61e+06     |\n",
      "|    total_reward         | -1.4e+06     |\n",
      "|    total_reward_pct     | -93.4        |\n",
      "|    total_trades         | 45373        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052079502 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.7        |\n",
      "|    explained_variance   | 0.0269       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.94         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 1.04e+05  |\n",
      "|    total_cost           | 1.99e+06  |\n",
      "|    total_reward         | -1.4e+06  |\n",
      "|    total_reward_pct     | -93.1     |\n",
      "|    total_trades         | 44196     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 106       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 249       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0217267 |\n",
      "|    clip_fraction        | 0.163     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.7     |\n",
      "|    explained_variance   | 0.108     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 3         |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -0.0159   |\n",
      "|    std                  | 1.04      |\n",
      "|    value_loss           | 9.34      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019803077 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.35        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.44        |\n",
      "-----------------------------------------\n",
      "day: 2610, episode: 50\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 116782.01\n",
      "total_reward: -1383217.99\n",
      "total_cost: 2199799.89\n",
      "total_trades: 44686\n",
      "Sharpe: 0.239\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.17e+05    |\n",
      "|    total_cost           | 2.2e+06     |\n",
      "|    total_reward         | -1.38e+06   |\n",
      "|    total_reward_pct     | -92.2       |\n",
      "|    total_trades         | 44686       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027927147 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.0134     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.03        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.93        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| environment/            |           |\n",
      "|    portfolio_value      | 3.57e+03  |\n",
      "|    total_cost           | 9.06e+05  |\n",
      "|    total_reward         | -1.5e+06  |\n",
      "|    total_reward_pct     | -99.8     |\n",
      "|    total_trades         | 42300     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 106       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 307       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0174537 |\n",
      "|    clip_fraction        | 0.154     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.9     |\n",
      "|    explained_variance   | 0.0655    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.741     |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -0.0112   |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 7.47      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.3e+04      |\n",
      "|    total_cost           | 1.14e+06     |\n",
      "|    total_reward         | -1.49e+06    |\n",
      "|    total_reward_pct     | -99.1        |\n",
      "|    total_trades         | 42768        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 327          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036363453 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44          |\n",
      "|    explained_variance   | 0.112        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.79         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 5.95         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.87e+04    |\n",
      "|    total_cost           | 1.6e+06     |\n",
      "|    total_reward         | -1.44e+06   |\n",
      "|    total_reward_pct     | -96.1       |\n",
      "|    total_trades         | 43702       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014489846 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0767      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.6         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013689689 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.986       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 6.45        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 7.24e+04    |\n",
      "|    total_cost           | 1.4e+06     |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.2       |\n",
      "|    total_trades         | 43475       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021382311 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.059       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.26        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 4.56        |\n",
      "-----------------------------------------\n",
      "day: 2610, episode: 55\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 4161.45\n",
      "total_reward: -1495838.55\n",
      "total_cost: 1244580.55\n",
      "total_trades: 43691\n",
      "Sharpe: 0.272\n",
      "=================================\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 4.16e+03   |\n",
      "|    total_cost           | 1.24e+06   |\n",
      "|    total_reward         | -1.5e+06   |\n",
      "|    total_reward_pct     | -99.7      |\n",
      "|    total_trades         | 43691      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 404        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01486009 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.103      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.18       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 7.03       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.25e+05    |\n",
      "|    total_cost           | 1.14e+06    |\n",
      "|    total_reward         | -1.38e+06   |\n",
      "|    total_reward_pct     | -91.7       |\n",
      "|    total_trades         | 43556       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017671354 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.728       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 7.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.06e+05    |\n",
      "|    total_cost           | 1.17e+06    |\n",
      "|    total_reward         | -1.29e+06   |\n",
      "|    total_reward_pct     | -86.2       |\n",
      "|    total_trades         | 43715       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 445         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014555991 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 465         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018062571 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 4.66        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 9.67e+04   |\n",
      "|    total_cost           | 2.13e+06   |\n",
      "|    total_reward         | -1.4e+06   |\n",
      "|    total_reward_pct     | -93.6      |\n",
      "|    total_trades         | 45240      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 485        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01713745 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.00407    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.79       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 12         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 7.37e+03     |\n",
      "|    total_cost           | 7.76e+05     |\n",
      "|    total_reward         | -1.49e+06    |\n",
      "|    total_reward_pct     | -99.5        |\n",
      "|    total_trades         | 42863        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129845105 |\n",
      "|    clip_fraction        | 0.178        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.4        |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.78         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 7.62         |\n",
      "------------------------------------------\n",
      "day: 2610, episode: 60\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 69909.60\n",
      "total_reward: -1430090.40\n",
      "total_cost: 1848192.17\n",
      "total_trades: 44871\n",
      "Sharpe: -0.311\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 6.99e+04    |\n",
      "|    total_cost           | 1.85e+06    |\n",
      "|    total_reward         | -1.43e+06   |\n",
      "|    total_reward_pct     | -95.3       |\n",
      "|    total_trades         | 44871       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 526         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019729266 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.95        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015576446 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.23        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.02e+05    |\n",
      "|    total_cost           | 2.13e+06    |\n",
      "|    total_reward         | -1.3e+06    |\n",
      "|    total_reward_pct     | -86.5       |\n",
      "|    total_trades         | 45438       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 566         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010983072 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.5         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.79e+04    |\n",
      "|    total_cost           | 9.99e+05    |\n",
      "|    total_reward         | -1.45e+06   |\n",
      "|    total_reward_pct     | -96.8       |\n",
      "|    total_trades         | 43565       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019583229 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 7.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.76e+04    |\n",
      "|    total_cost           | 6.73e+05    |\n",
      "|    total_reward         | -1.44e+06   |\n",
      "|    total_reward_pct     | -96.2       |\n",
      "|    total_trades         | 42370       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011801394 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.382       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 7.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.59e+05    |\n",
      "|    total_cost           | 2.32e+06    |\n",
      "|    total_reward         | -1.34e+06   |\n",
      "|    total_reward_pct     | -89.4       |\n",
      "|    total_trades         | 45930       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011881199 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.13        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 9.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012231166 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0639      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.5         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "day: 2610, episode: 65\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 482703.08\n",
      "total_reward: -1017296.92\n",
      "total_cost: 2667635.75\n",
      "total_trades: 46235\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.83e+05    |\n",
      "|    total_cost           | 2.67e+06    |\n",
      "|    total_reward         | -1.02e+06   |\n",
      "|    total_reward_pct     | -67.8       |\n",
      "|    total_trades         | 46235       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 668         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019498182 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.00168     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 3.1e+04     |\n",
      "|    total_cost           | 1.4e+06     |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -97.9       |\n",
      "|    total_trades         | 44039       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 7413        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011843931 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0959      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.66        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.22e+04    |\n",
      "|    total_cost           | 1.07e+06    |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.2       |\n",
      "|    total_trades         | 43522       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 7430        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019764248 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 9.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 5.83e+03    |\n",
      "|    total_cost           | 4.4e+05     |\n",
      "|    total_reward         | -1.49e+06   |\n",
      "|    total_reward_pct     | -99.6       |\n",
      "|    total_trades         | 42116       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 7447        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009225355 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 8.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 7464        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030535314 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0809     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 4.76e+05    |\n",
      "|    total_cost           | 3.65e+06    |\n",
      "|    total_reward         | -1.02e+06   |\n",
      "|    total_reward_pct     | -68.2       |\n",
      "|    total_trades         | 47718       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 7483        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027289452 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | -0.00106    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "day: 2610, episode: 70\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 95298.14\n",
      "total_reward: -1404701.86\n",
      "total_cost: 1630204.87\n",
      "total_trades: 44592\n",
      "Sharpe: 0.303\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.53e+04    |\n",
      "|    total_cost           | 1.63e+06    |\n",
      "|    total_reward         | -1.4e+06    |\n",
      "|    total_reward_pct     | -93.6       |\n",
      "|    total_trades         | 44592       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 7502        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019607982 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0932      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.52        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.59e+05    |\n",
      "|    total_cost           | 2.31e+06    |\n",
      "|    total_reward         | -1.24e+06   |\n",
      "|    total_reward_pct     | -82.8       |\n",
      "|    total_trades         | 45937       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 7525        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023764236 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 11         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 7543       |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03706941 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.4      |\n",
      "|    explained_variance   | 0.0921     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.37       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | 0.00592    |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 2.99e+04    |\n",
      "|    total_cost           | 1.1e+06     |\n",
      "|    total_reward         | -1.47e+06   |\n",
      "|    total_reward_pct     | -98         |\n",
      "|    total_trades         | 43708       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 7565        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009613279 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0865      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 4.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.96e+05    |\n",
      "|    total_cost           | 2.76e+06    |\n",
      "|    total_reward         | -5.04e+05   |\n",
      "|    total_reward_pct     | -33.6       |\n",
      "|    total_trades         | 46014       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 7583        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014809873 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.15e+06   |\n",
      "|    total_cost           | 2.53e+06   |\n",
      "|    total_reward         | -3.47e+05  |\n",
      "|    total_reward_pct     | -23.1      |\n",
      "|    total_trades         | 45761      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 7605       |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01036888 |\n",
      "|    clip_fraction        | 0.0939     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.6      |\n",
      "|    explained_variance   | 0.0513     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.8       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n",
      "day: 2610, episode: 75\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 595607.65\n",
      "total_reward: -904392.35\n",
      "total_cost: 2054829.46\n",
      "total_trades: 44828\n",
      "Sharpe: 0.291\n",
      "=================================\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 5.96e+05     |\n",
      "|    total_cost           | 2.05e+06     |\n",
      "|    total_reward         | -9.04e+05    |\n",
      "|    total_reward_pct     | -60.3        |\n",
      "|    total_trades         | 44828        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 7626         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069652963 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.7        |\n",
      "|    explained_variance   | 0.0926       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.9         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 7644        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011686271 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1.58e+06   |\n",
      "|    total_cost           | 3.07e+06   |\n",
      "|    total_reward         | 7.86e+04   |\n",
      "|    total_reward_pct     | 5.24       |\n",
      "|    total_trades         | 46113      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 7662       |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11231378 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.7      |\n",
      "|    explained_variance   | 0.0594     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53         |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.0367     |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 136        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 2.28e+06     |\n",
      "|    total_cost           | 3.04e+06     |\n",
      "|    total_reward         | 7.82e+05     |\n",
      "|    total_reward_pct     | 52.1         |\n",
      "|    total_trades         | 46248        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 13           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 7682         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042362083 |\n",
      "|    clip_fraction        | 0.0566       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.8        |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.4         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 243          |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2020-07-01 to  2020-10-02\n",
      "PPO Sharpe Ratio:  0.006609453367579865\n",
      "======DDPG Training========\n",
      "{'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]), 'buffer_size': 50000, 'learning_rate': 5e-06, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_504_1\n",
      "day: 2610, episode: 80\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1321039.66\n",
      "total_reward: -178960.34\n",
      "total_cost: 5093.52\n",
      "total_trades: 39645\n",
      "Sharpe: 0.302\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.03e+06  |\n",
      "|    total_cost       | 3.52e+03  |\n",
      "|    total_reward     | -4.73e+05 |\n",
      "|    total_reward_pct | -31.6     |\n",
      "|    total_trades     | 37660     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 34        |\n",
      "|    time_elapsed     | 302       |\n",
      "|    total timesteps  | 10444     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -170      |\n",
      "|    critic_loss      | 101       |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 7833      |\n",
      "-----------------------------------\n",
      "day: 2610, episode: 85\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1518514.81\n",
      "total_reward: 18514.81\n",
      "total_cost: 2939.11\n",
      "total_trades: 38475\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.2e+06   |\n",
      "|    total_cost       | 4.71e+03  |\n",
      "|    total_reward     | -2.99e+05 |\n",
      "|    total_reward_pct | -19.9     |\n",
      "|    total_trades     | 37832     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 28        |\n",
      "|    time_elapsed     | 743       |\n",
      "|    total timesteps  | 20888     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -102      |\n",
      "|    critic_loss      | 86.8      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 18277     |\n",
      "-----------------------------------\n",
      "day: 2610, episode: 90\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1073993.53\n",
      "total_reward: -426006.47\n",
      "total_cost: 4799.18\n",
      "total_trades: 38259\n",
      "Sharpe: 0.296\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.07e+06  |\n",
      "|    total_cost       | 4.8e+03   |\n",
      "|    total_reward     | -4.26e+05 |\n",
      "|    total_reward_pct | -28.4     |\n",
      "|    total_trades     | 38259     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 27        |\n",
      "|    time_elapsed     | 1127      |\n",
      "|    total timesteps  | 31332     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -60.4     |\n",
      "|    critic_loss      | 85.9      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 28721     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 9.31e+05  |\n",
      "|    total_cost       | 3.39e+03  |\n",
      "|    total_reward     | -5.69e+05 |\n",
      "|    total_reward_pct | -37.9     |\n",
      "|    total_trades     | 38364     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 27        |\n",
      "|    time_elapsed     | 1510      |\n",
      "|    total timesteps  | 41776     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -36.7     |\n",
      "|    critic_loss      | 83.1      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 39165     |\n",
      "-----------------------------------\n",
      "day: 2610, episode: 95\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1767808.41\n",
      "total_reward: 267808.41\n",
      "total_cost: 4877.51\n",
      "total_trades: 38512\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "-----------------------------------\n",
      "| environment/        |           |\n",
      "|    portfolio_value  | 1.44e+06  |\n",
      "|    total_cost       | 2.95e+03  |\n",
      "|    total_reward     | -6.31e+04 |\n",
      "|    total_reward_pct | -4.21     |\n",
      "|    total_trades     | 38338     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 27        |\n",
      "|    time_elapsed     | 1883      |\n",
      "|    total timesteps  | 52220     |\n",
      "| train/              |           |\n",
      "|    actor_loss       | -22.4     |\n",
      "|    critic_loss      | 71.6      |\n",
      "|    learning_rate    | 5e-06     |\n",
      "|    n_updates        | 49609     |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2020-07-01 to  2020-10-02\n",
      "======Best Model Retraining from:  2000-01-01 to  2020-10-02\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\ensemble_504_1\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 53        |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 233       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 32.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -826     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 395      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -459      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 221       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -703     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 319      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | -1.06e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 527       |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 270       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.25e+06 |\n",
      "|    total_cost         | 8.91e+05 |\n",
      "|    total_reward       | 1.75e+06 |\n",
      "|    total_reward_pct   | 116      |\n",
      "|    total_trades       | 42750    |\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 73.5     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 383      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 323      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 640      |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 337      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.00526 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 60.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.00134  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -1.3e+03 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.14e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.5e+06  |\n",
      "|    total_cost         | 1.74e+06 |\n",
      "|    total_reward       | 2e+06    |\n",
      "|    total_reward_pct   | 133      |\n",
      "|    total_trades       | 44795    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -218     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 34.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 42.5      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 9.65      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -229     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 36.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -152      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 25        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -216     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 59.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 41.8     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 41.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.46e+06  |\n",
      "|    total_cost         | 7.03e+05  |\n",
      "|    total_reward       | -3.59e+04 |\n",
      "|    total_reward_pct   | -2.39     |\n",
      "|    total_trades       | 45621     |\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 13        |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.32      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -269     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 42.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0.0204   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 801      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 363      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 718       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 399       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.95e+06 |\n",
      "|    total_cost         | 6.71e+05 |\n",
      "|    total_reward       | 1.45e+06 |\n",
      "|    total_reward_pct   | 96.7     |\n",
      "|    total_trades       | 44580    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -61.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 65.1     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.77     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -13      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.434    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -68.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0.0348   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -39.3    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "day: 2673, episode: 5\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 395605.42\n",
      "total_reward: -1104394.58\n",
      "total_cost: 206365.63\n",
      "total_trades: 42180\n",
      "Sharpe: 0.306\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.96e+05 |\n",
      "|    total_cost         | 2.06e+05 |\n",
      "|    total_reward       | -1.1e+06 |\n",
      "|    total_reward_pct   | -73.6    |\n",
      "|    total_trades       | 42180    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -1.44    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 247      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0.0403   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -168     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -13.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -44.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -82.5     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.811    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.937    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 6.59e+05  |\n",
      "|    total_cost         | 1.47e+05  |\n",
      "|    total_reward       | -8.41e+05 |\n",
      "|    total_reward_pct   | -56.1     |\n",
      "|    total_trades       | 41319     |\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 290       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -45.1     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -31.6    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.782    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 306      |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -20      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.246    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 105      |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 6.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -0.0114  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -66.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.42     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 5.45e+05  |\n",
      "|    total_cost         | 2.73e+05  |\n",
      "|    total_reward       | -9.55e+05 |\n",
      "|    total_reward_pct   | -63.7     |\n",
      "|    total_trades       | 40976     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 332       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 12.5      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.123     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 341       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 48.1      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -3.1     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.0307   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 43.6     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 367      |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 48.9     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.04e+05  |\n",
      "|    total_cost         | 6.5e+04   |\n",
      "|    total_reward       | -1.2e+06  |\n",
      "|    total_reward_pct   | -79.7     |\n",
      "|    total_trades       | 35799     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 375       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 30.6      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.831     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 383      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -32.4    |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 0.755    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 391       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 22        |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.399     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 399      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 14.5     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.241    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 408      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 60.7     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 417      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.615    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.75e+05  |\n",
      "|    total_cost         | 1.38e+05  |\n",
      "|    total_reward       | -1.12e+06 |\n",
      "|    total_reward_pct   | -75       |\n",
      "|    total_trades       | 34222     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 425       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -168      |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 434      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 65.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 442      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -74.1    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 451      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 47.2     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 459      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -34.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.957    |\n",
      "------------------------------------\n",
      "day: 2673, episode: 10\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 421819.24\n",
      "total_reward: -1078180.76\n",
      "total_cost: 297919.31\n",
      "total_trades: 36911\n",
      "Sharpe: 0.307\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.22e+05  |\n",
      "|    total_cost         | 2.98e+05  |\n",
      "|    total_reward       | -1.08e+06 |\n",
      "|    total_reward_pct   | -71.9     |\n",
      "|    total_trades       | 36911     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -2.96     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.649     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 476      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 3.82     |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.0504   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 485       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -0.699    |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0161    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 493      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.679    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.00176  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 502      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 0.735    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.00064  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.21e+04  |\n",
      "|    total_cost         | 4.41e+05  |\n",
      "|    total_reward       | -1.49e+06 |\n",
      "|    total_reward_pct   | -99.2     |\n",
      "|    total_trades       | 41756     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 511       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 37.6      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.825     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 521      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 3.02     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.505    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 529      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -54.6    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 538       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -144      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 546      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -78.4    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 9.62     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 554       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 5.51      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.566     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.58e+06  |\n",
      "|    total_cost         | 7.89e+05  |\n",
      "|    total_reward       | 8.08e+04  |\n",
      "|    total_reward_pct   | 5.39      |\n",
      "|    total_trades       | 39084     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 32.5      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.895     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 571      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 189      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 20.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 580      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -64.6    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 588      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0.117    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 179      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 17.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 597      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -71.7    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 7.46     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 2.2e+06   |\n",
      "|    total_cost         | 7.78e+05  |\n",
      "|    total_reward       | 7.02e+05  |\n",
      "|    total_reward_pct   | 46.8      |\n",
      "|    total_trades       | 41836     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 606       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -43       |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.01      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 614      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 7.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 624      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -228     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 27.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 635       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -234      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 31.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 644      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -118     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 7.32     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.21e+06  |\n",
      "|    total_cost         | 1.64e+05  |\n",
      "|    total_reward       | -2.86e+05 |\n",
      "|    total_reward_pct   | -19.1     |\n",
      "|    total_trades       | 40926     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 652       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 33.9      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 6.51      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 661      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -11.4    |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.559    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 669      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 60       |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 678      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -17.9    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 686      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -85      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 3.73     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 695       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -39       |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 6.89      |\n",
      "-------------------------------------\n",
      "day: 2673, episode: 15\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 332405.03\n",
      "total_reward: -1167594.97\n",
      "total_cost: 379464.75\n",
      "total_trades: 41239\n",
      "Sharpe: 0.258\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.32e+05  |\n",
      "|    total_cost         | 3.79e+05  |\n",
      "|    total_reward       | -1.17e+06 |\n",
      "|    total_reward_pct   | -77.8     |\n",
      "|    total_trades       | 41239     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 703       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -47.5     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.61      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 712      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 54.6     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 7.87     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 720       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 945       |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 643       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 729      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -45.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.79     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 738       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -110      |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 14.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.02e+06 |\n",
      "|    total_cost         | 4.65e+05 |\n",
      "|    total_reward       | 2.52e+06 |\n",
      "|    total_reward_pct   | 168      |\n",
      "|    total_trades       | 39057    |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 746      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 281      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 64.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 755      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 0.885    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.000629 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 763      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 1.49e-06 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -590     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 210      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 772      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -576     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 187      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 780      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -60.5    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 39.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 3.47e+06  |\n",
      "|    total_cost         | 2.39e+05  |\n",
      "|    total_reward       | 1.97e+06  |\n",
      "|    total_reward_pct   | 131       |\n",
      "|    total_trades       | 35949     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 788       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 33        |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.879     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 796      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -37.2    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 808      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 15.7     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.556    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 821      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 3.51     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.007    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 830      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -644     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 277      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 839       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -1.77e+03 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.54e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.02e+06  |\n",
      "|    total_cost         | 1.19e+05  |\n",
      "|    total_reward       | 7.52e+06  |\n",
      "|    total_reward_pct   | 502       |\n",
      "|    total_trades       | 36107     |\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 848       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -45.2     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.69      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 856      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -132     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 9.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 866      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -86.1    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 3.93     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 57        |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 876       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -472      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 116       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 885      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -257     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 40.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.17e+07 |\n",
      "|    total_cost         | 1.3e+05  |\n",
      "|    total_reward       | 1.02e+07 |\n",
      "|    total_reward_pct   | 683      |\n",
      "|    total_trades       | 35500    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 895      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -123     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 13.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 905      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -47.8    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 7.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 914      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -224     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 24.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 923      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 226      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 67.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 933      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 425      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 204      |\n",
      "------------------------------------\n",
      "day: 2673, episode: 20\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 21472067.99\n",
      "total_reward: 19972067.99\n",
      "total_cost: 231214.89\n",
      "total_trades: 37393\n",
      "Sharpe: 0.309\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.15e+07 |\n",
      "|    total_cost         | 2.31e+05 |\n",
      "|    total_reward       | 2e+07    |\n",
      "|    total_reward_pct   | 1.33e+03 |\n",
      "|    total_trades       | 37393    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 942      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -15.5    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.152    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 951      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -14.8    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.764    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 961       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -365      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 72.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 970      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -274     |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 43.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 979       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -2.05e+03 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.25e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 988      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 351      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 920      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.06e+07 |\n",
      "|    total_cost         | 4.95e+06 |\n",
      "|    total_reward       | 1.91e+07 |\n",
      "|    total_reward_pct   | 1.27e+03 |\n",
      "|    total_trades       | 43572    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 998      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -14.7    |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.258    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 1007      |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -21.8     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.283     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 1017     |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 4.06     |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.0238   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 1026     |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 7.43     |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0243   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 1036     |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 0.529    |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 0.000194 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | -1.8e+03 |\n",
      "|    total_cost         | 3.53e+05 |\n",
      "|    total_reward       | -1.5e+06 |\n",
      "|    total_reward_pct   | -100     |\n",
      "|    total_trades       | 40122    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 1045     |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -4.74    |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.78     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 1055      |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 77.9      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 2.7       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 1064     |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 57.1     |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 1073     |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 446      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 416      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 1082     |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 265      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 209      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 1090     |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -818     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 340      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 6.64e+06 |\n",
      "|    total_cost         | 1.17e+06 |\n",
      "|    total_reward       | 5.14e+06 |\n",
      "|    total_reward_pct   | 343      |\n",
      "|    total_trades       | 41484    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 1099     |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 311      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 62       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 1107     |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 309      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 151      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 1117     |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -576     |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 183      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 1127     |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.9    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 1.26e+03 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 3.47e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 1138      |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -5.77e+03 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 1.73e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.9e+07   |\n",
      "|    total_cost         | 1.29e+06  |\n",
      "|    total_reward       | 1.75e+07  |\n",
      "|    total_reward_pct   | 1.17e+03  |\n",
      "|    total_trades       | 44844     |\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 1148      |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | 88.3      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 4.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 1157     |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 103      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 7.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 1166     |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 281      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 35.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 1176      |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -799      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 390       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 1185     |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 25.8     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 26.9     |\n",
      "------------------------------------\n",
      "day: 2673, episode: 25\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 12083676.30\n",
      "total_reward: 10583676.30\n",
      "total_cost: 809189.68\n",
      "total_trades: 43009\n",
      "Sharpe: 0.481\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.21e+07 |\n",
      "|    total_cost         | 8.09e+05 |\n",
      "|    total_reward       | 1.06e+07 |\n",
      "|    total_reward_pct   | 706      |\n",
      "|    total_trades       | 43009    |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 1195     |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -60.7    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 2.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 1203     |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -0.356   |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 0.321    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 1213     |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 59.7     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 4.13     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 56        |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 1223      |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -7.93     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 1.41      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 1232     |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -143     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 1241      |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 56.3      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 2.04      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.29e+05  |\n",
      "|    total_cost         | 3.36e+05  |\n",
      "|    total_reward       | -5.71e+05 |\n",
      "|    total_reward_pct   | -38.1     |\n",
      "|    total_trades       | 41632     |\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 1251      |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | 2.7       |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.108     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 1262      |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -79.7     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 4.7       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 1271      |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | -91       |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 4.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 1282     |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -132     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 9.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 1292     |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 107      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 39.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 2.07e+06 |\n",
      "|    total_cost         | 4.61e+05 |\n",
      "|    total_reward       | 5.66e+05 |\n",
      "|    total_reward_pct   | 37.7     |\n",
      "|    total_trades       | 37784    |\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 1303     |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -62.3    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 1312     |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 27       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 1321     |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | -9.51    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 1330     |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 21       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.488    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 1339     |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 12       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 0.194    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.69e+05  |\n",
      "|    total_cost         | 3.39e+05  |\n",
      "|    total_reward       | -7.31e+05 |\n",
      "|    total_reward_pct   | -48.8     |\n",
      "|    total_trades       | 35639     |\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 1349      |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -81.7     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 4.2       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 1360     |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -117     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 1369     |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -315     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 70.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 1379      |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 1.2e+03   |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 783       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 1388     |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | 93.3     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 181      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 1397     |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 50       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 37       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 5.16e+06 |\n",
      "|    total_cost         | 2.38e+05 |\n",
      "|    total_reward       | 3.66e+06 |\n",
      "|    total_reward_pct   | 244      |\n",
      "|    total_trades       | 35885    |\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 1407     |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -42.7    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 1418     |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | -93.8    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 6.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 1427     |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -59.6    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 1437     |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -4.5     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 1446     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -220     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 24.7     |\n",
      "------------------------------------\n",
      "day: 2673, episode: 30\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 1114777.18\n",
      "total_reward: -385222.82\n",
      "total_cost: 85344.20\n",
      "total_trades: 37494\n",
      "Sharpe: 0.307\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.11e+06  |\n",
      "|    total_cost         | 8.53e+04  |\n",
      "|    total_reward       | -3.85e+05 |\n",
      "|    total_reward_pct   | -25.7     |\n",
      "|    total_trades       | 37494     |\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 1455      |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -65       |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 4.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 1464     |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -26.1    |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 1474     |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -256     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 55.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 1484     |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 221      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 28.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 1493      |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | -478      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 199       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 4.22e+06  |\n",
      "|    total_cost         | 2.4e+05   |\n",
      "|    total_reward       | 2.72e+06  |\n",
      "|    total_reward_pct   | 181       |\n",
      "|    total_trades       | 41628     |\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 1506      |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | 63.9      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 9.22      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 1515      |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | 112       |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 1524     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 104      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 9.35     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 1534      |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | 690       |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 260       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 1544     |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -501     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 432      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 1553     |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 940      |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 479      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 8.73e+06 |\n",
      "|    total_cost         | 2.33e+05 |\n",
      "|    total_reward       | 7.23e+06 |\n",
      "|    total_reward_pct   | 482      |\n",
      "|    total_trades       | 39965    |\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 1563     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | 66       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 3.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 1574     |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -239     |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 41.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 1583      |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | -46.2     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 7.48      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 1592      |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | -186      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 21.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 1604     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 37       |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.48e+06  |\n",
      "|    total_cost         | 9.67e+04  |\n",
      "|    total_reward       | -2.44e+04 |\n",
      "|    total_reward_pct   | -1.63     |\n",
      "|    total_trades       | 39503     |\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 1614      |\n",
      "|    total_timesteps    | 88500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | 87.3      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 7.6       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 1624     |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -13      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 3.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 1632     |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -76.9    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 4        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 1640     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -322     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 60       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 1648     |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 2.47e+03 |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 3.66e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 3.13e+06 |\n",
      "|    total_cost         | 4.65e+05 |\n",
      "|    total_reward       | 1.63e+06 |\n",
      "|    total_reward_pct   | 109      |\n",
      "|    total_trades       | 38555    |\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 1657     |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -20.5    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 0.341    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 1665     |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -139     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 9.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 1674     |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 36.5     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 14.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 1682     |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 404      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 86.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 1690     |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 262      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 54.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 1698      |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -1.27e+03 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 919       |\n",
      "-------------------------------------\n",
      "day: 2673, episode: 35\n",
      "begin_total_asset: 1500000.00\n",
      "end_total_asset: 4811498.79\n",
      "total_reward: 3311498.79\n",
      "total_cost: 157649.06\n",
      "total_trades: 38365\n",
      "Sharpe: 0.313\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 4.81e+06 |\n",
      "|    total_cost         | 1.58e+05 |\n",
      "|    total_reward       | 3.31e+06 |\n",
      "|    total_reward_pct   | 221      |\n",
      "|    total_trades       | 38365    |\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 1707     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -32.6    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 1716     |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -290     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 35.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 1724     |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -19.4    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 3.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 1732     |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -37.2    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 8.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 1742     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -36.1    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 10.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.94e+06 |\n",
      "|    total_cost         | 2.54e+04 |\n",
      "|    total_reward       | 4.42e+05 |\n",
      "|    total_reward_pct   | 29.5     |\n",
      "|    total_trades       | 38657    |\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 1751     |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 299      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 49.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 1759     |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -378     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 144      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 1766     |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 496      |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 252      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 1775     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -358     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 76       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 1784     |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -8.23    |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 47.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 7.03e+06  |\n",
      "|    total_cost         | 5.13e+04  |\n",
      "|    total_reward       | 5.53e+06  |\n",
      "|    total_reward_pct   | 369       |\n",
      "|    total_trades       | 40681     |\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 1792      |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | 16.4      |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.459     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 1800     |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -101     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 7.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 1808     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -107     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 5.44     |\n",
      "------------------------------------\n",
      "======Trading from:  2020-10-02 to  2021-01-11\n",
      "Ensemble Strategy took:  1194.0142626365025  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "-0qd8acMtj1f",
    "outputId": "a7fa85f0-7825-4b9a-d313-cd99ad70ecb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.235258</td>\n",
       "      <td>0.021856</td>\n",
       "      <td>0.354622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.231081</td>\n",
       "      <td>0.238328</td>\n",
       "      <td>0.241891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.109143</td>\n",
       "      <td>-0.282221</td>\n",
       "      <td>0.055951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.248089</td>\n",
       "      <td>-0.175771</td>\n",
       "      <td>-0.424196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>PPO</td>\n",
       "      <td>-0.708764</td>\n",
       "      <td>-0.584231</td>\n",
       "      <td>-1.137173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.389002</td>\n",
       "      <td>0.250089</td>\n",
       "      <td>0.413635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.3015</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>0.080439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126  2019-01-02  2019-04-01       DDPG   0.235258   0.021856    0.354622\n",
       "1  189  2019-04-01  2019-06-27       DDPG   0.231081   0.238328    0.241891\n",
       "2  252  2019-06-27  2019-09-24        A2C   0.109143  -0.282221    0.055951\n",
       "3  315  2019-09-24  2019-12-20        A2C   0.248089  -0.175771   -0.424196\n",
       "4  378  2019-12-20  2020-03-24        PPO  -0.708764  -0.584231   -1.137173\n",
       "5  441  2020-03-24  2020-07-01       DDPG   0.389002   0.250089    0.413635\n",
       "6  504  2020-07-01  2020-10-02        A2C     0.3015   0.006609    0.080439"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.read_csv('results/ensemble_df_summary_20210517.csv')\n",
    "# df_summary.to_csv('results/ensemble_df_summary_20210517.csv', index=False)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "X4JKB--8tj1g"
   },
   "outputs": [],
   "source": [
    "unique_trade_date = processed_full[(processed_full.date > val_test_start)&(processed_full.date <= val_test_end)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "q9mKF7GGtj1g",
    "outputId": "5de4e5e6-d74b-4d12-b786-7e299dabd6a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.7558402147296476\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "oyosyW7_tj1g",
    "outputId": "29307dfb-1d27-4fb7-dc7a-7a34a4902d59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.475870e+06</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>-0.016087</td>\n",
       "      <td>2019-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.470745e+06</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>-0.003473</td>\n",
       "      <td>2019-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.497176e+06</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>2019-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.477800e+06</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>-0.012941</td>\n",
       "      <td>2019-04-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return    datadate\n",
       "0   1.500000e+06  2019-04-01           NaN  2019-04-01\n",
       "1   1.475870e+06  2019-04-02     -0.016087  2019-04-02\n",
       "2   1.470745e+06  2019-04-03     -0.003473  2019-04-03\n",
       "3   1.497176e+06  2019-04-04      0.017971  2019-04-04\n",
       "4   1.477800e+06  2019-04-05     -0.012941  2019-04-05"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value = pd.read_csv('results/ensemble_df_account_value_20210517.csv')\n",
    "# df_account_value.to_csv('results/ensemble_df_account_value_20210517.csv', index=False)\n",
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "wLsRdw2Ctj1h",
    "outputId": "01dd70f8-639f-49f7-8e75-60ebc88b0e4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "1053083a-d74c-48b0-a623-de33282e2fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return            0.277934\n",
      "Cumulative returns       0.535994\n",
      "Annual volatility      290.524602\n",
      "Sharpe ratio             0.755840\n",
      "Calmar ratio             0.278645\n",
      "Stability                0.007187\n",
      "Max drawdown            -0.997448\n",
      "Omega ratio            103.463126\n",
      "Sortino ratio          280.261702\n",
      "Skew                          NaN\n",
      "Kurtosis                      NaN\n",
      "Tail ratio               1.303097\n",
      "Daily value at risk    -35.731270\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "4f77cef2-3934-444a-cacc-4ed8f94514ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to IHSG===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (430, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2019-04-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-01-07</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>20</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>27.124%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>50.607%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>29422.576%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-99.745%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>103.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>283.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-3617.527%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>7584844315817185135397817855243028418895524408400980482151422921539584.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>-1.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.74</td>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.02</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.03</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.52</td>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.67</td>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>87.14%</td>\n",
       "      <td>-99.74%</td>\n",
       "      <td>38388.93%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to IHSG===========\")\n",
    "%matplotlib inline\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^JKSE', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlLT9_5WN478"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YktexHcqh1jc",
    "outputId": "38566531-a3a0-4705-db30-d437e8f8fc73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (430, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_perf_stats=get_baseline('^JKSE',\n",
    "                                  start = df_account_value.loc[0,'date'],\n",
    "                                  end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook FinRL_ensemble_stock_trading_ICAIF_2020.ipynb to html\n",
      "[NbConvertApp] Writing 2671810 bytes to FinRL_ensemble_stock_trading_ICAIF_2020.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html FinRL_ensemble_stock_trading_ICAIF_2020.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_ensemble_stock_trading_ICAIF_2020.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
